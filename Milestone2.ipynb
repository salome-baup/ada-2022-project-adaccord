{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d00dcbed",
   "metadata": {},
   "source": [
    "## Importing librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7524e6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os \n",
    "import json\n",
    "import string\n",
    "import requests\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# EDA\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from wikidata.client import Client\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "\n",
    "# Preprocessing\n",
    "from langdetect import detect\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import wordnet\n",
    "from names_dataset import NameDataset\n",
    "from nltk.corpus import stopwords\n",
    "from itertools import chain \n",
    "\n",
    "\n",
    "# LDA\n",
    "from gensim.models import Phrases\n",
    "from gensim import corpora\n",
    "from gensim import models\n",
    "\n",
    "# BERTopic\n",
    "from bertopic import BERTopic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3240ba52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7bfd36b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install langdetect\n",
    "!pip install names-dataset\n",
    "!pip install bertopic\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f1ea528",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import download\n",
    "download('averaged_perceptron_tagger')\n",
    "download('wordnet')\n",
    "download('omw-1.4')\n",
    "download('punkt')\n",
    "download('stopwords')\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5198b3e5",
   "metadata": {
    "tags": []
   },
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dabee6f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "[[1]](http://www.cs.cmu.edu/~ark/personas/) CMU Movie Summary Corpus webpage  \n",
    "[[2]](http://www.cs.cmu.edu/~dbamman/pubs/pdf/bamman+oconnor+smith.acl13.pdf) _Learning Latent Personas of Film Characters_, David Bamman, Brendan O'Connor and Noah A. Smith, ACL 2013, Sofia, Bulgaria, August 2013 \\\n",
    "[[3]](https://www.nltk.org/) NLKT documentation \\\n",
    "\n",
    "# Table of contents\n",
    "### [1. Metadata](#1)\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;**[1.1 The data](#1.1)**\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;[1.2 Cleaning the dictionaries](#1.2)\\\n",
    "&nbsp;&nbsp;&nbsp;[1.3 Duplicate values](#1.3)\\\n",
    "&nbsp;&nbsp;&nbsp;[1.4 Missing values](#1.4)\\\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[1.4.1 Recovering Ethnicities](#1.4.1)\\\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[1.4.2 Recovering missing Actor names ](#1.4.2)\n",
    "\n",
    "### [2. Plot Summaries and Metascores](#2)\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;**[2.1 Preprocessing](#2.1)**\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[2.1.1 Missing plot summaries check](#2.1.1)\\\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[2.1.2 Cleaning](#2.1.2)\\\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[2.1.3 Tokenization](#2.1.3)\\\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[2.1.4 PoS tagging](#2.1.4)\\\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[2.1.5 Lemmatization](#2.1.5)\\\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[2.1.6 Regrouping tokens and removing stop words](#2.1.6)\\\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[2.1.7 Integration into movies dataset ](#2.1.7)\\\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[2.1.8 Preprocessing results](#2.1.8)\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;**[2.2 Importing Metascore](#2.2)**\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;**[2.3 Initial analysis](#2.3)**\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[2.3.1 Plot structure](#2.3.1)\\\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[2.3.2 Most common tokens](#2.3.2)\\\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[2.3.3 Words polarity](#2.3.3)\\\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[2.3.4 Ratings](#2.3.4)\\\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[2.3.5 Combined infromation](#2.3.5)\n",
    "\n",
    "### [3. Topic extraction](#3)\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;**[3.1 LDA](#3.1)**\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[3.1.1 Data preparation](#3.1.1)\\\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[3.1.2 Implementation](#3.1.2)\\\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[3.1.3 Model evaluation](#3.1.3)\\\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[3.1.4 Resulting topics](#3.1.4)\\\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[3.1.5 Topic Visualizations](#3.1.5)\\\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[3.1.6 Assigning topics to movies](#3.1.6)\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;**[3.2 BERTopic](#3.2)**\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[3.2.1 Implementation](#3.2.1)\\\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[3.2.2 Model evaluation](#3.2.2)\\\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[3.2.3 Resulting topics](#3.2.3)\\\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[3.2.4 Topic Visualizations](#3.2.4)\\\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[3.2.5 Assigning topics to movies](#3.2.5)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0db749e",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 1. Metadata <a id='1'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9392f814",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1.1 The Data  <a id='1.1'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd8b4e47",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "`movie.metadata.tsv.gz` [3.4 M]\n",
    "\n",
    "\n",
    "Metadata for 81,741 movies, extracted from the Noverber 4, 2012 dump of Freebase. Tab-separated. The columns are:\n",
    "\n",
    "1. Wikipedia movie ID\n",
    "2. Freebase movie ID\n",
    "3. Movie name\n",
    "4. Movie release date\n",
    "5. Movie box office revenue\n",
    "6. Movie runtime\n",
    "7. Movie languages (Freebase ID:name tuples)\n",
    "8. Movie countries (Freebase ID:name tuples)\n",
    "9. Movie genres (Freebase ID:name tuples)\n",
    "\n",
    "\n",
    "`character.metadata.tsv.gz` [14 M]\n",
    "\n",
    "Metadata for 450,669 characters aligned to the movies above, extracted from the November 4, 2012 dump of Freebase. Tab-separated. The columns are:\n",
    "\n",
    "1. Wikipedia movie ID\n",
    "2. Freebase movie ID\n",
    "3. Movie release date\n",
    "4. Character name\n",
    "5. Actor date of birth\n",
    "6. Actor gender\n",
    "7. Actor height (in meters)\n",
    "8. Actor ethnicity (Freebase ID)\n",
    "9. Actor name\n",
    "10. Actor age at movie release\n",
    "11. Freebase character/actor map ID\n",
    "12. Freebase character ID\n",
    "13. Freebase actor ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df45a638",
   "metadata": {
    "id": "Lh7MrLDZiVK2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WikiMovieID</th>\n",
       "      <th>FreeMovieID</th>\n",
       "      <th>Title</th>\n",
       "      <th>ReleaseDate</th>\n",
       "      <th>Revenue</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Languages</th>\n",
       "      <th>Countries</th>\n",
       "      <th>Genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>975900</td>\n",
       "      <td>/m/03vyhn</td>\n",
       "      <td>Ghosts of Mars</td>\n",
       "      <td>2001-08-24</td>\n",
       "      <td>14010832.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>{\"/m/02h40lc\": \"English Language\"}</td>\n",
       "      <td>{\"/m/09c7w0\": \"United States of America\"}</td>\n",
       "      <td>{\"/m/01jfsb\": \"Thriller\", \"/m/06n90\": \"Science...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3196793</td>\n",
       "      <td>/m/08yl5d</td>\n",
       "      <td>Getting Away with Murder: The JonBenét Ramsey ...</td>\n",
       "      <td>2000-02-16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>95.0</td>\n",
       "      <td>{\"/m/02h40lc\": \"English Language\"}</td>\n",
       "      <td>{\"/m/09c7w0\": \"United States of America\"}</td>\n",
       "      <td>{\"/m/02n4kr\": \"Mystery\", \"/m/03bxz7\": \"Biograp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28463795</td>\n",
       "      <td>/m/0crgdbh</td>\n",
       "      <td>Brun bitter</td>\n",
       "      <td>1988</td>\n",
       "      <td>NaN</td>\n",
       "      <td>83.0</td>\n",
       "      <td>{\"/m/05f_3\": \"Norwegian Language\"}</td>\n",
       "      <td>{\"/m/05b4w\": \"Norway\"}</td>\n",
       "      <td>{\"/m/0lsxr\": \"Crime Fiction\", \"/m/07s9rl0\": \"D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9363483</td>\n",
       "      <td>/m/0285_cd</td>\n",
       "      <td>White Of The Eye</td>\n",
       "      <td>1987</td>\n",
       "      <td>NaN</td>\n",
       "      <td>110.0</td>\n",
       "      <td>{\"/m/02h40lc\": \"English Language\"}</td>\n",
       "      <td>{\"/m/07ssc\": \"United Kingdom\"}</td>\n",
       "      <td>{\"/m/01jfsb\": \"Thriller\", \"/m/0glj9q\": \"Erotic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>261236</td>\n",
       "      <td>/m/01mrr1</td>\n",
       "      <td>A Woman in Flames</td>\n",
       "      <td>1983</td>\n",
       "      <td>NaN</td>\n",
       "      <td>106.0</td>\n",
       "      <td>{\"/m/04306rv\": \"German Language\"}</td>\n",
       "      <td>{\"/m/0345h\": \"Germany\"}</td>\n",
       "      <td>{\"/m/07s9rl0\": \"Drama\"}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   WikiMovieID FreeMovieID                                              Title  \\\n",
       "0       975900   /m/03vyhn                                     Ghosts of Mars   \n",
       "1      3196793   /m/08yl5d  Getting Away with Murder: The JonBenét Ramsey ...   \n",
       "2     28463795  /m/0crgdbh                                        Brun bitter   \n",
       "3      9363483  /m/0285_cd                                   White Of The Eye   \n",
       "4       261236   /m/01mrr1                                  A Woman in Flames   \n",
       "\n",
       "  ReleaseDate     Revenue  Runtime                           Languages  \\\n",
       "0  2001-08-24  14010832.0     98.0  {\"/m/02h40lc\": \"English Language\"}   \n",
       "1  2000-02-16         NaN     95.0  {\"/m/02h40lc\": \"English Language\"}   \n",
       "2        1988         NaN     83.0  {\"/m/05f_3\": \"Norwegian Language\"}   \n",
       "3        1987         NaN    110.0  {\"/m/02h40lc\": \"English Language\"}   \n",
       "4        1983         NaN    106.0   {\"/m/04306rv\": \"German Language\"}   \n",
       "\n",
       "                                   Countries  \\\n",
       "0  {\"/m/09c7w0\": \"United States of America\"}   \n",
       "1  {\"/m/09c7w0\": \"United States of America\"}   \n",
       "2                     {\"/m/05b4w\": \"Norway\"}   \n",
       "3             {\"/m/07ssc\": \"United Kingdom\"}   \n",
       "4                    {\"/m/0345h\": \"Germany\"}   \n",
       "\n",
       "                                              Genres  \n",
       "0  {\"/m/01jfsb\": \"Thriller\", \"/m/06n90\": \"Science...  \n",
       "1  {\"/m/02n4kr\": \"Mystery\", \"/m/03bxz7\": \"Biograp...  \n",
       "2  {\"/m/0lsxr\": \"Crime Fiction\", \"/m/07s9rl0\": \"D...  \n",
       "3  {\"/m/01jfsb\": \"Thriller\", \"/m/0glj9q\": \"Erotic...  \n",
       "4                            {\"/m/07s9rl0\": \"Drama\"}  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WikiMovieID</th>\n",
       "      <th>FreeMovieID</th>\n",
       "      <th>ReleaseDate</th>\n",
       "      <th>CharName</th>\n",
       "      <th>ActorDOB</th>\n",
       "      <th>ActorGender</th>\n",
       "      <th>ActorHeight</th>\n",
       "      <th>FreeEthnicityID</th>\n",
       "      <th>ActorName</th>\n",
       "      <th>ActorAgeRelease</th>\n",
       "      <th>FreeMapID</th>\n",
       "      <th>FreeCharID</th>\n",
       "      <th>FreeActorID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>975900</td>\n",
       "      <td>/m/03vyhn</td>\n",
       "      <td>2001-08-24</td>\n",
       "      <td>Akooshay</td>\n",
       "      <td>1958-08-26</td>\n",
       "      <td>F</td>\n",
       "      <td>1.620</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Wanda De Jesus</td>\n",
       "      <td>42.0</td>\n",
       "      <td>/m/0bgchxw</td>\n",
       "      <td>/m/0bgcj3x</td>\n",
       "      <td>/m/03wcfv7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>975900</td>\n",
       "      <td>/m/03vyhn</td>\n",
       "      <td>2001-08-24</td>\n",
       "      <td>Lieutenant Melanie Ballard</td>\n",
       "      <td>1974-08-15</td>\n",
       "      <td>F</td>\n",
       "      <td>1.780</td>\n",
       "      <td>/m/044038p</td>\n",
       "      <td>Natasha Henstridge</td>\n",
       "      <td>27.0</td>\n",
       "      <td>/m/0jys3m</td>\n",
       "      <td>/m/0bgchn4</td>\n",
       "      <td>/m/0346l4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>975900</td>\n",
       "      <td>/m/03vyhn</td>\n",
       "      <td>2001-08-24</td>\n",
       "      <td>Desolation Williams</td>\n",
       "      <td>1969-06-15</td>\n",
       "      <td>M</td>\n",
       "      <td>1.727</td>\n",
       "      <td>/m/0x67</td>\n",
       "      <td>Ice Cube</td>\n",
       "      <td>32.0</td>\n",
       "      <td>/m/0jys3g</td>\n",
       "      <td>/m/0bgchn_</td>\n",
       "      <td>/m/01vw26l</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>975900</td>\n",
       "      <td>/m/03vyhn</td>\n",
       "      <td>2001-08-24</td>\n",
       "      <td>Sgt Jericho Butler</td>\n",
       "      <td>1967-09-12</td>\n",
       "      <td>M</td>\n",
       "      <td>1.750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jason Statham</td>\n",
       "      <td>33.0</td>\n",
       "      <td>/m/02vchl6</td>\n",
       "      <td>/m/0bgchnq</td>\n",
       "      <td>/m/034hyc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>975900</td>\n",
       "      <td>/m/03vyhn</td>\n",
       "      <td>2001-08-24</td>\n",
       "      <td>Bashira Kincaid</td>\n",
       "      <td>1977-09-25</td>\n",
       "      <td>F</td>\n",
       "      <td>1.650</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Clea DuVall</td>\n",
       "      <td>23.0</td>\n",
       "      <td>/m/02vbb3r</td>\n",
       "      <td>/m/0bgchp9</td>\n",
       "      <td>/m/01y9xg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   WikiMovieID FreeMovieID ReleaseDate                    CharName  \\\n",
       "0       975900   /m/03vyhn  2001-08-24                    Akooshay   \n",
       "1       975900   /m/03vyhn  2001-08-24  Lieutenant Melanie Ballard   \n",
       "2       975900   /m/03vyhn  2001-08-24         Desolation Williams   \n",
       "3       975900   /m/03vyhn  2001-08-24          Sgt Jericho Butler   \n",
       "4       975900   /m/03vyhn  2001-08-24             Bashira Kincaid   \n",
       "\n",
       "     ActorDOB ActorGender  ActorHeight FreeEthnicityID           ActorName  \\\n",
       "0  1958-08-26           F        1.620             NaN      Wanda De Jesus   \n",
       "1  1974-08-15           F        1.780      /m/044038p  Natasha Henstridge   \n",
       "2  1969-06-15           M        1.727         /m/0x67            Ice Cube   \n",
       "3  1967-09-12           M        1.750             NaN       Jason Statham   \n",
       "4  1977-09-25           F        1.650             NaN         Clea DuVall   \n",
       "\n",
       "   ActorAgeRelease   FreeMapID  FreeCharID FreeActorID  \n",
       "0             42.0  /m/0bgchxw  /m/0bgcj3x  /m/03wcfv7  \n",
       "1             27.0   /m/0jys3m  /m/0bgchn4   /m/0346l4  \n",
       "2             32.0   /m/0jys3g  /m/0bgchn_  /m/01vw26l  \n",
       "3             33.0  /m/02vchl6  /m/0bgchnq   /m/034hyc  \n",
       "4             23.0  /m/02vbb3r  /m/0bgchp9   /m/01y9xg  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "movies_path = \"data/movie.metadata.tsv\"\n",
    "characters_path = \"data/character.metadata.tsv\"\n",
    "\n",
    "# naming the columns with adequate names\n",
    "movies_column_names = [\"WikiMovieID\", \"FreeMovieID\", \"Title\", \"ReleaseDate\", \"Revenue\", \"Runtime\", \"Languages\", \"Countries\", \"Genres\"]\n",
    "characters_column_names = [\"WikiMovieID\", \"FreeMovieID\", \"ReleaseDate\", \"CharName\", \"ActorDOB\", \"ActorGender\", \"ActorHeight\", \"FreeEthnicityID\",\\\n",
    "                           \"ActorName\", \"ActorAgeRelease\", \"FreeMapID\", \"FreeCharID\", \"FreeActorID\"]\n",
    "\n",
    "movies = pd.read_csv(movies_path, sep='\\t', header=None, names=movies_column_names)\n",
    "characters = pd.read_csv(characters_path, sep='\\t', header=None, names=characters_column_names)\n",
    "\n",
    "display(movies.head())\n",
    "display(characters.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851e43f4",
   "metadata": {
    "id": "X6iUOgrb_zJk"
   },
   "source": [
    "#### Initial remarks :\n",
    "- `ReleaseDate`doesn't have a standard format.\n",
    "- `Languages`, `Countries`and `Genres`columns have their values in a dictionary of form : `{Freebase id : Actual name}`\n",
    "\n",
    "#### Dataset length\n",
    "We verify that the given dataset entries are indeed as much as we expected : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8fecf3e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in the movie.metadata dataset : 81741\n",
      "Number of rows in the character.metadata dataset : 450669\n"
     ]
    }
   ],
   "source": [
    "n_mov = len(movies)\n",
    "n_char = len(characters)\n",
    "print('Number of rows in the movie.metadata dataset :', n_mov)\n",
    "print('Number of rows in the character.metadata dataset :', n_char)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e709333",
   "metadata": {
    "id": "rjVmf5vLn1Ag",
    "tags": []
   },
   "source": [
    "## 1.2 Cleaning Dictionaries  <a id='1.2'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba1660c",
   "metadata": {
    "id": "rjVmf5vLn1Ag",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "Columns `Languages`, `Countries`, `Genres` are dictionaries containing both the Freebase ID and the actual name, for each entry. We will keep only the names for the sake of clarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90e8d836",
   "metadata": {
    "id": "jgCSb-o_lbq_"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Languages</th>\n",
       "      <th>Countries</th>\n",
       "      <th>Genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[English Language]</td>\n",
       "      <td>[United States of America]</td>\n",
       "      <td>[Thriller, Science Fiction, Horror, Adventure,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[English Language]</td>\n",
       "      <td>[United States of America]</td>\n",
       "      <td>[Mystery, Biographical film, Drama, Crime Drama]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[Norwegian Language]</td>\n",
       "      <td>[Norway]</td>\n",
       "      <td>[Crime Fiction, Drama]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[English Language]</td>\n",
       "      <td>[United Kingdom]</td>\n",
       "      <td>[Thriller, Erotic thriller, Psychological thri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[German Language]</td>\n",
       "      <td>[Germany]</td>\n",
       "      <td>[Drama]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Languages                   Countries  \\\n",
       "0    [English Language]  [United States of America]   \n",
       "1    [English Language]  [United States of America]   \n",
       "2  [Norwegian Language]                    [Norway]   \n",
       "3    [English Language]            [United Kingdom]   \n",
       "4     [German Language]                   [Germany]   \n",
       "\n",
       "                                              Genres  \n",
       "0  [Thriller, Science Fiction, Horror, Adventure,...  \n",
       "1   [Mystery, Biographical film, Drama, Crime Drama]  \n",
       "2                             [Crime Fiction, Drama]  \n",
       "3  [Thriller, Erotic thriller, Psychological thri...  \n",
       "4                                            [Drama]  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def extract_values(column):\n",
    "    values = []\n",
    "    column=json.loads(column)\n",
    "    for key in column:\n",
    "        values.append(column[key])\n",
    "    return values\n",
    "\n",
    "movies.Languages = movies.Languages.apply(extract_values)\n",
    "movies.Countries = movies.Countries.apply(extract_values)\n",
    "movies.Genres = movies.Genres.apply(extract_values)\n",
    "\n",
    "display(movies[[\"Languages\", \"Countries\", \"Genres\"]].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83c8bbe",
   "metadata": {
    "id": "WVAODRGY4OmE",
    "tags": []
   },
   "source": [
    "## 1.3 Duplicate values  <a id='1.3'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b310970",
   "metadata": {
    "id": "WVAODRGY4OmE",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "Starting with the characters dataset we only care if a whole row is duplicated as there is no specific feature that we prohibit from happenning twice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a99a8151",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicated rows in characters : 0\n"
     ]
    }
   ],
   "source": [
    "print(\"Duplicated rows in characters : {}\".format(characters.duplicated().sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc3c0c8c",
   "metadata": {},
   "source": [
    "As for the movies dataset we have to be more careful as we don't want the same movie appearing twice under different release date or freebase id for example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "59a10531",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "moSpedsF4QP8",
    "outputId": "68874924-0ddd-4757-e01a-43cfe78e191d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate rows in :\n",
      "\tWikiMovieID : 0 \n",
      "\tFreeMovieID : 0 \n",
      "\tTitle : 6263 \n",
      "\tReleaseDate : 61351 \n",
      "\tRevenue : 74378 \n",
      "\tRuntime : 81143 \n",
      "\tLanguages : 79924 \n",
      "\tCountries : 79617 \n",
      "\tGenres : 57924 \n"
     ]
    }
   ],
   "source": [
    "print(\"Duplicate rows in :\")\n",
    "for column in movies.columns:\n",
    "    duplicated_rows = movies[column].duplicated().sum()\n",
    "    print(\"\\t{} : {} \".format(column, duplicated_rows))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4172f746",
   "metadata": {
    "id": "z-OCRjOv6OLy"
   },
   "source": [
    "The fact that `Title`has a duplicated rows is a bit concerning. We see however than `WikiMovieID` and movies `FreeMovieID` have only unique entries. This can indicate us that movies can have the same title while being actually different movies. We can also check the runtimes of movies with the same name : it is very unlikely that 2 different movies with the same title would have the exact same runtime too. This reasoning can also be done for the release date."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e9590ca",
   "metadata": {},
   "source": [
    "---\n",
    "TODO : a code cell which outputs the movies that have the same name AND that have the same runtime ?   \n",
    "TODO : a code cell which outputs the movies that have the same name AND that have the same release date ?  \n",
    "and then check manually if there is an error in the runtime or the release date, using the freebase id  \n",
    "and then maybe delete the following example cells? as will have been already checked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8f29d01f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81
    },
    "id": "mwYgX2b9V-fE",
    "outputId": "bdb71854-bdd3-4f21-d866-0faa908a574f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WikiMovieID</th>\n",
       "      <th>FreeMovieID</th>\n",
       "      <th>Title</th>\n",
       "      <th>ReleaseDate</th>\n",
       "      <th>Revenue</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Languages</th>\n",
       "      <th>Countries</th>\n",
       "      <th>Genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>62836</th>\n",
       "      <td>29666067</td>\n",
       "      <td>/m/0fphzrf</td>\n",
       "      <td>Hunting Season</td>\n",
       "      <td>1010-12-02</td>\n",
       "      <td>12160978.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>[Turkish Language, English Language]</td>\n",
       "      <td>[Turkey]</td>\n",
       "      <td>[Crime Fiction, Mystery, Drama, Thriller]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       WikiMovieID FreeMovieID           Title ReleaseDate     Revenue  \\\n",
       "62836     29666067  /m/0fphzrf  Hunting Season  1010-12-02  12160978.0   \n",
       "\n",
       "       Runtime                             Languages Countries  \\\n",
       "62836    140.0  [Turkish Language, English Language]  [Turkey]   \n",
       "\n",
       "                                          Genres  \n",
       "62836  [Crime Fiction, Mystery, Drama, Thriller]  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies[movies.Title==\"Hunting Season\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eb38456",
   "metadata": {
    "id": "tAEMhesrWCPY"
   },
   "source": [
    "Wrong input for release date (1010->2010)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c20f594d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 112
    },
    "id": "C8g5ZN_c7C-b",
    "outputId": "5fc871f2-fb2b-4650-bf6c-381596d624a7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WikiMovieID</th>\n",
       "      <th>FreeMovieID</th>\n",
       "      <th>Title</th>\n",
       "      <th>ReleaseDate</th>\n",
       "      <th>Revenue</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Languages</th>\n",
       "      <th>Countries</th>\n",
       "      <th>Genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>623</th>\n",
       "      <td>3670013</td>\n",
       "      <td>/m/09thsq</td>\n",
       "      <td>Harlow</td>\n",
       "      <td>1965-06-23</td>\n",
       "      <td>1000000.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>[English Language]</td>\n",
       "      <td>[United States of America]</td>\n",
       "      <td>[Biographical film, Biography, Drama, Black-an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1223</th>\n",
       "      <td>27171821</td>\n",
       "      <td>/m/0bwklv0</td>\n",
       "      <td>Harlow</td>\n",
       "      <td>1965</td>\n",
       "      <td>NaN</td>\n",
       "      <td>109.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[United States of America]</td>\n",
       "      <td>[Biographical film]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      WikiMovieID FreeMovieID   Title ReleaseDate    Revenue  Runtime  \\\n",
       "623       3670013   /m/09thsq  Harlow  1965-06-23  1000000.0    109.0   \n",
       "1223     27171821  /m/0bwklv0  Harlow        1965        NaN    109.0   \n",
       "\n",
       "               Languages                   Countries  \\\n",
       "623   [English Language]  [United States of America]   \n",
       "1223                  []  [United States of America]   \n",
       "\n",
       "                                                 Genres  \n",
       "623   [Biographical film, Biography, Drama, Black-an...  \n",
       "1223                                [Biographical film]  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies[movies.Title==\"Harlow\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6886e31",
   "metadata": {
    "id": "EM2wFqtq94YV"
   },
   "source": [
    "Actually these are 2 different movies, but the first movie `WikiID`=3670013 has a wrong runtime (the correct runtime for this ID is 125 and not 109).\n",
    "\n",
    "So far couldn't find an example of a duplicated movie + No duplicated Wiki/Freebase IDs "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2910698f",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f311c4",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1.4 Missing values  <a id='1.4'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c58450f5",
   "metadata": {},
   "source": [
    "We want to see which columns have missing entries, and for those columns what is the percentage of missing entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d47dd6c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WikiMovieID    False\n",
       "FreeMovieID    False\n",
       "Title          False\n",
       "ReleaseDate     True\n",
       "Revenue         True\n",
       "Runtime         True\n",
       "Languages      False\n",
       "Countries      False\n",
       "Genres         False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies.isna().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "287c3474",
   "metadata": {},
   "source": [
    "For the movies dataset, only `ReleaseDate`, `Revenue` and `Runtime` have missing entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c1d3ec2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of missing entries in the movie dataset (%):\n",
      "    ReleaseDate : 8.44\n",
      "    Revenue : 89.72\n",
      "    Runtime : 25.02\n"
     ]
    }
   ],
   "source": [
    "mov_missing = movies[['ReleaseDate', 'Revenue', 'Runtime']].isna().sum()\n",
    "print('Percentage of missing entries in the movie dataset (%):')\n",
    "for x in range(len(mov_missing.values)):\n",
    "    print(\"   \",mov_missing.index[x], ':', round(100*mov_missing.values[x]/n_mov, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe2b6a4",
   "metadata": {},
   "source": [
    "90% of the revenues are non specified. We won't use this feature in our project.  \n",
    "8% of the release dates and 25% of the runtimes are missing, we can fill them if we find the correct ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7e56f5b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WikiMovieID        False\n",
       "FreeMovieID        False\n",
       "ReleaseDate         True\n",
       "CharName            True\n",
       "ActorDOB            True\n",
       "ActorGender         True\n",
       "ActorHeight         True\n",
       "FreeEthnicityID     True\n",
       "ActorName           True\n",
       "ActorAgeRelease     True\n",
       "FreeMapID          False\n",
       "FreeCharID          True\n",
       "FreeActorID         True\n",
       "dtype: bool"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "characters.isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4475c477",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of missing entries in the characters dataset (%):\n",
      "    ReleaseDate : 2.22\n",
      "    CharName : 57.22\n",
      "    ActorDOB : 23.55\n",
      "    ActorGender : 10.12\n",
      "    ActorHeight : 65.65\n",
      "    FreeEthnicityID : 76.47\n",
      "    ActorName : 0.27\n",
      "    ActorAgeRelease : 35.08\n",
      "    FreeCharID : 57.22\n",
      "    FreeActorID : 0.18\n"
     ]
    }
   ],
   "source": [
    "char_missing = characters[['ReleaseDate', 'CharName', 'ActorDOB', 'ActorGender', 'ActorHeight', 'FreeEthnicityID', 'ActorName',\n",
    "                           'ActorAgeRelease', 'FreeCharID', 'FreeActorID']].isna().sum()\n",
    "print('Percentage of missing entries in the characters dataset (%):')\n",
    "for x in range(len(char_missing.values)):\n",
    "    print(\"   \",char_missing.index[x], ':', round(100*char_missing.values[x]/n_char, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2480e8c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### 1.4.1 Recovering Ethnicities  <a id='1.4.1'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab2af37c",
   "metadata": {},
   "source": [
    "`Ethnicity` only has the ID of the Freebase database whose API is currently depreciated. To solve this problem we use the [Freebase/Wikidata Mappings](https://developers.google.com/freebase#freebase-wikidata-mappings) which as the name suggests maps the given Freebase Ids to WikiData.\n",
    "\n",
    "- Note : The data has been created based on the Wikidata-Dump of October 28, 2013, and contains only those links that have at least two common Wikipedia-Links and not a single disagreeing Wikipedia-Link. Since the movies/characters dataset were gathered during that time too there is no time conflict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0ca31ff8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Freebase</th>\n",
       "      <th>W3</th>\n",
       "      <th>Wiki</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;http://rdf.freebase.com/ns/m.0695j&gt;</td>\n",
       "      <td>&lt;http://www.w3.org/2002/07/owl#sameAs&gt;</td>\n",
       "      <td>&lt;http://www.wikidata.org/entity/Q6718&gt; .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;http://rdf.freebase.com/ns/m.05nrg&gt;</td>\n",
       "      <td>&lt;http://www.w3.org/2002/07/owl#sameAs&gt;</td>\n",
       "      <td>&lt;http://www.wikidata.org/entity/Q538&gt; .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;http://rdf.freebase.com/ns/m.0jgd&gt;</td>\n",
       "      <td>&lt;http://www.w3.org/2002/07/owl#sameAs&gt;</td>\n",
       "      <td>&lt;http://www.wikidata.org/entity/Q414&gt; .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;http://rdf.freebase.com/ns/m.0d_23&gt;</td>\n",
       "      <td>&lt;http://www.w3.org/2002/07/owl#sameAs&gt;</td>\n",
       "      <td>&lt;http://www.wikidata.org/entity/Q2537&gt; .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;http://rdf.freebase.com/ns/m.04g7d&gt;</td>\n",
       "      <td>&lt;http://www.w3.org/2002/07/owl#sameAs&gt;</td>\n",
       "      <td>&lt;http://www.wikidata.org/entity/Q315&gt; .</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Freebase  \\\n",
       "0  <http://rdf.freebase.com/ns/m.0695j>   \n",
       "1  <http://rdf.freebase.com/ns/m.05nrg>   \n",
       "2   <http://rdf.freebase.com/ns/m.0jgd>   \n",
       "3  <http://rdf.freebase.com/ns/m.0d_23>   \n",
       "4  <http://rdf.freebase.com/ns/m.04g7d>   \n",
       "\n",
       "                                       W3  \\\n",
       "0  <http://www.w3.org/2002/07/owl#sameAs>   \n",
       "1  <http://www.w3.org/2002/07/owl#sameAs>   \n",
       "2  <http://www.w3.org/2002/07/owl#sameAs>   \n",
       "3  <http://www.w3.org/2002/07/owl#sameAs>   \n",
       "4  <http://www.w3.org/2002/07/owl#sameAs>   \n",
       "\n",
       "                                       Wiki  \n",
       "0  <http://www.wikidata.org/entity/Q6718> .  \n",
       "1   <http://www.wikidata.org/entity/Q538> .  \n",
       "2   <http://www.wikidata.org/entity/Q414> .  \n",
       "3  <http://www.wikidata.org/entity/Q2537> .  \n",
       "4   <http://www.wikidata.org/entity/Q315> .  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mappings_path = \"data/fb2w.nt.gz\"\n",
    "maps = pd.read_csv(mappings_path, sep='\\t', header=None, skiprows=4, names=[\"Freebase\", \"W3\", \"Wiki\"])\n",
    "display(maps.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "105eeb95",
   "metadata": {},
   "source": [
    "We only need the ID and not the whole website link so we transform columns in the following way :\n",
    "- Freebase : <http://rdf.freebase.com/ns/m.CODE_ID> -> /m/CODE_ID\n",
    "- Wiki : <http://www.wikidata.org/entity/CODE_ID> -> CODE_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "06c9b794",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Transforms the Freebase website to Freebase ID\n",
    "\"\"\"\n",
    "def elim_freebase(web):\n",
    "    return \"/m/\"+web[30:-1]\n",
    "\n",
    "\"\"\"\n",
    "Transforms the Freebase website to Freebase ID\n",
    "\"\"\"\n",
    "def elim_wiki(web):\n",
    "    return web[32:-3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ea9d3cff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>free</th>\n",
       "      <th>wiki</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/m/0695j</td>\n",
       "      <td>Q6718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/m/05nrg</td>\n",
       "      <td>Q538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/m/0jgd</td>\n",
       "      <td>Q414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/m/0d_23</td>\n",
       "      <td>Q2537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/m/04g7d</td>\n",
       "      <td>Q315</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       free   wiki\n",
       "0  /m/0695j  Q6718\n",
       "1  /m/05nrg   Q538\n",
       "2   /m/0jgd   Q414\n",
       "3  /m/0d_23  Q2537\n",
       "4  /m/04g7d   Q315"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maps[\"free\"] = maps.Freebase.apply(elim_freebase)\n",
    "maps[\"wiki\"] = maps.Wiki.apply(elim_wiki)\n",
    "\n",
    "# We don't need the rest of the columns so we drop them \n",
    "maps.drop(columns = [\"Freebase\", \"W3\", \"Wiki\"], inplace=True)\n",
    "maps.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd1bab75",
   "metadata": {},
   "source": [
    "Firstly, we get the Wikidata IDs based on the mapping we created :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8f2c92e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WikiMovieID</th>\n",
       "      <th>FreeMovieID</th>\n",
       "      <th>ReleaseDate</th>\n",
       "      <th>CharName</th>\n",
       "      <th>ActorDOB</th>\n",
       "      <th>ActorGender</th>\n",
       "      <th>ActorHeight</th>\n",
       "      <th>FreeEthnicityID</th>\n",
       "      <th>ActorName</th>\n",
       "      <th>ActorAgeRelease</th>\n",
       "      <th>FreeMapID</th>\n",
       "      <th>FreeCharID</th>\n",
       "      <th>FreeActorID</th>\n",
       "      <th>Ethnicity_W</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>975900</td>\n",
       "      <td>/m/03vyhn</td>\n",
       "      <td>2001-08-24</td>\n",
       "      <td>Akooshay</td>\n",
       "      <td>1958-08-26</td>\n",
       "      <td>F</td>\n",
       "      <td>1.620</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Wanda De Jesus</td>\n",
       "      <td>42.0</td>\n",
       "      <td>/m/0bgchxw</td>\n",
       "      <td>/m/0bgcj3x</td>\n",
       "      <td>/m/03wcfv7</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>975900</td>\n",
       "      <td>/m/03vyhn</td>\n",
       "      <td>2001-08-24</td>\n",
       "      <td>Lieutenant Melanie Ballard</td>\n",
       "      <td>1974-08-15</td>\n",
       "      <td>F</td>\n",
       "      <td>1.780</td>\n",
       "      <td>/m/044038p</td>\n",
       "      <td>Natasha Henstridge</td>\n",
       "      <td>27.0</td>\n",
       "      <td>/m/0jys3m</td>\n",
       "      <td>/m/0bgchn4</td>\n",
       "      <td>/m/0346l4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>975900</td>\n",
       "      <td>/m/03vyhn</td>\n",
       "      <td>2001-08-24</td>\n",
       "      <td>Desolation Williams</td>\n",
       "      <td>1969-06-15</td>\n",
       "      <td>M</td>\n",
       "      <td>1.727</td>\n",
       "      <td>/m/0x67</td>\n",
       "      <td>Ice Cube</td>\n",
       "      <td>32.0</td>\n",
       "      <td>/m/0jys3g</td>\n",
       "      <td>/m/0bgchn_</td>\n",
       "      <td>/m/01vw26l</td>\n",
       "      <td>Q49085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>975900</td>\n",
       "      <td>/m/03vyhn</td>\n",
       "      <td>2001-08-24</td>\n",
       "      <td>Sgt Jericho Butler</td>\n",
       "      <td>1967-09-12</td>\n",
       "      <td>M</td>\n",
       "      <td>1.750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jason Statham</td>\n",
       "      <td>33.0</td>\n",
       "      <td>/m/02vchl6</td>\n",
       "      <td>/m/0bgchnq</td>\n",
       "      <td>/m/034hyc</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>975900</td>\n",
       "      <td>/m/03vyhn</td>\n",
       "      <td>2001-08-24</td>\n",
       "      <td>Bashira Kincaid</td>\n",
       "      <td>1977-09-25</td>\n",
       "      <td>F</td>\n",
       "      <td>1.650</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Clea DuVall</td>\n",
       "      <td>23.0</td>\n",
       "      <td>/m/02vbb3r</td>\n",
       "      <td>/m/0bgchp9</td>\n",
       "      <td>/m/01y9xg</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   WikiMovieID FreeMovieID ReleaseDate                    CharName  \\\n",
       "0       975900   /m/03vyhn  2001-08-24                    Akooshay   \n",
       "1       975900   /m/03vyhn  2001-08-24  Lieutenant Melanie Ballard   \n",
       "2       975900   /m/03vyhn  2001-08-24         Desolation Williams   \n",
       "3       975900   /m/03vyhn  2001-08-24          Sgt Jericho Butler   \n",
       "4       975900   /m/03vyhn  2001-08-24             Bashira Kincaid   \n",
       "\n",
       "     ActorDOB ActorGender  ActorHeight FreeEthnicityID           ActorName  \\\n",
       "0  1958-08-26           F        1.620             NaN      Wanda De Jesus   \n",
       "1  1974-08-15           F        1.780      /m/044038p  Natasha Henstridge   \n",
       "2  1969-06-15           M        1.727         /m/0x67            Ice Cube   \n",
       "3  1967-09-12           M        1.750             NaN       Jason Statham   \n",
       "4  1977-09-25           F        1.650             NaN         Clea DuVall   \n",
       "\n",
       "   ActorAgeRelease   FreeMapID  FreeCharID FreeActorID Ethnicity_W  \n",
       "0             42.0  /m/0bgchxw  /m/0bgcj3x  /m/03wcfv7         NaN  \n",
       "1             27.0   /m/0jys3m  /m/0bgchn4   /m/0346l4         NaN  \n",
       "2             32.0   /m/0jys3g  /m/0bgchn_  /m/01vw26l      Q49085  \n",
       "3             33.0  /m/02vchl6  /m/0bgchnq   /m/034hyc         NaN  \n",
       "4             23.0  /m/02vbb3r  /m/0bgchp9   /m/01y9xg         NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "characters = characters.merge(maps, how=\"left\", left_on=\"FreeEthnicityID\", right_on=\"free\")\n",
    "characters.drop(columns=[\"free\"], inplace=True)\n",
    "characters.rename(columns={\"wiki\":\"Ethnicity_W\"}, inplace=True)\n",
    "display(characters.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef5e438",
   "metadata": {},
   "source": [
    "As we can see the mapping is not complete : Some Freebase IDs do not correspond to any Wikidata ID. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f89f7dda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 12992 instances of ethnicities that we could not map from Freebase to Wikidata\n"
     ]
    }
   ],
   "source": [
    "unmapped_ethnicities = characters.Ethnicity_W.isna().sum() - characters.FreeEthnicityID.isna().sum()\n",
    "print(\"There are {} instances of ethnicities that we could not map from Freebase to Wikidata\".format(unmapped_ethnicities))\n",
    "# Instances of ethnicities -> Can we replace by number of actors ethnicities? Actors with different initial ethnicities ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5106ab7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Given a Wikidata ID (eg. \"Q49085\") returns the corresponding label \n",
    "\n",
    "Using this function row by row (pd.apply method) takes enormous time -> improvement? For ethnicities its ok as they're only 350 dinstinct ones\n",
    "\"\"\"\n",
    "def get_wikidata_label(wikidata_id):\n",
    "    client = Client()\n",
    "    entity = client.get(wikidata_id, load=True)\n",
    "    return str(entity.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b0d2b302",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Result is map_Ethnicity_W_to_Ethnicity_name a map between Ethnicity wikidata ID and Ethnicity label\n",
    "map_Ethnicity_W_to_Ethnicity_name = pd.DataFrame(characters.Ethnicity_W.unique(), columns=[\"Ethnicity_W\"]).dropna()\n",
    "\n",
    "# Getting the equivalent label for each Wikidata ID\n",
    "map_Ethnicity_W_to_Ethnicity_name[\"EthnicityName\"] = map_Ethnicity_W_to_Ethnicity_name.Ethnicity_W.apply(get_wikidata_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5e0ae846",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WikiMovieID</th>\n",
       "      <th>FreeMovieID</th>\n",
       "      <th>ReleaseDate</th>\n",
       "      <th>CharName</th>\n",
       "      <th>ActorDOB</th>\n",
       "      <th>ActorGender</th>\n",
       "      <th>ActorHeight</th>\n",
       "      <th>ActorName</th>\n",
       "      <th>ActorAgeRelease</th>\n",
       "      <th>FreeMapID</th>\n",
       "      <th>FreeCharID</th>\n",
       "      <th>FreeActorID</th>\n",
       "      <th>EthnicityName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>975900</td>\n",
       "      <td>/m/03vyhn</td>\n",
       "      <td>2001-08-24</td>\n",
       "      <td>Akooshay</td>\n",
       "      <td>1958-08-26</td>\n",
       "      <td>F</td>\n",
       "      <td>1.620</td>\n",
       "      <td>Wanda De Jesus</td>\n",
       "      <td>42.0</td>\n",
       "      <td>/m/0bgchxw</td>\n",
       "      <td>/m/0bgcj3x</td>\n",
       "      <td>/m/03wcfv7</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>975900</td>\n",
       "      <td>/m/03vyhn</td>\n",
       "      <td>2001-08-24</td>\n",
       "      <td>Lieutenant Melanie Ballard</td>\n",
       "      <td>1974-08-15</td>\n",
       "      <td>F</td>\n",
       "      <td>1.780</td>\n",
       "      <td>Natasha Henstridge</td>\n",
       "      <td>27.0</td>\n",
       "      <td>/m/0jys3m</td>\n",
       "      <td>/m/0bgchn4</td>\n",
       "      <td>/m/0346l4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>975900</td>\n",
       "      <td>/m/03vyhn</td>\n",
       "      <td>2001-08-24</td>\n",
       "      <td>Desolation Williams</td>\n",
       "      <td>1969-06-15</td>\n",
       "      <td>M</td>\n",
       "      <td>1.727</td>\n",
       "      <td>Ice Cube</td>\n",
       "      <td>32.0</td>\n",
       "      <td>/m/0jys3g</td>\n",
       "      <td>/m/0bgchn_</td>\n",
       "      <td>/m/01vw26l</td>\n",
       "      <td>African Americans</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>975900</td>\n",
       "      <td>/m/03vyhn</td>\n",
       "      <td>2001-08-24</td>\n",
       "      <td>Sgt Jericho Butler</td>\n",
       "      <td>1967-09-12</td>\n",
       "      <td>M</td>\n",
       "      <td>1.750</td>\n",
       "      <td>Jason Statham</td>\n",
       "      <td>33.0</td>\n",
       "      <td>/m/02vchl6</td>\n",
       "      <td>/m/0bgchnq</td>\n",
       "      <td>/m/034hyc</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>975900</td>\n",
       "      <td>/m/03vyhn</td>\n",
       "      <td>2001-08-24</td>\n",
       "      <td>Bashira Kincaid</td>\n",
       "      <td>1977-09-25</td>\n",
       "      <td>F</td>\n",
       "      <td>1.650</td>\n",
       "      <td>Clea DuVall</td>\n",
       "      <td>23.0</td>\n",
       "      <td>/m/02vbb3r</td>\n",
       "      <td>/m/0bgchp9</td>\n",
       "      <td>/m/01y9xg</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   WikiMovieID FreeMovieID ReleaseDate                    CharName  \\\n",
       "0       975900   /m/03vyhn  2001-08-24                    Akooshay   \n",
       "1       975900   /m/03vyhn  2001-08-24  Lieutenant Melanie Ballard   \n",
       "2       975900   /m/03vyhn  2001-08-24         Desolation Williams   \n",
       "3       975900   /m/03vyhn  2001-08-24          Sgt Jericho Butler   \n",
       "4       975900   /m/03vyhn  2001-08-24             Bashira Kincaid   \n",
       "\n",
       "     ActorDOB ActorGender  ActorHeight           ActorName  ActorAgeRelease  \\\n",
       "0  1958-08-26           F        1.620      Wanda De Jesus             42.0   \n",
       "1  1974-08-15           F        1.780  Natasha Henstridge             27.0   \n",
       "2  1969-06-15           M        1.727            Ice Cube             32.0   \n",
       "3  1967-09-12           M        1.750       Jason Statham             33.0   \n",
       "4  1977-09-25           F        1.650         Clea DuVall             23.0   \n",
       "\n",
       "    FreeMapID  FreeCharID FreeActorID      EthnicityName  \n",
       "0  /m/0bgchxw  /m/0bgcj3x  /m/03wcfv7                NaN  \n",
       "1   /m/0jys3m  /m/0bgchn4   /m/0346l4                NaN  \n",
       "2   /m/0jys3g  /m/0bgchn_  /m/01vw26l  African Americans  \n",
       "3  /m/02vchl6  /m/0bgchnq   /m/034hyc                NaN  \n",
       "4  /m/02vbb3r  /m/0bgchp9   /m/01y9xg                NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Assigining the missing ethnicities\n",
    "characters = characters.merge(map_Ethnicity_W_to_Ethnicity_name, how=\"left\", left_on=\"Ethnicity_W\", right_on=\"Ethnicity_W\").drop(columns= [\"FreeEthnicityID\", \"Ethnicity_W\"])\n",
    "display(characters.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0ff777ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique ethnicities : 355\n"
     ]
    }
   ],
   "source": [
    "ethn_len = characters.EthnicityName.nunique()\n",
    "print(\"Number of unique ethnicities : {}\".format(ethn_len))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bfbc368",
   "metadata": {},
   "source": [
    "The whole ethnicities plot (355 different ethnicities) was not really readable, so :\n",
    "- what are the most present ones (ex 20 first) \n",
    "- group some ethnicities together into big categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9a2b036e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAnEAAAGkCAYAAABelnM5AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAABc4klEQVR4nO3debzt5dz/8de7Uxo0kA6aSwqVREnS7TaLUCiVodAtQ8hw3ypjop/Mwi0iKUODQoUS0UCT0zyoWypKUREdae79++O6VmedffbeZ59z1vXde+3zfj4e67HXutZa38937e/6rvVZ1yjbRERERMRwWWKydyAiIiIiFlySuIiIiIghlCQuIiIiYggliYuIiIgYQkniIiIiIoZQkriIiIiIIZQkLqYtSV+V9KEBbWstSf+SNKPePk3Sfw1i23V7J0nabVDbW4C4H5d0q6S/TPDx+0n6Tuv9ilgYkr4l6eMD2tazJN2wCM//l6THzOcxc32uLOx2YvGVJC6GkqTrJN0pabakf0g6S9JbJD34nrb9Ftsfm+C2njfeY2z/yfbytu8fwL7PkwjZfpHtwxd12wu4H2sC7wU2tP3oUe5fpC+xCcQf2BfuAsa1pMd2HXdBTOQ9OR1N5rEZdOz6eXHNfB4z1+fKaD8OJ7KdWHwliYth9lLbKwBrAwcCewOHDjqIpCUHvc0pYm3gb7ZvnuwdiUUz6PfoNH7PR0wvtnPJZeguwHXA80aUbQE8AGxcb38L+Hi9vgrwY+AfwN+BMyk/Yr5dn3Mn8C/gfcA6gIHdgT8BZ/SVLVm3dxrwCeA84J/A8cDK9b5nATeMtr/ANsA9wL013sV92/uven0J4IPAH4GbgSOAlep9vf3Yre7brcAHxvk/rVSff0vd3gfr9p9XX/MDdT++NeJ5Dx1x/7+A1YD9gGPqNmcDlwOb9z1vNeC4Gu9a4J1j7Nce9X9wT932icAbgBP7HnM1cEzf7euBTev1xwM/r8fyKuBVfY/7FvC/wE/qPp4LrFfvO6P+/+6ocXcCLqP8IOg9f6n6f910lP1+FnBDfZ/cDNwEbA+8GPi/uj/v73v80sAXgBvr5QvA0gv6nhxnP/YG/lKfswSwD/AH4G/1OPXek733zR51P24C3tu3vf2AY4HvALcD/0V57xxaH/tn4OPAjPr4xwKnU977twJH921rYMemlr8EuKj+n84CNunb3pOBC+q2jgaOop7zY7zv3gj8DrgN+Bmw9jjvi97/+L19x/oNE3kt9X4Dj63XlwU+SzkH/wn8upb1jsuSwAHA/cBddR++PMp2lgY+Qzn3/wp8FVh2vPfTZH9W59L2Muk7kEsuC3NhlCSulv8JeGu9/i3mJHGfqB94S9XLfwAabVt9H6xHUJKZuT5s62NOo3yxbVwfcxzwnXrfsxgjiavX9+s9tu/+05iTxL2RksA8Blge+AHw7RH79vW6X08C7gaeMMb/6QhKgrlCfe7/AbuPtZ8jnjva69ivfsm8GJhR/6/n1PuWAM4HPgw8pO7/NcALx9j+g8en3n5M/QJaAliV8oX35777bqv3PZSS0L2B8uX3FEoisVHfdv9OSeqXBL4LHNUX58EvxXr7fcydhGwHXDrO/+S++hqXAt5ESVi/V//HG9X/z2Pq4/cHzgEeCcykJCEfW9D35Dj78UnKF/uywLtqrDVq2deAI0e8b46s/78n1v3uf0/eS0lIl6jb+1HdxkPr/p8HvLk+/kjgA/WxywBb1/JBH5unUBKop1Heb7vV/83SlPfYH4F31//fDvU1jJrE1dd2NfCEGvuDwFnjxO79j/ev238x8G/g4Qv6WijJ3mnA6vV1bFVfQ++49H+u/NeI/e7fzheAE4CVKe+3E4FPzO/9lMv0vaQ5NaabGykfcCPdS0kM1rZ9r+0zXT/5xrGf7Tts3znG/d+2fZntO4APAa8ar4PyAngN8Dnb19j+F7AvsPOIJq6P2r7T9sXAxZRkbi51X3YC9rU92/Z1lNqA1y3i/v3a9k9d+vF8uy/2U4GZtve3fY9LP56vAztPZKP18bOBTYH/pNSU/FnS4+vtM20/QKmZuc72Ybbvs30BJYneoW9zP7B9nu37KF+um44T+jvAiyWtWG+/rr6usdwLHGD7XkrNzyrAQfV/fDmldnKT+tjXAPvbvtn2LcBHmfP/X5j3ZL8HgI/Yvru+R99MqZW9wfbdlMRsh1HeN3fYvhQ4DNil776zbf+o/o9XBF4EvKs+/mbg88w5lvdSmuNXs32X7V/X8kEfmzcBX7N9ru37XfqN3g1sWS9LAV+o/79jgd+Os603UxKe39XY/w/YVNLa4zznXsrxu9f2Tyk1ZI9bkNdS++m+EdjL9p/r6zirHqMJkyTK/+Pdtv9ue3Z9Df3HZFHeTzGEksTFdLM65dfxSJ+m/Ao/RdI1kvaZwLauX4D7/0j5QlllQns5vtXq9vq3vSTwqL6y/tGk/6bU2I20CnNqK/q3tfoi7t/I2MvURGFtYLU60OQfkv4BvH/Efs/P6ZQakGfW66dRErj/rLepcZ42Is5rgP7BGRP5/wBg+0bgN8ArJT2Mkrx8d5x9/JvnDHDpJfh/7bv/zr54ox3L1er1hXlP9rvF9l19t9cGftj3P/kdpXmu//8/8j272hj3rU15P9/Ut72vUWrkoNReCjhP0uWS3tj3vIEdm7q9947Y3pp1v1ej1NT2Jyp/HGUb/ds6qG87f6+vYbzz4W81QRtrfyd6Hi5DaeZeFDOB5YDz+17DybUcFv39FEMonVdj2pD0VMoH8q9H3ld/tb6X8oWwEfArSb+1fSqluWI08/sVu2bf9bUov4RvpfSrWa5vv2Yw54N2Itu9kfKF07/t+yiJwhrzeW6/W5lTY3JF37b+PMHnL+iv+OuBa22vvwjbPx14KbAupZbhH5Qk4OnAl/vinG77+Qu4f+M5nNIPbElKjdRE/0fz0zuWl9fba9WyhX1P9hv5mOuBN9r+zcgHSlqnXl0TuHLkvoyyvespNV6rjEhiqPv+F0qtEJK2Bn4h6QwGf2yup9R6HjDyDkn/CawuSX2J3FqMnSz1tjVegt7CrZQm9vUotebjGe+430r5gbDRaO/P+byfYppKTVwMPUkrSnoJpWnrO7WpaORjXiLpsbVJ4nZKDUWvNuWvlD5XC+q1kjaUtByl38yxtYbm/yi1U9tKWorS92bpvuf9FVinfzqUEY4E3i1pXUnLU5KZo0f7Mh1P3ZdjgAMkrVCbjd5DaT6ciL8Cj5C00gQffx5wu6S9JS0raYakjWtyPdb2R/7fTweeTemsfQOlc/Y2wCOAC+tjfgxsIOl1kpaql6dKesICvK6RcX9E6X+1F6Uf4aAcCXxQ0kxJq1D60n0Hmrwnv0o51mvX7c+UtN2Ix3xI0nL1S/4NlMEA87B9E3AK8Nl6fi0hab2aOCFpR0m9HxS3UZKP+xn8sfk68BZJT1Px0HperQCcTflx805JS0p6BaV/2nj/n33ra0fSSpJ2HCf2QNTm6W8Cn5O0Wj0vni5p6VEePuY+1O18Hfi8pEcCSFpd0gvr9fHeTzFNJYmLYXaipNmUX9gfAD5H+WIazfrALyh9Ws4GvmL7tHrfJyhftP+Q9N8LEP/blM7Nf6E0l7wTwPY/gbcB36DUet1BGeXW8/3692+SLhhlu9+s2z6DMsLzLuAdC7Bf/d5R419DqaH8Xt3+fNm+kpKEXFP/N6vN5/H3U2rRNq37fSvlfzBWEngosGHd9o/qNv6PcozOrLdvr/v+m14TZq1xeAGlL9CNlP9/r4P/ROwHHF7jvqpu805K3611KQNJBuXjwCzgEuBSykjK3tx4g35PHkTp9H5KPS/OoQwI6Hc6pcntVOAztk8ZZ3u7Uprjr6AkasdS+lxB6f94rqR/1Zh72b520MfG9ixKjd+X6z5cDbwewPY9wCvq7dso/T/HPHa2f1j35ShJt1NGJb9orNgT3N+J+m/K8f8tpRn3k4z+/XsQpR/jbZK+OMr9e1P+B+fU1/AL5vTRG+/9FNOUnH6PERFI+jCwge3XTva+DFptTr0WWGpBa3QjYupKn7iIWOxJWpkyL+CijtyNiOhMmlMjYrEm6U2UJvmTbJ8x2fsTETFRaU6NiIiIGEKpiYuIiIgYQkniIiIiIobQYjewYZVVVvE666wz2bsRERERMV/nn3/+rbZnjnbfYpfErbPOOsyaNWuydyMiIiJiviSNuZxcmlMjIiIihlCSuIiIiIghlCQuIiIiYggliYuIiIgYQkniIiIiIoZQkriIiIiIIZQkLiIiImIIJYmLiIiIGEJJ4iIiIiKGUJK4iIiIiCGUJC4iIiJiCC12a6eOZ519frJQz7vuwG0HvCcRERER40tNXERERMQQapbESfqmpJslXTai/B2SrpJ0uaRP9ZXvK+nqet8L+8o3k3Rpve+LklTLl5Z0dC0/V9I6rV5LRERExFTTsibuW8A2/QWSng1sB2xieyPgM7V8Q2BnYKP6nK9ImlGfdjCwB7B+vfS2uTtwm+3HAp8HPtnwtURERERMKc2SONtnAH8fUfxW4EDbd9fH3FzLtwOOsn237WuBq4EtJK0KrGj7bNsGjgC273vO4fX6scBze7V0EREREdNd133iNgD+ozZ/ni7pqbV8deD6vsfdUMtWr9dHls/1HNv3Af8EHjFaUEl7SJoladYtt9wysBcTERERMVm6TuKWBB4ObAn8D3BMrT0brQbN45Qzn/vmLrQPsb257c1nzpy54HsdERERMcV0ncTdAPzAxXnAA8AqtXzNvsetAdxYy9cYpZz+50haEliJeZtvIyIiIqalrpO4HwHPAZC0AfAQ4FbgBGDnOuJ0XcoAhvNs3wTMlrRlrbHbFTi+busEYLd6fQfgl7XfXERERMS012yyX0lHAs8CVpF0A/AR4JvAN+u0I/cAu9XE63JJxwBXAPcBe9q+v27qrZSRrssCJ9ULwKHAtyVdTamB27nVa4mIiIiYapolcbZ3GeOu147x+AOAA0YpnwVsPEr5XcCOi7KPEREREcMqKzZEREREDKEkcRERERFDKElcRERExBBKEhcRERExhJLERURERAyhJHERERERQyhJXERERMQQShIXERERMYSSxEVEREQMoSRxEREREUMoSVxERETEEEoSFxERETGEksRFREREDKEkcRERERFDKElcRERExBBKEhcRERExhJLERURERAyhJHERERERQyhJXERERMQQShIXERERMYSSxEVEREQMoSRxEREREUOoWRIn6ZuSbpZ02Sj3/bckS1qlr2xfSVdLukrSC/vKN5N0ab3vi5JUy5eWdHQtP1fSOq1eS0RERMRU07Im7lvANiMLJa0JPB/4U1/ZhsDOwEb1OV+RNKPefTCwB7B+vfS2uTtwm+3HAp8HPtnkVURERERMQc2SONtnAH8f5a7PA+8D3Fe2HXCU7bttXwtcDWwhaVVgRdtn2zZwBLB933MOr9ePBZ7bq6WLiIiImO467RMn6WXAn21fPOKu1YHr+27fUMtWr9dHls/1HNv3Af8EHtFgtyMiIiKmnCW7CiRpOeADwAtGu3uUMo9TPt5zRou9B6VJlrXWWmu++xoREREx1XVZE7cesC5wsaTrgDWACyQ9mlLDtmbfY9cAbqzla4xSTv9zJC0JrMTozbfYPsT25rY3nzlz5sBeUERERMRk6SyJs32p7UfaXsf2OpQk7Cm2/wKcAOxcR5yuSxnAcJ7tm4DZkras/d12BY6vmzwB2K1e3wH4Ze03FxERETHttZxi5EjgbOBxkm6QtPtYj7V9OXAMcAVwMrCn7fvr3W8FvkEZ7PAH4KRafijwCElXA+8B9mnyQiIiIiKmoGZ94mzvMp/71xlx+wDggFEeNwvYeJTyu4AdF20vIyIiIoZTVmyIiIiIGEJJ4iIiIiKGUJK4iIiIiCGUJC4iIiJiCCWJi4iIiBhCSeIiIiIihlCSuIiIiIghlCQuIiIiYggliYuIiIgYQkniIiIiIoZQkriIiIiIIZQkLiIiImIIJYmLiIiIGEJJ4iIiIiKGUJK4iIiIiCGUJC4iIiJiCCWJi4iIiBhCSeIiIiIihlCSuIiIiIghlCQuIiIiYggliYuIiIgYQkniIiIiIoZQkriIiIiIIdQsiZP0TUk3S7qsr+zTkq6UdImkH0p6WN99+0q6WtJVkl7YV76ZpEvrfV+UpFq+tKSja/m5ktZp9VoiIiIippqWNXHfArYZUfZzYGPbmwD/B+wLIGlDYGdgo/qcr0iaUZ9zMLAHsH699La5O3Cb7ccCnwc+2eyVREREREwxzZI422cAfx9Rdort++rNc4A16vXtgKNs3237WuBqYAtJqwIr2j7btoEjgO37nnN4vX4s8NxeLV1ERETEdDeZfeLeCJxUr68OXN933w21bPV6fWT5XM+pieE/gUeMFkjSHpJmSZp1yy23DOwFREREREyWSUniJH0AuA/4bq9olId5nPLxnjNvoX2I7c1tbz5z5swF3d2IiIiIKafzJE7SbsBLgNfUJlIoNWxr9j1sDeDGWr7GKOVzPUfSksBKjGi+jYiIiJiuOk3iJG0D7A28zPa/++46Adi5jjhdlzKA4TzbNwGzJW1Z+7vtChzf95zd6vUdgF/2JYURERER09qSrTYs6UjgWcAqkm4APkIZjbo08PM6BuEc22+xfbmkY4ArKM2se9q+v27qrZSRrstS+tD1+tEdCnxb0tWUGridW72WiIiIiKmmWRJne5dRig8d5/EHAAeMUj4L2HiU8ruAHRdlHyMiIiKGVVZsiIiIiBhCSeIiIiIihlCSuIiIiIghlCQuIiIiYggliYuIiIgYQkniIiIiIobQAiVxkh4uaZNWOxMREREREzPfJE7SaZJWlLQycDFwmKTPtd+1iIiIiBjLRGriVrJ9O/AK4DDbmwHPa7tbERERETGeiSRxS0paFXgV8OPG+xMREREREzCRJO6jwM+Aq23/VtJjgN+33a2IiIiIGM+4a6dKmgGsafvBwQy2rwFe2XrHIiIiImJs49bE2b4feFlH+xIREREREzRuTVx1lqQvA0cDd/QKbV/QbK8iIiIiYlwTSeK2qn/37ysz8JzB705ERERETMR8kzjbz+5iRyIiIiJi4iYy2e9Kkj4naVa9fFbSSl3sXERERESMbiJTjHwTmE2ZJ+5VwO3AYS13KiIiIiLGN5E+cevZ7p9S5KOSLmq0PxERERExAROpibtT0ta9G5KeAdzZbpciIiIiYn4mUhP3FuCIvn5wtwG7tduliIiIiJifiSRxt9t+kqQVAWzfLmndxvsVEREREeOYSHPqcVCSN9u317Jj2+1SRERERMzPmEmcpMdLeiWwkqRX9F1eDywzvw1L+qakmyVd1le2sqSfS/p9/fvwvvv2lXS1pKskvbCvfDNJl9b7vihJtXxpSUfX8nMlrbNw/4KIiIiI4TNec+rjgJcADwNe2lc+G3jTBLb9LeDLwBF9ZfsAp9o+UNI+9fbekjYEdgY2AlYDfiFpg7p268HAHsA5wE+BbYCTgN2B22w/VtLOwCeBnSawX1PGOvv8ZKGed92B2w5FvIiIiGhnzCTO9vHA8ZKebvvsBd2w7TNGqR3bDnhWvX44cBqwdy0/yvbdwLWSrga2kHQdsGIvvqQjgO0pSdx2wH51W8cCX5Yk217QfY2IiIgYNhPpE/cWSQ/r3ZD0cEnfXMh4j7J9E0D9+8havjpwfd/jbqhlq9frI8vneo7t+4B/Ao8YLaikPXorTtxyyy0LuesRERERU8dEkrhNbP+jd8P2bcCTB7wfGqXM45SP95x5C+1DbG9ue/OZM2cu5C5GRERETB0TSeKWGDEAYWUmNjXJaP4qadW6nVWBm2v5DcCafY9bA7ixlq8xSvlcz5G0JLAS8PeF3K+IiIiIoTKRJO6zwFmSPibpY8BZwKcWMt4JzJkoeDfg+L7yneuI03WB9YHzapPrbElb1lGpu454Tm9bOwC/TH+4iIiIWFzMt0bN9hGSzgeeTWnCfIXtK+b3PElHUgYxrCLpBuAjwIHAMZJ2B/4E7FhjXC7pGOAK4D5gzzoyFeCtlJGuy1IGNJxUyw8Fvl0HQfydMro1IiIiYrEwoWbRmmTdQp0fTtJatv80n+fsMsZdzx3j8QcAB4xSPgvYeJTyu6hJYERERMTiZr7NqZJeJun3wLXA6cB1zKkNi4iIiIhJMJE+cR8DtgT+z/a6lJq03zTdq4iIiIgY10SSuHtt/40ySnUJ278CNm27WxERERExnon0ifuHpOWBM4DvSrqZMvggIiIiIibJRGritgP+DbwbOBn4A3OvpRoRERERHZvIFCN31KsPUNY7jYiIiIhJNpGauIiIiIiYYpLERURERAyhMZM4SafWv5/sbnciIiIiYiLG6xO3qqT/BF4m6SjKklsPsn1B0z2LiIiIiDGNl8R9GNgHWAP43Ij7DDyn1U5FRERExPjGTOJsHwscK+lDtj/W4T5FRERExHxMZIqRj0l6GfDMWnSa7R+33a2IiIiIGM98R6dK+gSwF3BFvexVyyIiIiJikkxk2a1tgU1tPwAg6XDgQmDfljsWEREREWOb6DxxD+u7vlKD/YiIiIiIBTCRmrhPABdK+hVlmpFnklq4iIiIiEk1kYENR0o6DXgqJYnb2/ZfWu9YRERERIxtIjVx2L4JOKHxvkRERETEBGXt1IiIiIghlCQuIiIiYgiNm8RJWkLSZV3tTERERERMzLhJXJ0b7mJJaw0yqKR3S7pc0mWSjpS0jKSVJf1c0u/r34f3PX5fSVdLukrSC/vKN5N0ab3vi5I0yP2MiIiImKom0py6KnC5pFMlndC7LGxASasD7wQ2t70xMAPYGdgHONX2+sCp9TaSNqz3bwRsA3xF0oy6uYOBPYD162Wbhd2viIiIiGEykdGpH20Ud1lJ9wLLATdS5p57Vr3/cOA0YG9gO+Ao23cD10q6GthC0nXAirbPBpB0BLA9cFKD/Y2IiIiYUuZbE2f7dOA6YKl6/bfABQsb0Pafgc8AfwJuAv5p+xTgUXUqk96UJo+sT1kduL5vEzfUstXr9ZHlEREREdPefJM4SW8CjgW+VotWB360sAFrX7ftgHWB1YCHSnrteE8ZpczjlI8Wcw9JsyTNuuWWWxZ0lyMiIiKmnIn0idsTeAZwO4Dt3zOnlmxhPA+41vYttu8FfgBsBfxV0qoA9e/N9fE3AGv2PX8NSvPrDfX6yPJ52D7E9ua2N585c+Yi7HpERETE1DCRJO5u2/f0bkhakjFqvCboT8CWkparo0mfC/yOsiLEbvUxuwHH1+snADtLWlrSupQBDOfVJtfZkras29m17zkRERER09pEBjacLun9lIEIzwfeBpy4sAFtnyvpWEq/uvuAC4FDgOWBYyTtTkn0dqyPv1zSMcAV9fF72r6/bu6twLeAZSkDGjKoISIiIhYLE0ni9gF2By4F3gz8FPjGogS1/RHgIyOK76bUyo32+AOAA0YpnwVsvCj7EhERETGM5pvE2X5A0uHAuZRm1KtsL0pzakREREQsovkmcZK2Bb4K/IEyInRdSW+2nabLiIiIiEkykebUzwLPtn01gKT1gJ+Q/mcRERERk2Yio1Nv7iVw1TXMmf4jIiIiIibBmDVxkl5Rr14u6afAMZQ+cTtSVm2IiIiIiEkyXnPqS/uu/xX4z3r9FuDhzfYoIiIiIuZrzCTO9hu63JGIiIiImLiJjE5dF3gHsE7/422/rN1uRURERMR4JjI69UfAoZRVGh5oujcRERERMSETSeLusv3F5nsSERERERM2kSTuIEkfAU6hLI0FgO0Lmu1VRERERIxrIkncE4HXAc9hTnOq6+2IiIiImAQTSeJeDjzG9j2tdyYiIiIiJmYiKzZcDDys8X5ERERExAKYSE3co4ArJf2WufvEZYqRiIiIiEkykSTuI833IiIiIiIWyHyTONund7EjERERETFxE1mxYTZlNCrAQ4ClgDtsr9hyxyIiIiJibBOpiVuh/7ak7YEtWu1QRERERMzfREanzsX2j8gccRERERGTaiLNqa/ou7kEsDlzmlcjIiIiYhJMZHTqS/uu3wdcB2zXZG8iIiIiYkIm0ifuDV3sSERERERM3JhJnKQPj/M82/7YwgaV9DDgG8DGlKbZNwJXAUcD61Bq+15l+7b6+H2B3YH7gXfa/lkt3wz4FrAs8FNgL9tp6o2IiIhpb7yauDtGKXsoJZl6BLDQSRxwEHCy7R0kPQRYDng/cKrtAyXtA+wD7C1pQ2BnYCNgNeAXkjawfT9wMLAHcA4lidsGOGkR9isGaJ19frJQz7vuwG0HvCcRERHTz5hJnO3P9q5LWgHYC3gDcBTw2bGeNz+SVgSeCby+xrkHuEfSdsCz6sMOB04D9qb0vzvK9t3AtZKuBraQdB2wou2z63aPALYnSVxEREQsBsadYkTSypI+DlxCSfieYntv2zcvQszHALcAh0m6UNI3JD0UeJTtmwDq30fWx68OXN/3/Btq2er1+sjy0V7HHpJmSZp1yy23LMKuR0REREwNYyZxkj4N/BaYDTzR9n69PmqLaEngKcDBtp9MabbdZ5zHa5Qyj1M+b6F9iO3NbW8+c+bMBd3fiIiIiClnvJq491L6oH0QuFHS7fUyW9LtixDzBuAG2+fW28dSkrq/SloVoP69ue/xa/Y9fw3gxlq+xijlEREREdPemEmc7SVsL2t7Bdsr9l1WWJR1U23/Bbhe0uNq0XOBK4ATgN1q2W7A8fX6CcDOkpaWtC6wPnBebXKdLWlLSQJ27XtORERExLQ2kcl+W3gH8N06MvUayoCJJYBjJO0O/AnYEcD25ZKOoSR69wF71pGpAG9lzhQjJ5FBDREREbGYmJQkzvZFlOW7RnruGI8/ADhglPJZlLnmIiIiIhYr445OjYiIiIipKUlcRERExBBKEhcRERExhJLERURERAyhJHERERERQyhJXERERMQQShIXERERMYSSxEVEREQMoSRxEREREUMoSVxERETEEEoSFxERETGEksRFREREDKEkcRERERFDKElcRERExBBKEhcRERExhJLERURERAyhJHERERERQyhJXERERMQQShIXERERMYSSxEVEREQMoSRxEREREUMoSVxERETEEEoSFxERETGEJi2JkzRD0oWSflxvryzp55J+X/8+vO+x+0q6WtJVkl7YV76ZpEvrfV+UpMl4LRERERFdm8yauL2A3/Xd3gc41fb6wKn1NpI2BHYGNgK2Ab4iaUZ9zsHAHsD69bJNN7seERERMbkmJYmTtAawLfCNvuLtgMPr9cOB7fvKj7J9t+1rgauBLSStCqxo+2zbBo7oe05ERETEtDZZNXFfAN4HPNBX9ijbNwHUv4+s5asD1/c97oZatnq9PrJ8HpL2kDRL0qxbbrllIC8gIiIiYjJ1nsRJeglws+3zJ/qUUco8Tvm8hfYhtje3vfnMmTMnGDYiIiJi6lpyEmI+A3iZpBcDywArSvoO8FdJq9q+qTaV3lwffwOwZt/z1wBurOVrjFIei6l19vnJQj3vugO3HfCeREREtNd5TZztfW2vYXsdyoCFX9p+LXACsFt92G7A8fX6CcDOkpaWtC5lAMN5tcl1tqQt66jUXfueExERETGtTUZN3FgOBI6RtDvwJ2BHANuXSzoGuAK4D9jT9v31OW8FvgUsC5xULxERERHT3qQmcbZPA06r1/8GPHeMxx0AHDBK+Sxg43Z7GBERETE1ZcWGiIiIiCGUJC4iIiJiCCWJi4iIiBhCSeIiIiIihlCSuIiIiIghlCQuIiIiYggliYuIiIgYQkniIiIiIoZQkriIiIiIIZQkLiIiImIIJYmLiIiIGEKTunZqxDBbZ5+fLNTzrjtw2wHvSURELI5SExcRERExhJLERURERAyhJHERERERQyhJXERERMQQShIXERERMYSSxEVEREQMoSRxEREREUMoSVxERETEEEoSFxERETGEksRFREREDKHOl92StCZwBPBo4AHgENsHSVoZOBpYB7gOeJXt2+pz9gV2B+4H3mn7Z7V8M+BbwLLAT4G9bLvL1xPRha6X+MqSYhERU99k1MTdB7zX9hOALYE9JW0I7AOcant94NR6m3rfzsBGwDbAVyTNqNs6GNgDWL9etunyhURERERMls6TONs32b6gXp8N/A5YHdgOOLw+7HBg+3p9O+Ao23fbvha4GthC0qrAirbPrrVvR/Q9JyIiImJam9Q+cZLWAZ4MnAs8yvZNUBI94JH1YasD1/c97YZatnq9PrI8IiIiYtqbtCRO0vLAccC7bN8+3kNHKfM45aPF2kPSLEmzbrnllgXf2YiIiIgpZlKSOElLURK479r+QS3+a20ipf69uZbfAKzZ9/Q1gBtr+RqjlM/D9iG2N7e9+cyZMwf3QiIiIiImSedJnCQBhwK/s/25vrtOAHar13cDju8r31nS0pLWpQxgOK82uc6WtGXd5q59z4mIiIiY1jqfYgR4BvA64FJJF9Wy9wMHAsdI2h34E7AjgO3LJR0DXEEZ2bqn7fvr897KnClGTqqXiIiIiGmv8yTO9q8ZvT8bwHPHeM4BwAGjlM8CNh7c3kVEREQMh6zYEBERETGEJqM5NSJiLlkhIiJiwaUmLiIiImIIJYmLiIiIGEJJ4iIiIiKGUPrERcRiJ33wImI6SBIXEdFYksaIaCFJXETENJOkMWLxkCQuIiIWSddJY5LUiCIDGyIiIiKGUJK4iIiIiCGU5tSIiIhxpLk4pqokcREREYupJKjDLUlcRERETEvTPUlNn7iIiIiIIZQkLiIiImIIJYmLiIiIGEJJ4iIiIiKGUJK4iIiIiCGUJC4iIiJiCCWJi4iIiBhCSeIiIiIihlCSuIiIiIghNPRJnKRtJF0l6WpJ+0z2/kRERER0YaiTOEkzgP8FXgRsCOwiacPJ3auIiIiI9oY6iQO2AK62fY3te4CjgO0meZ8iIiIimpPtyd6HhSZpB2Ab2/9Vb78OeJrtt4943B7AHvXm44CrFiLcKsCti7C7iZd40yFW4iVe4i0+8abzaxumeGvbnjnaHUsu2v5MOo1SNk9WavsQ4JBFCiTNsr35omwj8RJv2GMlXuIl3uITbzq/tukSb9ibU28A1uy7vQZw4yTtS0RERERnhj2J+y2wvqR1JT0E2Bk4YZL3KSIiIqK5oW5OtX2fpLcDPwNmAN+0fXmjcIvUHJt4iTdNYiVe4iXe4hNvOr+2aRFvqAc2RERERCyuhr05NSIiImKxlCQuIiIiYggliYuIiIgYQknipghJz5D00Hr9tZI+J2ntRrEeJelQSSfV2xtK2r1FrL6Yqq/rw/X2WpK2aBjvU5JWlLSUpFMl3SrptQ3jdXn89qqvTfU4XiDpBS1iTQZJy0n6kKSv19vrS3rJZO9XBHR//klaT9LS9fqzJL1T0sNaxetSl5+bNcZkfPetLel59fqyklYY5PaTxI1D0o69f7ikD0r6gaSnNAp3MPBvSU8C3gf8ETiiUaxvUUb0rlZv/x/wrkaxer4CPB3Ypd6eTVn3tpUX2L4deAllPsENgP9pGK/L4/fG+tpeAMwE3gAc2ChW74P255L+T9I1kq6VdE2reMBhwN2U9wuU4/fxhvEAkLSVpFdL2rV3aRireSIgabak20e5zJZ0+yBjjRK7k8RD0vvq3y9J+uLIy6DjVZ2ef8BxwP2SHgscCqwLfK9VsGn8vQcdf/dJehNwLPC1WrQG8KNBxkgSN74P2Z4taWvghcDhlDddC/e5DBXeDjjI9kHAQDP2PqvYPgZ4AMpULcD9jWL1PM32nsBdNeZtwEMaxluq/n0xcKTtvzeMBd0ev95KJS8GDrN9cV9ZC4cCnwO2Bp4KbF7/trKe7U8B9wLYvpO2rw9J3wY+w5zX2HudrTRPBGyvYHvFUS4r2F5xkLFG0VXi8bv6dxZw/iiXFro+/x6on9EvB75g+93Aqg3jTdfvPej+u29P4BnA7TXe74FHDjLAUM8T14Hewd0WONj28ZL2axRrtqR9gdcCz5Q0gzmJyKDdIekR1CXKJG0J/LNRrJ5762vqxZxJPZEaOVHSlcCdwNtqvLsaxuvy+J0v6RTKF+O+9Vdzy//lP22f1HD7I90jaVnmvFfWo9TMtbQ5sKG7m3NpnkRA0kATAUkr2r5d0sqj3d/4h80DdR7PXuLxJUkXDjqI7RPr38MHve1xdH3+3StpF2A34KW1rNVnC0zf7z3o/rvvbtv39E5tSUsyytKgiyJJ3Pj+LOlrwPOAT9bmgVa1lzsBrwZ2t/0XSWsBn24U6z2UlS3Wk/QbSk3ADo1i9XwR+CHwSEkH1HgfbBXM9j6SPgncbvt+SXdQfu210uXx2x3YFLjG9r/rh9IbGsUC+JWkTwM/oC+Zsn1Bo3gfAU4G1pT0Xcov2dc3itVzGfBo4KbGcXq6SAS+R+lOcD7li6M/STTwmAHH69dJ4iHpRMb5UrT9skHHpPvz7w3AW4ADbF8raV3gOw3jTdfvPej+u+90Se8HlpX0fOBtwImDDJDJfschaTlgG+BS27+XtCrwRNunTPKuLbL6i+BxlA/2q2zf20HMxwPPrTFPtf27+TxlUeNtBaxD348V2y37W3RG0urA2sz92s5oFOtXoxTb9nNaxKsxHwFsSXmvnGP71kZxeknACpQv5vOYO1FtkQQgaQnmJAL/qK93dduXtIjXNUkbUhKPs20fWROPnWwPtMlY0n+Od7/t0wcZry9uZ+df17r83pP0RuDM2szYiS6/++p5vjul24Qo/fG+Mcga/yRx81Grdx/F3CfrnxrEeQXwSUp7uerFg+y7UmOMyfYPBhWrL+aoTTl9MZs06dQ+TusBFzGnecC239koXvPj1xfrk5RfsFcw92trknB0ZX6dp1vU/E1WElBjd5mIb8K8P2gGfr4vDro+/yQ9A9iPOe+V3mdLs5rU2h9ufduH1a4oy9u+tkGc/Sn9UNem1BifCZxR+xkOMk7n331dSRI3DknvoDTt/JU5TR22vUmDWFcDL21ZOyXpsHHutu03Noh5LfM25fTHbPJBJOl3dNjHqYvj1xfrKmAT2637ifXH3BbYCFimV2Z7/wHHGK3Gry9c05q/dYGbbN9Vby8LPMr2dY3idZYISPomsAlwOXN/jrU434+x/SpJlzJ3M2cv8Rj4Z2eNuz7wCWBD5n6PDvzzpevzr/btfTclyXmwE77tvzWK9xFKH9HH2d5A0mrA920/o0W8GnNZ4E3Af1NqpGcMePudfveN8v4fGXBg50H6xI1vL8obucnJMsJfWycAtlv22xgr5rpdx6y67uPU/Pj1uYbSv6irL5GvAssBzwa+QelDct6g49h+9qC3uQC+D2zVd/v+WtZqFO72lM+WLo7hlrY37CAOlM9MKH3xunQY5Qf35ynv0zfQbsRop+cf3Q8sejnwZOACANs3asBzm/VI+iClz+vywIWUJO7MQceZhO++zt7/SeLGdz3tR232zJJ0NGUOmf4+OS2aOB9B+cDbmvJr4dfA/q2T1Vql3Yt5pu0fNQy3CnCFpE76ONHh8QP+DVwk6dQRsZo0FQNb2d5E0iW2Pyrps5RBDk1IWobSAfjB9wrw1V4tWSNL2r6nd6OOKGs5BU6XicDZkja0fUXrQLZvqn//KOnRwBaUY/hb239pGHpZ26dKku0/AvtJOpPyOTdoXZ9/XQ8suse2JfVGcD60URyAVwD3AT8BTqf0f212nnf13Vffg72YTc+DJHHjuwY4TdJPmPvk+VyDWCtSPhz6J/w0bb4sjwLOAF5Zb78GOJoyGqkJSV8BHgscWYveIun5LnPHtbBfo+2Opcvjd0K9dOXO+vfftWnlb5RRla0cQZkM+kv19i7At4EdG8a8RdLLbJ8AIGk7oMlgiqrLROBwSiL3lxqradMmgKT/Aj4M/LLG+5Kk/W1/s1HIu2on8t9LejvwZwY8H1efrs+/p9W//fMWGmjVveCYOjr1YSqT1b4R+HqLQLafUmv5tgaeD3xd0l9tb90iHh1/93VxHqRP3Dhq34B52P5o1/sySJLOt73ZiLJZtptNbirpcmDjXh+1+oF7qe2NWsWMwZD0IUpC9VzKKhumjLD6UKN4F9t+0vzKBhxzPeC7lJncRamF39X21Y3i7TZauRvMd1b7a74HuJS+aUz6awsaxLyKUoP7t3r7EcBZth/XKN5TKRP/Pgz4GOVH1adtn9Mi3nRXp8N4cESl7Z83irMx8B/Af1KS1OsprTQfbhSv0+++Ls6D1MSNo8tkrTYh7c68nccH3vmYUj2/M3BMvb0DpTq7pauAtSjLqgCsCTSbTkFlEscvAU+grAwxA7ijxWjRGq+z49dlJ+663Y/Vq8dJ+jGwjO2W3QwulLRl7wtY0tOA3zSMh+0/AFtKWp7y43Z243hdTk77p14NY4duoNSm9symfEG3cqftfwH/ou2cbZ2ffzVm84FF/WrS1iRxG+GTlJqxL1KaGltPddX1d1/z8yA1ceOoQ6vfx7wnz8CrsSV9H7iSMvHh/pRq3t/Z3mvcJy5crNnAQ5nzq3wJ4I563S0SHUmnUzqJ9zrEPxU4m9KsNPC+apJmATtTOqdvDuxKGTL//kHG6YvX5fH7NXM6cb+U2onbdov+P0jaE/iu7X/U2w8HdrH9lUbxfkeZx6k3lc9alFqWB2g3OnxpShPLOsw9DUeTL8qOR1N+hVJDdSLt+9u+p17dFHgicDyl5nY74Dzbbxl0zBr315Qfa98Cvtd7rzaM1eX5N+rAItsDXbi9fi+MN6Ky1Q/gZYG1bF/VYvsjYnX63SfpCEY5Dyhrtg6ka1aSuHGozKh+NGXEzFsos4/fYnvvBrEutP3k2nl8E0lLUaqxm02r0CV1PB9Xr4q89/+sZWfZ3mp+z13IeJ0dv16TgKRLbT+xlp1p+z8GHatu+yLbm44ou9D2kxvFW3u8+1s0A0o6mTKIaeQ0Dp8ddKwar7NEYIzpFdyolnjc/W/ZulET4zdS+k7+Fvhmi2bASTj/ep8pvb/LAz+w/YL5Pnnh4u0P/IXSD1WUH6QruKxnPOhYL6WsWfwQ2+tK2pQy0GCo57zs6eJ8SHPq+B5h+1BJe9Uk4/Rao9RCrxr5H7WfwF8otQJNSHoZ8Mx68zTbP24VC0qSJulRzJmy4TzbNzcM+e86uvAiSZ+iTDXScpRVl8evy07cAEvUUX+9/owzKLUeTbiMbHwSpa8MlD4yA538cxRr2N6mcYx+nY2mdIfTK0xmf2GX1QU+CMyiNM9tKknA+wdc69j1+df1wKIX2n5a3+2DJZ0LDDyJowxA2wI4DcD2RZLWaRDnQV1+9/XOhzp4w7XJf6BarYc2XfS+mG+StK2kJwNrNIp1SG2m+iBl5NMVtDlpkHQgZT6nK+plr1rWjKRXUaqRdwReBZwrqeWada+jvL/fTqkuX5M5I5Ja6Oz4Ae+iNK+8E9iMsnj0qB3lB+RnlBFrz5X0HMoI45NbBZO0F2WQwSPr5TsqE2+3dJakJzaO0W+uREBlofgmiYCkZSTtKekrkr7Zu7SI1RdzpqRPS/qppF/2Lg3jbSLp85Rm9+dQJt5+Qr3++QGHexfdnn8/lvQwypqiFwDXUUZZtnK/pNdImiFpCUmvoa92esDua9y/di5df/dJ2ljShZR5Sy+XdL6kgQ7mS3PqOCS9hDJH1ZqUTvIrAh+dhE7CAyXpEmBT2w/U2zOAC1v0NeqLeTHw/F7tm0p/w1+0GnGoMrfRnSNe49K2/90i3nRWk403M2fd21Moo1ObfLDX9+fTbd9Rbz+UsgZny/fnFZQpcK6lg2k4NO9oypWAT7UYTakO+2v2xeysK0qNdwZlGoxjbd854r7X2f52i7hdU+m72XRgUa0JO4gyCa8pg4re5Qarl0g6FDgV2IfyI/udwFIN+052+t0n6SzgA7Z/VW8/C/h/A+3WYzuXKXAB/h/wsL7bDwc+3ijWJcDKfbdXBi5p/PouHXF7iZFlA453DmW9v97t5SlDu6fD8fv5KLF+1vL4dXmhTIWxTN/tZVq+V2qMtUe7TPb/YhFf05L174X17yX171LALxvHPr8/Zr1++mT/Twb02jo9/4A9R4n3tsn+PwzotS0HHEDpwzirXl+mYbxOv/uAiydStiiX9IkbhaT32f6UpC8xymgdt5mQ80XuGzlp+zZJL6Y0zw3aJyjTOPyKUuPwTGDfBnH6nSzpZ8yZ7HcnoOVSMsu4r/+B7X9JWq5hvC6P3yruG31XYw28KU5jr4PZi9uqZuwwSnP7D+vt7YFDG8UCHuyHN8+i34OOI+kLtt8l6URG/58OskP3ecBT6Li/bTVXVxTgRtp1Rel62o9Ozr8+b7L9vyPivQloNTp8A+BgytrBG0vaBHiZ7Y8POpZLy8gH6qULXX/3XaMyz2avJvi1lNr+gUkSN7reGpizOow5Q9LSrmspqgy7XrpFINtHSjqNMshAwN5uuyQOtv9Hc5bdEnCI7R/O52mL4g5JT3FdmkbSZszpINxCZ8cPeEDSWrb/VGOtzThTAyyCSVkH0/bn6vuz9155g+0LW8ZU36LflCRyKeA7lCalQep9mH9mwNsdz8j+mssDTSZq7vNxSSsB72VOV5R3N4zX5dqpXZ1/PZ0OLKI0S/8P8DUA25dI+h4wsCRurB8x1d3AH4D/tT3QOdUm4bvvjcBHmbNyzxkMeB7D9ImbIiS9D3gZ5cPIlIN/gtsM6+4NG3+M7f0lrQU82vbAFzUfEXdtSk3HL2qt2Aw3mlS19jk6ilIDALAqsJPt8xvF6/L4bQMcQllrEMqvyT1s/6xBrBmUpqJmS7KNEXeeWjHbA/0FOyLeRdRFv12nTlHf9DTDSNINwMh5qHqJjd1m+cBJoQ6n/ejy/KvxPk2pOf0q5bPlLcD1tt/bKN5vbT9VfdMIaZRphhYxxnhTTi1JmZt1F9tPH1TMGneyvvuWd4ORqZCauFHN51fCoJs8etv8VG226nUe/1irDwVKNfwDlJFb+1NmkT6OOdN/DFyt/t+D0gdhPWB1yofSc1vEs/1bSY+n1KwIuNINZwPv8vjZPlnSU4Ata6x3226yzqft+yX9W9JK7mgUWYe1Yv06WfR7rKbpngEnjTMotW6j1Ug1+fU+n64oBv4OfMdlhYxB6mzajy7Pv2pvysCit9I3sKhhvFtVlqHrnQs7UKZoGhjPf17QU2sz7qB1+t0naSvKsVoeWEtl6qQ3237bwGKkJm5efb8SXgE8mvIFAmUh7uvcaNb/rki6wGXh4f5fWq3XpryIMh/QuX0xH/zVPMA4z7H9y9p0Ow83mKW+K5Ieb/vK+gUyj17TcYO4x1C+sH7OnNnNW/UNnZRaMUn/DaxPWYT7E5Sa1O/Z/tKA43Q2kXHvPB/U9iYY86W2T9QYa8MCjwB2G/RnTRejfSfr/OuapMdQahq3Am6j9OF6zSDfm5Ol6+8+lfn1dqC0yvTiXWZ740HFSE3cKHq/EiR9zPYz++46UWUo+8BI+rXtrTXvkie9KQ5aLHVyb20m6/3SmknfwtiN3G37nlKbDZKWpE1twH8Cv6TMgj+SmdM3YSA6Pn7vodRmjraKgCm/Llv4Ce3X1u3XSa1YT21iORp4PHA7pQbww24w23/HX4St+oSNyfaJ9e+Ya8NKumOs+xYh7m/r1ZZrp3Z6/mmSBhbZvgZ4Xj3vlmjV5WWSdP7dZ/v63vdeNdCpmVITNw6VNRy3rW9qJK0L/NRlEsmhpTJ5406UiSq/Rfml8EHb328Y81PAPyhrmL4DeBtwhe2Bj0qqzSo72D5mvg8eMvW1Pd120wXhR4nb5fqGndSKjYh5vu3NWm1/lHhbUjr8P4HSSX0GcMcgk35JK9v++6C2t4CxN6DMEbcOc69FO+hEp9OuL12ef5JWtX3TWLW3rX4QSPoDZYqmM4EzbF/RIs5k6Pq7T9KxlH6pX6a0ZrwT2Nz2zgOLkSRubH0dWK+pRetQ2rMH2tepfjBcMsgq1gnEfDxz+qP90vbvxnv8AOItAewOvIBSQ/AzyoSxrfrmnDGiFrWZro+fpLMH3eF3PvE6X99Q0vMp7xWAU1rUio2I97/At/pqdJqSNAvYGfg+pf/frsBjW/yomQwqk3t/lXnXoh3owKL5dJCfSN+rhYnZ2fk3GQOLVCYUfhpl2btnUGqoL7b98gaxNqCMhF2bhsn+iJidffdJWoUycfLzKHOj/gzYy/bfBhUjzanjqB1Y16e8iaF0jr+7QZwHJF2svmHrHViO8uvfwLKtg9XXeDhwbo15VasErvp5rdE5mrn7cQ28ZmISjt8pkl5JWQS7i19h+zHv+oYt126EMuHvspT3yqWNY0GZluItkq6jvF+arthA2fjVkma4rHxxmMrs7tPFfbYPbh2kRZI2AZ2df5MxsIiSdN9b/z4A/BVotc719ynJ/tdpt7TXSJ1999UBL69pGSNJ3PxtxpwmgSdJwvYRDeKsSllb7TzmTjoGXtsh6cOUNUyPo3xZHSbp+24wmWNfzG0pJ+sfasx1Jb3ZdqsJf99Y/+7ZV2agxeSf0OHxo/TNeShljcM7adt/Eur6hiP6dTT78pL0X8CHKX0bBXxJ0v62B77eZ1/i/aJBb3s+/i3pIcBFtavBTZRjOl2cKOltwA8p834BbX5EAV1P9tv1+XcXcKmkTgYWUfqFXkppBvz6IGuNRtFJst/T9XdfHSRyEKUp1cDZlNHM14z7xAWJkebUsUn6NmU6jIuY8yvBLU6esZoFGjUH/A54su276u1lKSMBm/X1k3Ql8BLbV9fb6wE/sf348Z85HLo8fl1T9+sbXgVs1fvykPQIypJpj2sQ68ERnJKOs/3KQccYI+7alBqOh1AmwV2JMrnpoKfemBSSRpvTz42SKiT9mjmT/b6UOtmv7Y+0iNelsUb6jjd4ZBHjbUeZaHsL4B7gLErfuFMbxNqPUsvXVbLf6XefpHOA/2XOSkU7A++w/bRBxUhN3Pg2BzbsosnK9ukaZTLcRuGuo/xavaveXppSQ9bSzb0ErrqGdlX01P/feyid8feov9QfZ/vHLeJ1efzqaMrXAOva/pikNYFV3W7CyndQlsW5m/Jh9DPKNA6t3ECZv6lnNjDQmdv79FcvtqqlHc32tg+inIMfBZC0F+VX+9Cz3bq5faRlbZ8qSbXD/36SzqQkdgPV9fln+/AuBxbZPh44vvYdexHwLuB9tGl67CWo/9O/C7Q7F6+j2+8+2f523+3vqMxjONAAg9zetCLp+8A7bQ90osMxYj04Ga7t9WrS8VXbA58MV9KPKJMb/pxywjwf+DU1qWpU03gwpfPqMTXmjsBVwG9qzEFP/XE0pVP1ri7r/y0LnO0Bzjo+Il6Xx+9g6oSVtp+gsqTSKbabTdbcJUlHAE8Ejqe8V7ajrAP6f1CW5RpgrP6auM7mVRstlvrmrhp2knYdrbxRVxQk/YbSEf9YSjP8n4EDG9Xednr+dT2wSNJxwKbA1dQRqsB5vdqrYdb1d5+kAymzMhxV4+1ESRz/t8Zb5BrH1MSNbxXgitrPqb+qt8XJsyd1Mtwa4/dqt6jyD+ul57RGcfotQ2k+6jU73kJZveGlNJi/DVjP9k6SdgGwfadGdOoasC6P39NcJ6yssW6r/auakLQ58H7mnS6iVaf/PzD3r+Pj698VGsR6kqTbKTVyy9br0KifU30/vprSJ/SEvrtWAFr2Pepaf0KzDGU04AVAkySOUlu0HKWp/2OUOdvGmnB4UXV6/tHRwCKVCZOvBw6kHKvXUrpPPBK4jDm1V4OOuzHz9mVs9T7p+rtvp/r3zSPK38iAahyTxI1vvw5jdTUZbrO+FPOJ2WoCzrHcU2vfepM6rkdfIt5AZ8eP7ies/C6luePSxnEAsP3R1jH6YrXqsjCWsyiDGFZh7kljZwOXdLwvzdh+R/9tSSsB3x7j4YOI18Vkvz1dn39dDSz6GvA8lyULn0kZKPIOSq3cIZQ51QZKZYm9Z1GSuJ9Smm9/TaNkv+vvvi66FSSJG0fHndJPl/R+Sm3A8ymT4Z7YYfzp5iPAycCakr5Lme/o9Q3jdXn8vkj5NflISQdQJ6xsFAvgFtsnzP9hMT+1v9Yfgc7m+Zsi/k2ZwHmgRtRmzqNRq0nX599lkl4NzKjdNN5J+TEwaDP6mvd2Ag6xfRxwnMpSeC3sADwJuND2GyQ9irbrwk476RM3Cs27hNKDd9FoKLk6ngx3cVBHNfYWqT7HDRep7vr4ac6ElQJOddsJK59LWTf4VObuVjC069BOlsn4bJkMmnslhSUoNS3H2N5nwHFuoTQBHknpyjB3dVWjH+Idn3/LUQYW9X+2fGzQfdQkXQZsavu+OpvAHrbP6N3nBpOZSzrP9haSzqfM1TgbuMz2RoOONV0liYtpS9ImzNuPa1okHrUz9ZrM/dqaLMAt6TuUCa8vZ06zkW2/cexnxeJMc0+5cx/wR9s3NIgzg9I5fRdgE8oav0favnzQsUbE7ez864qkDwAvBm4F1gKeYtuSHgscbvsZDWJ+hdLfdmfgvZTm8IsmofvN0EoSN0VIegmlQ25v+ZGWtX6TsdTJ0pROsuuMiLl/o3jfpHyod5J4dHz8PkZpGv4Dc2o73Or4SbrU9hNbbHuMeDOBNzHveyVJ4xQnaRngLcBjKX0oD7V9X0exl6Ykc5+mjN5sstbuJJx/nQ0sUlnTd1XKaNs7atkGwPKtk1RJ6wAr2h5431BJX7D9Lo2x1u6gm90lPd72lZJGHe0+yP9lkrgpQtLVwCuAS1s3oaqjdQ1HxDwZ+OcoMT875pMWLd4Vtjdsse0x4nV5/K4Cnmj7npZx+uJ9Hfi8O1oIW2X5qTOZ971yXBfxY+HVqX3upRy/F1Fq4PZqHHNpYFtKArcOcALwTdt/bhSv6/PvKkYZWFT7Vw41SS+nrF/6z3r7YcCzbP9owHE2s32+OpqUXdIhLvOT/mr0cINL+JPETRH1YD/XdvPRf5LOt71Z6zgjYjbpUzFOvEOBz3aYeHR5/I4D3mq72WTJI+L9jrJyybWUPnFN1xWVdJEbzecXbfXX2tYR2ue54dx7KusxbwycBBxl+7JWsfpidn3+/dr21l3E6tpo57qm0XyJXcjo1KnjfcBPJZ3O3J3HBzmx6cr1aqfrGlZnSXqi7S4WMwc4HDhb0l/oIPGgg+PX5xPAhbUjcuv5CwG2abTdsfxY0ott/7TjuLHo7u1dqR3kW8d7HWU90Q2Ad/bFazlQpOvz7yOSvsH0HFi0xChlA89LJF3KONOyNPxeQNJWzNsUPrApVFITN0VIOoXSqXNklfnA5sxSWc/QjBjBNSfU4Nc17Dt5lqRMMXAN3dTmXE1ZdquTJogujl9frMspczqNjNV8ShxJDwW2B15te9sBb7s3clOUBcbvpiQF02rk5nQm6X7mLNIuylJN/2YaHcOuz7/pPLCo9l3+B2UFA1PmpXu47dcPOM7a493f8Huh+frrSeKmCEmzbG8+2fsxaJN48vyy5UCNUeJ1dvwknW571L4djeI9hDJq7dWUWrnjgB/YzjyGsdiZhPOv04FFXao/Cj8EPI+S6J8CfLw3qGLY1a4oTddfT3Pq1PELSS+wfUrrQJJ2BE62PVvSB4GnUOYdunDQsXpJmsqKCTfYvlvSsygjR1strQJwpaTvUSbc7aIJorPjB5wv6ROUDtz9r22go8dUJi3eBXgh8CvKjPtbtB7+L+kZlGkG7pD0Wsr78wu2/9QybsQEdXL+9TlH0oZd9e/tUk3WBjp34Hjq6NsvAU8AHgLMAO5oWEN8GfBoyiotTaQmboqoTUmdNCFJusT2JpK2pvTv+AzwfttPG3SsvpgXAZtT+gb8jPIB+DjbL24U77BRips1QXR8/JqPeKpxHqCMMny97Wtr2TUtmt1HxL2EMov7JpTE8VDgFV3WfkSMpavzry9epwOLutD1lB99cWdR5qT7PuX7aFfgsbY/MOA4vde1AmXZsmbrr6cmboqw3WJx77H02ua3BQ62fbyk/RrHfKB2dH4FpVblS6oLSLcwWm2RygLPreJ1dvxsP3tkmcpyNYO2GeUD7xeSrgGOovxybe0+25a0HXCQ7UMltVrMPGKBdHj+9XQ9sKgLvXV0P9N1YNtXS5ph+37gsDql0aB19rqSxE1BtelxZ2CXRtNy/FnS1yj9ED5Z51kabZTQIN0raRfKL5+X1rKlGsdE0obU/yVlnrrm/dY6OH69OCtRJlB+NaV5YPVBbr82r18I7F2bOHcBHiLpJOCHtg8ZZLw+syXtC7wWeKbKrPzN3ysRC6L1+dfT32+4f2AR5Uf4UKpzts0A3mT7tR2G/nft43uRpE9RmjkfOuggvUEukj5pe+/++yR9EhjYIJjWX9wxQZJWlfRuSedRRiEtSfnSbOFVlCbNbWz/A1iZMplkS2+gLPp9gO1rJa0LfKdFIElrS9pHZVLjb1MWo39+y4EHXR0/SctK2knS8ZT+Fp8DPk5ZAqgZ27+x/XbKF9UXaLuA+06Upofdbf+lxvx0w3gREzIZ55+kh0jaXtIxlKTjeZTJ2odarQmbWZOqrryO0prwdsoo6jUpiXgrzx+l7EWDDJA+cZNM0psoX/ZrAMfUy/G2120Qa0Xbt/fNFzeXxvPEdaJWja9Eafo7yvbvJV3b4v9Z43V5/L4LPJMyguso4JfA1a1eW0TM0fX5N8rAoqOBL9lep0W8yVBbhJ5C6SP94IjURvNrdkbSWymVB4+hLM/WswJwlu3XDCpWmlMn3/8CZ1Pm3ZoFIKlVZv094CWU5YxGzhdnyhtuoCQdY/tVY0222KBz7i2UhOpRwEzg96PFHaAuj9/GwG3A74Arbd/fMFbnVGem75sv7sG7mCZzjMVQ6/r8+xllYNHWfQOLDmoYbzLcWC9LUBKcpsb4HvonMIsytcnfBhTqe5RVRD7B3KNvZw+6siQ1cZNM0irAjpRfXI+i1OS83nbT5rGuSFrV9k1jzRfXYp64vr4qu1AW4n4Y8ELb5zWI1enxk/R4Sn+YnYCbKZOAPrE2O0ZEQ12ef5KeTOlbuwNlkvSjgA/bHnfuzWEk6aFdzA1X+8HdT0myoPx/RUnktrb90rGeu4hxHwks07s9yOmSksRNIZLWYE4n/OUoncff3yDOEZRfeGfavnLQ259K6smzE+V/umbL5Lir49cXb/Maa0fKHHxbNYw1g5Kk9i8dM/B52yQtAVzSckBIxCB0fP71Bha9kjL7f8uBRZ2R9HTKFELL215L0pOAN9t+W6N4v7H9jNHK1GBSZUkvpfSbXI2S9K8N/M72RgOLkSRuapL0OGBnt1m26TnA1sB/UJpQLwLOsD3wqvpRmsYevIuOm8gkrd2i5m+MWM2O3yixBDzT7Zb9eQfwEeCvzL3sT6sl074L7JvJfWMYtD7/RsRagtJZfufRplEaNpLOpdQ0nuC66L2ky1r9iKuD3fawfW69vQXwddtPknRhbx8GHO85wC9sP1nSsymzFuwxsBhJ4hZPtWblqcCzgbcAd9p+/OTuVUxFKuvQPm2A/UXmF++XlPfmeczd2bnVAuMRMQkknWv7af0JlKSLbT+pUbynAt8ElqdUJNwO/BdlRoFtbR8z4HizbG9ek7kn235A0nm2txhUjAxsWAxJOpUyN87ZlGbVp9q+uXHM0UbEzrZ9b8u4MRDXU/qMdKV57WVETAnXS9oKcJ1q5J2UgSNN2P4t8MTab1p1iq2egSZw1T8kLQ+cAXxX0s3AfYMMkJq4xZCkz1Nm478b+A3lDXa27TsbxryOMifPbZRfQA+jzHl0M2XCx/NbxY6FI+k99epGwOOAnzD30jFDPQ1AREyuOjDsIMrcd6JM37JXq1r/OrH9KynLP/b3792/UbyHAndSRt++hjL91XcH+fpSEzeFSFqd0vGx/811xqDj2H53jbc8ZRLewyiL9C496Fh9TqZ0xv1Zjf0CynIyxwBfAQa6bqukmcCbmPdkbbJ2ao3ZyfFTWeLn/wGr2X6RyqoUT7d96IBD9Yb8/6leHlIvTUyl/pMRY+k6EagxOxlY1DXbt1KSm64cT2lVOJ++H6Qt1GN2vO3nUfoSH94kTmripoa6FMdOwBXMWdvULfoBSXo7ZVDDZsAfKTVxZ9r+5aBj9cWcNXLFhL7+AhfZ3nTA8c6iNBWfz5z/J7aPG2ScvnhdHr+TKIn3B2qH3CWBCwc9smqM2EtQRpLd3jpWxFQk6WTmJAL9ny2fbRSv04FFXVJZuecdzJsQN+n/2nLQxBjxTgBeZ7tZd5TUxE0d2wOPs93010G1LGXY8/m2B9o+P46/S9qbMtcRlITntvpr5YGxn7bQlvOINesa257ujt8qto9RWV8U2/dJun9+T1pYkr5HGfxyP+WLayVJn7OdpbBicbSG7S4Xpd+L8tnSycCijv2IMsXIibT5HhjpLElPtH1pB7EA7gIulfRz5h6k9c5BBUgSN3VcQ1nku3kSYPvTkramrCN3WG16XL43K3gjr6b8mvwRpXns17VsBmUt10H7saQX2/5pg22PprPjB9wh6RHUpkdJW9J24MGGLsu1vQb4KbA3JZlLEheLo64Tga4HFnXpLttf7DDe1sDrJV1L+azuddVoVav5k3ppJs2pU4Sk44AnAacyd+fxgWXsfbE+AmxO+XW3gaTVgO+PnARxGPX1qxJlBO7dwL007lfV8fF7CvAlyjJAl1GWF9vR9sWDjlXjXQ5sSpnl/Mu2T285DUDEVNS3ZNOSwPqUH27NEwFJhzJNBxZJejXlf3kKc7+2CxrF62zloK6kJm7qOKFeuvBy4MnABQC2b5TUdN06SRsA/828fR+eM8g4tpuvvzeGLo/f5cB/Uj7YBVxFGf3UyteA64CLgTPqB2H6xMXi5iWTFLeTgUWT5ImUFqHn0Nffr94eONt/rK1Q69t+sBWqRSwASetT1k/dkLmX3RrYOuWpiVsM9SYblHSB7afUYdBnt+woWyc7/CrzdgZuMrVIXabmItt3SHot8BTgC9NhRFfvuM2vrPE+LNlhf8qIKUPSepRltu6W9CxgE+CIEXOOxQRIuhLYxPY9HcXrtBVK0q8p3Yg+D7yUMhuEbH9kUDFSEzdFdJGx9zlG0teAh0l6E7A78I0GcfrdZ/vgxjH6HQw8qa7F9z5K59lvU2qwBq6TX1zSo4HVgWVVFsdWvWtFylqtAyXptba/0zdf3EhD35wTsRCOAzaX9FjK58oJlK4GL24RrNYWvY8yX2P/Z0uT2qqOXUyZM7TpZPN9um6FWtb2qZJUm2z3k3QmJbEbiCRxU8dhzMnYn03N2FsEsv0ZSc+nNIltAHzQ9i9axOpzoqS3AT9k7r4Pf28U7z7blrQdcJDtQyXt1igWdHP8Xgi8HliDuROo2cD7BxwLSp9CmDNfXL9U4cfi6oE6IvwVlNr9L0m6sGG87wJHU5pz3wLsBtzSMF6XHgVcKem3zP290GqJvXvq90JvUNhD5/eERXRXnZbp93Vqrz8DjxxkgDSnThGSzre9maRLe/N9STrT9n8MMEb/ZKojE4y7gD9Q5h47dVAx+2KPNvLVjWoakXQ6ZYLhNwDPpHzoXdRqLrUujl9frFe2mu9ujHjPsP2b+ZVFLA5UFm3/AvAB4KW2r205/1jfZ8slvS4vkk633aRVoUuSRn0Ntk9vFO+/KQMpnk9pOXkj8D3bX2oU76mUZcQeBnyMsmLDp2yfM6gYqYmbOppn7ON1+q/ztW1M+dU38A8j2+sOepvzsRNlCpPdbf9F0lq0nRKj/S+u2rwJrDNaE2fD0WpfovQpnF9ZxOLgDZQasQNqArcu8J2G8XrrS98kaVvgRkpt/NAbmazVvsyvBpokcSNaoR4HfNj2z1vEqvF+W6/+i/K+GbjUxE0Ro2TsKwKfHmTGPsH9eLPtrw1we++z/al6fUfb3++77//ZbtEM2LkufnH1jk3tnDsP2wNdOF7S04GtgHdRmol7VgRenilGItqT9BLK6jNrUn48rQh81HZXo+GbkrQpJXF7FXAtcJztL3cQdxXgb26QBNWVGsY0yObiJHHRVP+oyZEjKFuMqJT0a9tba951OLP+5gKqTR3PotQ6fLXvrtnAibZ/Pxn7FTEZJB1j+1V988XNpeXo/ummTjm1M7AL8DdKn7//tj3qPG4DiLclcCDwd8qP7G8Dq1CmZtrV9skDjncLZZLmI4FzGdF9aZDNxWlOnSLqshw79oapS3o4cJTtF07qji06jXF9tNuLzPbW9W8n88VJ+oLtd0k6kdE/2FusnToTeBPzzrn3xkHGqR80p0u6s1eb2rcPOwJJ4mJxslf92+l8cep4fdGOXEmpXXyp7asBJL27YbwvUwZ/rQT8EniR7XMkPZ6SaA00iQMeTel3twullvEnwJG2Lx9wnCRxU8gq/fMM2b5N0kD7VE0Sj3F9tNsDUfumXdKqo/EI365/P9NBrJ7jKR+Av6Bvzr2GdgY+NaJsX+D7ozw2YlqyfVP92/Xs/j+i2/VFu/BKyufKrySdTFlTu8lsDNWStk8BkLR/r5uL7SulwYe1fT8lMTxZ0tKUZO60GnuggyiSxE0dD0haqzcZbZ0Vfzq0dT9J0u2UE3TZep16e5mxn7bwbD8g6eL+/2crvcmKW42mGsNytvduHUTSiyhzX60uqX99wxWBTPQbi5VRumjMpWFXja7XF23O9g+BH9YpPrYH3g08StLBwA97CdcA9Se/d47cnQHHAqAmb9tSErh1gC8CPxh4nPSJmxokbQMcwpxROc8E9rD9s8nbq+El6ZfAU4HzgDt65YNughirf0xfvIH3k5H0ceAs2z8d9LZHxHkSZc3U/YEP9901G/iV7dtaxo+YiiTtD/yFUgsv4DXACiO7HAwwXqfri04WSSsDOwI7DXoiY0n3U74HBCwL/Lt3F7CM7aUGHO9wyiwPJ1G6RV02yO3PFStJ3NRRR8tsSXljnW371knepaHV1fxDGmNB5b54A2t66asJEGUi3rsp0w80HbQhaakaY4NadJXte8d5SsS0Jelc20+bX9kA432Csr7oH+hbX3TQiU4MjqQHmFN50HSAXZpTJ5mkx9d2+d4ozRvr37Vqc+C0+rXVla6aN7vsH9PVYI1RbAUcAVxH+RBaU9Juts+YpP2JmEz3S3oNpR+XKc1lLfumvhx4jDtaXzQWne0luoqVJG7yvQfYA/jsKPcZyK+tBTBOv5XWtVVbUuZwegLwEGAGcEeLeJKOoAxsONP2lYPe/ig+B7zA9lU1/gaUEV2bdRA7Yqp5NXBQvRj4TS1rpev1RWOIpDl1CqijKZ+eZYyGl6RZlNFW3wc2B3YFHmv7Aw1iPQfYGvgP4DHARcAZtg8adKwa78HlfsYri4jBk3QasAnQ1fqiMUSSxE0Rks62/fTJ3o9YOJJm2d58xPqGZ9neqlG8GZSBG8+mTMZ7p+3HN4r1TUqNQ286lddQhuw3WUYmYiqrNdEHA4+yvbGkTYCX2f54o3idri8awyVJ3BQh6aPAJcAPWiwDEm1JOgN4HvANysi1m4DXt1iaStKplIENZ1OaVX9tu1lTSx0qvyel9k/AGcBXbN897hMjpiFJpwP/A3zN9pNr2WUt5qXseM7LGELpEzd1vIfyxXyfpLvIMlHD5nWUJVzeTpnzaE3gFY1iXULpj7Yx8E/gH7Umd+T8R4OyJHCQ7c/Bg7WASzeKFTHVLWf7vBGTxDaZN7HLOS9jOHU2giJGJ+kZ9epM20vYfojtFW2vkARuqGxv+y7bt9v+qO330Gh5Htvvtv1Myqi1vwGHAf9oEas6lTK3Us+ylNUiIhZHt0pajzqAStIOlJr3VlYFLpd0qqQTepeG8WKIpDl1kkk63/ZmLRaDj+6MdvwkXdhrbhlwrLdTBjVsBvyR0rx5pu1fDjpWjXeR7U3nVxaxOJD0GMrE7FsBtwHXAq9pNd1Q+sTFeNKcOvnulXQYsMaIpY0AsP3OSdinmCBJvQWO1x3x63gFSi1ZC8tSpv0433YXy1/dIekpvTkLJW3GvEvXRCwWbF8DPK8uGbWE7dmN451eJxVf3/YvJC1HmcIoIkncFPASSof45wDnj7gv1aRT31mUppRVmHuuv9mUvmsDZ/vTLbY7jncB35fUm4h6VWCnjvchYkqQ9AfgHMqgojOAKxrHexNlLtGVgfWA1YGvAs9tGTeGQ5pTpwhJT7J9cd/trYFdbO85ibsVATy49NbjKANursyyW7G4qqO1n0bp0vAM4PHAxbZf3ijeRcAWwLl9o2Evtf3EFvFiuKQmboqwfbGkTSlNc6+i9LM4blJ3KuZrslaI6IKkpwLX2/6L7Xvr0nCvBP4oaT/bf5/kXYyYDPdT1iy+n7KW6V9pu5rC3bbv6Y2GlbQkaaWJKkncJKsTR+5MWX/vb8DRlBrSZ0/qjsWETOJ6pl34GqWpH0nPBA4E3gFsSunYvcOk7VnE5LkduJTSL/Xrtlv1fe05XdL7gWUlPR94G3Bi45gxJNKcOskkPUDpW7G77atr2TW2HzO5exaLO0kX9yYrlvS/wC2296u3Mzo1FkuStqNMfL0FcA+lX+wZtk9tFG8JYHfgBZQa/p8B38ik8AFJ4iadpJdTauK2Ak4GjqKcoOtO6o7FYk/SZcCmtu+TdCWwh+0zevdlFvlYnEl6PPAiysCfR9pedvxnRAxeJvudZLZ/aHsnSufY0yiz/T9K0sGSXjCpOxeLuyMpTTnHU6YUORNA0mMpK0VELHYkHVdHqB4ELA/sCjy8QZztJO3Zd/tcSdfUy46DjhfDKTVxU5CklYEdgZ1sP2ey9ycWX5K2pEwpcortO2rZBsDyvXnjIhYndcDPBbbvbxznN8DOtq+vty+iTCvyUOAw25liJJLERUREzE//aO16e1fqaG1g4KO1Jf3W9lP7bn/Z9tvr9XNsbznIeDGc0pwaERExf1+jDGToH619BKVrwSEN4s3VRNtL4KqZDeLFEEoSFxERMX8z+mrbdgIOsX2c7Q8Bj20Q79y6WsNcJL0ZOK9BvBhCmScuIiJi/mZIWrKuV/xcylJYPS2+S98N/EjSq4Fe/9PNgKWB7RvEiyGUJC4iImL+eqO1b6WD0dq2bwa2kvQcYKNa/BPbvxx0rBheGdgQERExARmtHVNNkriIiIiIIZSBDRERERFDKElcRERExBBKEhcR056k+yVd1HfZp5a/S9JyfY/71wJudzVJx87nMd+QtGG9/v4R9521IPEiIvqlT1xETHuS/mV7+VHKrwM2t33reI9rvR8REQsjNXERsViS9E5gNeBXkn7VV36ApIslnSPpUbXsW5K+KOmsugD5DrV8HUmX1eszJH1G0qWSLpH0jlp+mqTNJR0ILFtrAr9b7/tXX9z/kfTb+tyP1rKHSvpJ3Z/LJO3U0b8nIoZA5omLiMXBsnUB8Z5P2P6ipPcAz+7VxFEWFz/H9gckfQp4E/Dxet+qwNbA44ETgJHNqHsA6wJPtn2fpJX777S9j6S329505M5JegGwPrAFIOCEurTTTOBG29vWx620cC8/IqajJHERsTi4c7TkaRT3AD+u188Hnt93349sPwBc0auhG+F5wFfrjP4s4ILoL6iXC+vt5SlJ3ZnAZyR9Evix7TMXYJsRMc0liYuImONez+kofD9zf0be3XddozxXwMJ2MhaldvBr89whbQa8GPiEpFNs77+QMSJimkmfuIhYnM0GVhjQtk4B3iJpSYCRzanVvZKWGqX8Z8AbJS1fn7u6pEdKWg34t+3vAJ8BnjKgfY2IaSA1cRGxOBjZJ+5k2/sAhwAnSbrJ9rMXMcY3gA2ASyTdC3wd+PKIxxxS77/A9mt6hbZPkfQE4GxJAP8CXgs8Fvi0pAeAe4G3LuI+RsQ0kilGIiIiIoZQmlMjIiIihlCSuIiIiIghlCQuIiIiYggliYuIiIgYQkniIiIiIoZQkriIiIiIIZQkLiIiImIIJYmLiIiIGEL/H4YXL1uSLG0iAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Ethnicities visualization\n",
    "plt.figure(figsize=(10,5))\n",
    "characters.EthnicityName.value_counts()[:20].plot(kind=\"bar\")\n",
    "plt.xlabel('Ethnicities')\n",
    "plt.ylabel('Number of actors')\n",
    "plt.title('Distribution of the twenty most represented ethnicities');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "792eede8",
   "metadata": {},
   "source": [
    "#### I don't know on what I should base the big ethnicity categories : maybe\n",
    "- American Indian or Alaska Native\n",
    "- Asian\n",
    "- Black or African American\n",
    "- Hispanic or Latino\n",
    "- Native Hawaiian or Other Pacific Islander\n",
    "- White"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "78494a52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The percentage of missing Ethnicity names is : 79.35 %\n"
     ]
    }
   ],
   "source": [
    "print('The percentage of missing Ethnicity names is :', round(100*characters[['EthnicityName']].isna().sum().values[0]/n_char,2), '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04fe362b",
   "metadata": {},
   "source": [
    "We only have the names of 20% of the actor ethnicities : this is not enough to base our analysis and to draw conclusions. We thus decided to not use the Ethnicity in our project."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ab7127",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### 1.4.2 Recovering Missing Actor Names  <a id='1.4.2'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b0496b2",
   "metadata": {},
   "source": [
    "In addition, some actors do not have their name and/or date of birth and/or sex specified but the actor freebase ID is present. We can use the actor freebase ID to recover their Wikidata information. This gives us access to the following relevant information about the actor :\n",
    "- Name\n",
    "- Sex/Gender\n",
    "- Date of Birth  \n",
    "We can therefore replace the missing values in those categories, when the Actor Freebase ID is specified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "85cb4d20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows where:\n",
      "\tActor is missing but actor ID is specified : 413\n",
      "\tActor and DOB are missing but actor ID is specified : 400\n",
      "\tActor and Gender are missing but actor ID is specified : 401\n",
      "\tActor, DOB and Gender are missing but actor ID is specified : 400\n",
      "\tDOB is missing but Actor and actor ID are specified : 104930\n",
      "\tGender is missing but Actor and actor ID are specified : 44393\n",
      "\tDOB and Gender are missing but Actor and actor ID are specified : 62635\n"
     ]
    }
   ],
   "source": [
    "print('Number of rows where:\\n\\tActor is missing but actor ID is specified :', len(characters[(characters['ActorName'].isna() & ~characters['FreeActorID'].isna())]))\n",
    "print('\\tActor and DOB are missing but actor ID is specified :', len(characters[(characters['ActorName'].isna() & characters['ActorDOB'].isna() & ~characters['FreeActorID'].isna())]))\n",
    "print('\\tActor and Gender are missing but actor ID is specified :', len(characters[(characters['ActorName'].isna() & characters['ActorGender'].isna() & ~characters['FreeActorID'].isna())]))\n",
    "print('\\tActor, DOB and Gender are missing but actor ID is specified :', len(characters[(characters['ActorName'].isna() & characters['ActorDOB'].isna() & characters['ActorGender'].isna() & ~characters['FreeActorID'].isna())]))\n",
    "print('\\tDOB is missing but Actor and actor ID are specified :', len(characters[(~characters['ActorName'].isna() & characters['ActorDOB'].isna() & ~characters['FreeActorID'].isna())]))\n",
    "print('\\tGender is missing but Actor and actor ID are specified :', len(characters[(~characters['ActorName'].isna() & characters['ActorGender'].isna() & ~characters['FreeActorID'].isna())]))\n",
    "print('\\tDOB and Gender are missing but Actor and actor ID are specified :', len(characters[(~characters['ActorName'].isna() & characters['ActorDOB'].isna() & characters['ActorGender'] & ~characters['FreeActorID'].isna())]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f09cec5b",
   "metadata": {},
   "source": [
    "#### Starting with recovery of missing Actor names\n",
    "\n",
    "For this, we perform the same as in the Ethnicity names recovery."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3a1a2774",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WikiMovieID</th>\n",
       "      <th>FreeMovieID</th>\n",
       "      <th>ReleaseDate</th>\n",
       "      <th>CharName</th>\n",
       "      <th>ActorDOB</th>\n",
       "      <th>ActorGender</th>\n",
       "      <th>ActorHeight</th>\n",
       "      <th>ActorName</th>\n",
       "      <th>ActorAgeRelease</th>\n",
       "      <th>FreeMapID</th>\n",
       "      <th>FreeCharID</th>\n",
       "      <th>EthnicityName</th>\n",
       "      <th>free</th>\n",
       "      <th>WikiActorID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>975900</td>\n",
       "      <td>/m/03vyhn</td>\n",
       "      <td>2001-08-24</td>\n",
       "      <td>Akooshay</td>\n",
       "      <td>1958-08-26</td>\n",
       "      <td>F</td>\n",
       "      <td>1.620</td>\n",
       "      <td>Wanda De Jesus</td>\n",
       "      <td>42.0</td>\n",
       "      <td>/m/0bgchxw</td>\n",
       "      <td>/m/0bgcj3x</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/m/03wcfv7</td>\n",
       "      <td>Q1873468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>975900</td>\n",
       "      <td>/m/03vyhn</td>\n",
       "      <td>2001-08-24</td>\n",
       "      <td>Lieutenant Melanie Ballard</td>\n",
       "      <td>1974-08-15</td>\n",
       "      <td>F</td>\n",
       "      <td>1.780</td>\n",
       "      <td>Natasha Henstridge</td>\n",
       "      <td>27.0</td>\n",
       "      <td>/m/0jys3m</td>\n",
       "      <td>/m/0bgchn4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/m/0346l4</td>\n",
       "      <td>Q230527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>975900</td>\n",
       "      <td>/m/03vyhn</td>\n",
       "      <td>2001-08-24</td>\n",
       "      <td>Desolation Williams</td>\n",
       "      <td>1969-06-15</td>\n",
       "      <td>M</td>\n",
       "      <td>1.727</td>\n",
       "      <td>Ice Cube</td>\n",
       "      <td>32.0</td>\n",
       "      <td>/m/0jys3g</td>\n",
       "      <td>/m/0bgchn_</td>\n",
       "      <td>African Americans</td>\n",
       "      <td>/m/01vw26l</td>\n",
       "      <td>Q173637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>975900</td>\n",
       "      <td>/m/03vyhn</td>\n",
       "      <td>2001-08-24</td>\n",
       "      <td>Sgt Jericho Butler</td>\n",
       "      <td>1967-09-12</td>\n",
       "      <td>M</td>\n",
       "      <td>1.750</td>\n",
       "      <td>Jason Statham</td>\n",
       "      <td>33.0</td>\n",
       "      <td>/m/02vchl6</td>\n",
       "      <td>/m/0bgchnq</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/m/034hyc</td>\n",
       "      <td>Q169963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>975900</td>\n",
       "      <td>/m/03vyhn</td>\n",
       "      <td>2001-08-24</td>\n",
       "      <td>Bashira Kincaid</td>\n",
       "      <td>1977-09-25</td>\n",
       "      <td>F</td>\n",
       "      <td>1.650</td>\n",
       "      <td>Clea DuVall</td>\n",
       "      <td>23.0</td>\n",
       "      <td>/m/02vbb3r</td>\n",
       "      <td>/m/0bgchp9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/m/01y9xg</td>\n",
       "      <td>Q233347</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   WikiMovieID FreeMovieID ReleaseDate                    CharName  \\\n",
       "0       975900   /m/03vyhn  2001-08-24                    Akooshay   \n",
       "1       975900   /m/03vyhn  2001-08-24  Lieutenant Melanie Ballard   \n",
       "2       975900   /m/03vyhn  2001-08-24         Desolation Williams   \n",
       "3       975900   /m/03vyhn  2001-08-24          Sgt Jericho Butler   \n",
       "4       975900   /m/03vyhn  2001-08-24             Bashira Kincaid   \n",
       "\n",
       "     ActorDOB ActorGender  ActorHeight           ActorName  ActorAgeRelease  \\\n",
       "0  1958-08-26           F        1.620      Wanda De Jesus             42.0   \n",
       "1  1974-08-15           F        1.780  Natasha Henstridge             27.0   \n",
       "2  1969-06-15           M        1.727            Ice Cube             32.0   \n",
       "3  1967-09-12           M        1.750       Jason Statham             33.0   \n",
       "4  1977-09-25           F        1.650         Clea DuVall             23.0   \n",
       "\n",
       "    FreeMapID  FreeCharID      EthnicityName        free WikiActorID  \n",
       "0  /m/0bgchxw  /m/0bgcj3x                NaN  /m/03wcfv7    Q1873468  \n",
       "1   /m/0jys3m  /m/0bgchn4                NaN   /m/0346l4     Q230527  \n",
       "2   /m/0jys3g  /m/0bgchn_  African Americans  /m/01vw26l     Q173637  \n",
       "3  /m/02vchl6  /m/0bgchnq                NaN   /m/034hyc     Q169963  \n",
       "4  /m/02vbb3r  /m/0bgchp9                NaN   /m/01y9xg     Q233347  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "characters = characters.merge(maps, how=\"left\", left_on=\"FreeActorID\", right_on=\"free\")\n",
    "characters.drop(columns=[\"FreeActorID\"], inplace=True)\n",
    "characters.rename(columns={\"wiki\":\"WikiActorID\"}, inplace=True)\n",
    "display(characters.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f6698ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_actor = characters[(characters['ActorName'].isna() & ~characters['WikiActorID'].isna())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b39ee4a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_WikiActorId_Actor = pd.DataFrame(missing_actor.WikiActorID.unique(), columns=[\"WikiActorID\"]).dropna()\n",
    "map_WikiActorId_Actor[\"ActorName\"] = map_WikiActorId_Actor.WikiActorID.apply(get_wikidata_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3896aa97",
   "metadata": {},
   "outputs": [],
   "source": [
    "characters = characters.merge(map_WikiActorId_Actor, how=\"left\", left_on=\"WikiActorID\", right_on=\"WikiActorID\").drop(columns= [\"WikiActorID\", \"WikiActorID\"])\n",
    "characters.drop(columns=\"free\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5b9d77b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "characters[\"ActorName\"] = characters.fillna(value={\"ActorName_x\":\"\"}).ActorName_x + characters.fillna(value={\"ActorName_y\":\"\"}).ActorName_y\n",
    "characters.drop(columns=[\"ActorName_x\", \"ActorName_y\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2e947d5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WikiMovieID</th>\n",
       "      <th>FreeMovieID</th>\n",
       "      <th>ReleaseDate</th>\n",
       "      <th>CharName</th>\n",
       "      <th>ActorDOB</th>\n",
       "      <th>ActorGender</th>\n",
       "      <th>ActorHeight</th>\n",
       "      <th>ActorAgeRelease</th>\n",
       "      <th>FreeMapID</th>\n",
       "      <th>FreeCharID</th>\n",
       "      <th>EthnicityName</th>\n",
       "      <th>ActorName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>975900</td>\n",
       "      <td>/m/03vyhn</td>\n",
       "      <td>2001-08-24</td>\n",
       "      <td>Akooshay</td>\n",
       "      <td>1958-08-26</td>\n",
       "      <td>F</td>\n",
       "      <td>1.620</td>\n",
       "      <td>42.0</td>\n",
       "      <td>/m/0bgchxw</td>\n",
       "      <td>/m/0bgcj3x</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Wanda De Jesus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>975900</td>\n",
       "      <td>/m/03vyhn</td>\n",
       "      <td>2001-08-24</td>\n",
       "      <td>Lieutenant Melanie Ballard</td>\n",
       "      <td>1974-08-15</td>\n",
       "      <td>F</td>\n",
       "      <td>1.780</td>\n",
       "      <td>27.0</td>\n",
       "      <td>/m/0jys3m</td>\n",
       "      <td>/m/0bgchn4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Natasha Henstridge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>975900</td>\n",
       "      <td>/m/03vyhn</td>\n",
       "      <td>2001-08-24</td>\n",
       "      <td>Desolation Williams</td>\n",
       "      <td>1969-06-15</td>\n",
       "      <td>M</td>\n",
       "      <td>1.727</td>\n",
       "      <td>32.0</td>\n",
       "      <td>/m/0jys3g</td>\n",
       "      <td>/m/0bgchn_</td>\n",
       "      <td>African Americans</td>\n",
       "      <td>Ice Cube</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>975900</td>\n",
       "      <td>/m/03vyhn</td>\n",
       "      <td>2001-08-24</td>\n",
       "      <td>Sgt Jericho Butler</td>\n",
       "      <td>1967-09-12</td>\n",
       "      <td>M</td>\n",
       "      <td>1.750</td>\n",
       "      <td>33.0</td>\n",
       "      <td>/m/02vchl6</td>\n",
       "      <td>/m/0bgchnq</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jason Statham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>975900</td>\n",
       "      <td>/m/03vyhn</td>\n",
       "      <td>2001-08-24</td>\n",
       "      <td>Bashira Kincaid</td>\n",
       "      <td>1977-09-25</td>\n",
       "      <td>F</td>\n",
       "      <td>1.650</td>\n",
       "      <td>23.0</td>\n",
       "      <td>/m/02vbb3r</td>\n",
       "      <td>/m/0bgchp9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Clea DuVall</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   WikiMovieID FreeMovieID ReleaseDate                    CharName  \\\n",
       "0       975900   /m/03vyhn  2001-08-24                    Akooshay   \n",
       "1       975900   /m/03vyhn  2001-08-24  Lieutenant Melanie Ballard   \n",
       "2       975900   /m/03vyhn  2001-08-24         Desolation Williams   \n",
       "3       975900   /m/03vyhn  2001-08-24          Sgt Jericho Butler   \n",
       "4       975900   /m/03vyhn  2001-08-24             Bashira Kincaid   \n",
       "\n",
       "     ActorDOB ActorGender  ActorHeight  ActorAgeRelease   FreeMapID  \\\n",
       "0  1958-08-26           F        1.620             42.0  /m/0bgchxw   \n",
       "1  1974-08-15           F        1.780             27.0   /m/0jys3m   \n",
       "2  1969-06-15           M        1.727             32.0   /m/0jys3g   \n",
       "3  1967-09-12           M        1.750             33.0  /m/02vchl6   \n",
       "4  1977-09-25           F        1.650             23.0  /m/02vbb3r   \n",
       "\n",
       "   FreeCharID      EthnicityName           ActorName  \n",
       "0  /m/0bgcj3x                NaN      Wanda De Jesus  \n",
       "1  /m/0bgchn4                NaN  Natasha Henstridge  \n",
       "2  /m/0bgchn_  African Americans            Ice Cube  \n",
       "3  /m/0bgchnq                NaN       Jason Statham  \n",
       "4  /m/0bgchp9                NaN         Clea DuVall  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "characters.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "299d4f25",
   "metadata": {},
   "source": [
    "From wikidata actor page,\n",
    "- sex/gender (P21) is given as : male (Q6581097), female (Q6581072), intersex (Q1097630), transgender female (Q1052281), transgender male (Q2449503).\n",
    "- date of birth (P569) is given as : Day of the month as a zero-padded decimal number, blank space, Month full name, blank space, Year with century as a decimal number. To recover the date of birth in the same format as the ones in the characters dataset, we must read the date given by wikidata without the blank spaces and then use datetime to format it correctly. See example just below :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6f7760b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1949-12-26\n"
     ]
    }
   ],
   "source": [
    "wiki_date = '26 December 1949'\n",
    "no_space = wiki_date.replace(\" \", \"\")\n",
    "date = datetime.strptime(no_space, '%d''%B''%Y')\n",
    "formated_date = '{:%Y-%m-%d}'.format(date)\n",
    "print(formated_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b5ca65",
   "metadata": {},
   "source": [
    "We later decided that we won't use the actors information, so we didn't push further and didn't recover missing DOB or genders."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef13684f",
   "metadata": {},
   "source": [
    "### Saving out results\n",
    "\n",
    "Extracting from wikidata takes a few minutes so we can save our final `characters` dataframe in case we want to use that directly in further applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bccf48c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os  \n",
    "os.makedirs('data', exist_ok=True)  \n",
    "characters.to_csv('data/characters_aug.tsv', sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d3720d7",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 2. Plot Summaries   <a id='2'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5dcc252d",
   "metadata": {},
   "outputs": [],
   "source": [
    "characters = pd.read_csv('data/characters_aug.tsv.gz', sep='\\t', header=0, index_col=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98317c17-f90b-4e20-8fda-361c43c43ab3",
   "metadata": {
    "tags": []
   },
   "source": [
    "The plot summaries are loaded from the file `plot_summaries.txt` and stored into `plot_summaries`dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2b6962e3-2f02-46aa-a34a-d4ba8110a6e2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WikiMovieID</th>\n",
       "      <th>Plot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23890098</td>\n",
       "      <td>Shlykov, a hard-working taxi driver and Lyosha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31186339</td>\n",
       "      <td>The nation of Panem consists of a wealthy Capi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20663735</td>\n",
       "      <td>Poovalli Induchoodan  is sentenced for six yea...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   WikiMovieID                                               Plot\n",
       "0     23890098  Shlykov, a hard-working taxi driver and Lyosha...\n",
       "1     31186339  The nation of Panem consists of a wealthy Capi...\n",
       "2     20663735  Poovalli Induchoodan  is sentenced for six yea..."
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot_summaries = pd.read_csv('data/plot_summaries.txt', sep=\"\\t\", header=None,names=[\"WikiMovieID\", \"Plot\"])\n",
    "plot_summaries.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c393a17",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2.1 Preprocessing  <a id='2.1'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f908b664",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 2.1.1 Missing plot summaries check  <a id='2.1.1'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cca4e357-2742-470b-8789-834776e5883d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing plot summary in the plot_summary dataset: 0\n"
     ]
    }
   ],
   "source": [
    "print('Number of missing plot summary in the plot_summary dataset: {}'.format(plot_summaries.Plot.isna().sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7a771f9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing plot summary when matched to films in movies dataset: 48.37%\n"
     ]
    }
   ],
   "source": [
    "print('Number of missing plot summary when matched to films in movies dataset: {:.2f}%'.format((movies.merge(plot_summaries, how=\"left\", on='WikiMovieID')).Plot.isna().sum()/len(movies)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86f5f931",
   "metadata": {},
   "source": [
    "We can see that we don't have the plot summary for about half of the movies."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92434f63",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 2.1.2 Cleaning <a id='2.1.2'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "823e2c3a",
   "metadata": {},
   "source": [
    "We detect the langage used in the plot summary and keep only the ones written in English."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8253c5f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WikiMovieID</th>\n",
       "      <th>FreeMovieID</th>\n",
       "      <th>Title</th>\n",
       "      <th>ReleaseDate</th>\n",
       "      <th>Revenue</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Languages</th>\n",
       "      <th>Countries</th>\n",
       "      <th>Genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>975900</td>\n",
       "      <td>/m/03vyhn</td>\n",
       "      <td>Ghosts of Mars</td>\n",
       "      <td>2001-08-24</td>\n",
       "      <td>14010832.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>[English Language]</td>\n",
       "      <td>[United States of America]</td>\n",
       "      <td>[Thriller, Science Fiction, Horror, Adventure,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3196793</td>\n",
       "      <td>/m/08yl5d</td>\n",
       "      <td>Getting Away with Murder: The JonBenét Ramsey ...</td>\n",
       "      <td>2000-02-16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>95.0</td>\n",
       "      <td>[English Language]</td>\n",
       "      <td>[United States of America]</td>\n",
       "      <td>[Mystery, Biographical film, Drama, Crime Drama]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28463795</td>\n",
       "      <td>/m/0crgdbh</td>\n",
       "      <td>Brun bitter</td>\n",
       "      <td>1988</td>\n",
       "      <td>NaN</td>\n",
       "      <td>83.0</td>\n",
       "      <td>[Norwegian Language]</td>\n",
       "      <td>[Norway]</td>\n",
       "      <td>[Crime Fiction, Drama]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   WikiMovieID FreeMovieID                                              Title  \\\n",
       "0       975900   /m/03vyhn                                     Ghosts of Mars   \n",
       "1      3196793   /m/08yl5d  Getting Away with Murder: The JonBenét Ramsey ...   \n",
       "2     28463795  /m/0crgdbh                                        Brun bitter   \n",
       "\n",
       "  ReleaseDate     Revenue  Runtime             Languages  \\\n",
       "0  2001-08-24  14010832.0     98.0    [English Language]   \n",
       "1  2000-02-16         NaN     95.0    [English Language]   \n",
       "2        1988         NaN     83.0  [Norwegian Language]   \n",
       "\n",
       "                    Countries  \\\n",
       "0  [United States of America]   \n",
       "1  [United States of America]   \n",
       "2                    [Norway]   \n",
       "\n",
       "                                              Genres  \n",
       "0  [Thriller, Science Fiction, Horror, Adventure,...  \n",
       "1   [Mystery, Biographical film, Drama, Crime Drama]  \n",
       "2                             [Crime Fiction, Drama]  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "242c3720",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 42303/42303 [08:18<00:00, 84.91it/s]\n"
     ]
    }
   ],
   "source": [
    "plot_summaries['lang'] = plot_summaries.Plot.progress_apply(detect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0f8c366f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "en    42275\n",
       "id       14\n",
       "es        6\n",
       "de        4\n",
       "sw        2\n",
       "hi        1\n",
       "et        1\n",
       "Name: lang, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot_summaries.lang.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "71d68739",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_summaries = plot_summaries.loc[plot_summaries.lang=='en']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de679864",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 2.1.3 Tokenization <a id='2.1.3'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "896b1aa5",
   "metadata": {},
   "source": [
    "Tokenizers are used to divide strings into lists of substrings. For each `Plot` in `plot_summaries` dataset, a list of words and punctuation marks stored in the `words_punc` column, a list of sentences in `sentences` and a list of tokenized sentences `tokens_sentences`. To do so, we use the natural langage processing library `NLTK` (Natural Language Toolkit). \"NLTK is a leading platform for building Python programs to work with human language data\"[[3]](https://www.nltk.org/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9c9cee4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████| 42275/42275 [01:50<00:00, 382.02it/s]\n",
      "100%|███████████████████████████████████| 42275/42275 [00:22<00:00, 1867.65it/s]\n",
      "100%|████████████████████████████████████| 42275/42275 [01:59<00:00, 353.56it/s]\n"
     ]
    }
   ],
   "source": [
    "plot_summaries['words_punc'] = plot_summaries.Plot.progress_apply(lambda x: word_tokenize(x))\n",
    "plot_summaries['sentences'] = plot_summaries.Plot.progress_apply(lambda x: sent_tokenize(x))\n",
    "plot_summaries['tokens_sentences'] = plot_summaries['sentences'].progress_apply(lambda sentences: [word_tokenize(sentence) for sentence in sentences])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d60c2c8e",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 2.1.4 PoS tagging <a id='2.1.4'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a93d6e",
   "metadata": {},
   "source": [
    "Part-of-speech (POS) tagging is a popular Natural Language Processing process which refers to categorizing words in a text (corpus) in correspondence with a particular part of speech, depending on the definition of the word and its context. POS tags from the [*Penn Treebank* tagset](https://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html) are used to describe the lexical terms that we have within our plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0ded4963",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 42275/42275 [16:06<00:00, 43.74it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    [[(Shlykov, NNP), (,, ,), (a, DT), (hard-worki...\n",
       "1    [[(The, DT), (nation, NN), (of, IN), (Panem, N...\n",
       "2    [[(Poovalli, NNP), (Induchoodan, NNP), (is, VB...\n",
       "Name: POS_tokens, dtype: object"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot_summaries['POS_tokens'] = plot_summaries['tokens_sentences'].progress_apply(lambda tokens_sentences: [pos_tag(tokens) for tokens in tokens_sentences])\n",
    "\n",
    "plot_summaries['POS_tokens'].head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c678b890",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 2.1.5 Lemmatization <a id='2.1.5'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4816542",
   "metadata": {},
   "source": [
    "Lemmatization is the process of grouping together the different inflected forms of a word so they can be analyzed as a single item. It links words with similar meanings to one word. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1821b30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wordnet_pos(treebank_tag):\n",
    "\n",
    "    if treebank_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif treebank_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif treebank_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif treebank_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2479400a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████| 42275/42275 [01:37<00:00, 432.17it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Plot</th>\n",
       "      <th>tokens_sentences_lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Shlykov, a hard-working taxi driver and Lyosha...</td>\n",
       "      <td>[[Shlykov, ,, a, hard-working, taxi, driver, a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The nation of Panem consists of a wealthy Capi...</td>\n",
       "      <td>[[The, nation, of, Panem, consist, of, a, weal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Poovalli Induchoodan  is sentenced for six yea...</td>\n",
       "      <td>[[Poovalli, Induchoodan, be, sentence, for, si...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Plot  \\\n",
       "0  Shlykov, a hard-working taxi driver and Lyosha...   \n",
       "1  The nation of Panem consists of a wealthy Capi...   \n",
       "2  Poovalli Induchoodan  is sentenced for six yea...   \n",
       "\n",
       "                         tokens_sentences_lemmatized  \n",
       "0  [[Shlykov, ,, a, hard-working, taxi, driver, a...  \n",
       "1  [[The, nation, of, Panem, consist, of, a, weal...  \n",
       "2  [[Poovalli, Induchoodan, be, sentence, for, si...  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Lemmatizing each word with its POS tag, in each sentence\n",
    "plot_summaries['tokens_sentences_lemmatized'] = plot_summaries['POS_tokens'].progress_apply(\n",
    "    lambda list_tokens_POS: [\n",
    "        [\n",
    "            lemmatizer.lemmatize(el[0], get_wordnet_pos(el[1])) \n",
    "            if get_wordnet_pos(el[1]) != '' else el[0] for el in tokens_POS\n",
    "        ] \n",
    "        for tokens_POS in list_tokens_POS\n",
    "    ]\n",
    ")\n",
    "\n",
    "plot_summaries[['Plot','tokens_sentences_lemmatized']].head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e473b965",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 2.1.6 Regrouping tokens and removing stop words <a id='2.1.6'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ca0181",
   "metadata": {},
   "source": [
    "In order to extact interesting information from the words present in the plot summaries, we have to take into account only the meaningful words by removing insignificant ones called stop words.\n",
    "What we have seen is that the names of the characters in the plot summaries create a lot of unwanted noise which in turn disturbs greatly our results in the topic extraction methods.Therefore, we introduce the [name-dataset](https://pypi.org/project/names-dataset/), which used a Facebook dump to create a first and last name database. From there  we extract the top 1000 first names for each gender and use them as stopwords. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "260785d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "nd = NameDataset()\n",
    "names = nd.get_top_names(n=2000, country_alpha2=\"US\")\n",
    "names = names[\"US\"][\"M\"] + names[\"US\"][\"F\"]\n",
    "names = [name.lower() for name in names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b4b6bdae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████| 42275/42275 [00:04<00:00, 9254.71it/s]\n"
     ]
    }
   ],
   "source": [
    "# Words gathered after running the LDA model and collecting the words appearing in more than 4 topics \n",
    "stops = [\"one\", \"two\", \"also\", \"see\", \"take\", \"get\", \"find\", \"try\", \"however\", \"go\", \"come\", \"leave\", \"become\", \"make\", \"back\", \"run\"]\n",
    "my_stopwords = stopwords.words('English') + names + stops\n",
    "\n",
    "plot_summaries['tokens'] = plot_summaries['tokens_sentences_lemmatized'].progress_apply(lambda sentences: list(chain.from_iterable(sentences)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2a4a6f88",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 42275/42275 [08:42<00:00, 80.93it/s]\n"
     ]
    }
   ],
   "source": [
    "plot_summaries['tokens'] = plot_summaries['tokens'].progress_apply(lambda tokens: [token.lower() for token in tokens if token.isalpha() \n",
    "                                                    and token.lower() not in my_stopwords and len(token)>1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf3dc48",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 2.1.7 Integration into movies dataset <a id='2.1.7'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e77f136-694c-4e85-8614-8452952cbbff",
   "metadata": {},
   "source": [
    "The preprocessed plot summaries `plot_summaries` are added to the `movies` dataset according to the Wikipedia movie ID, `WikiMovieID`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8985339f",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = movies.merge(plot_summaries, how=\"left\", on='WikiMovieID') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "658ea17b-e28a-40b8-9782-f0d078ca9015",
   "metadata": {},
   "source": [
    "### 2.1.8 Preprocessing results <a id='2.1.8'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c8a99c29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Plot</th>\n",
       "      <th>words_punc</th>\n",
       "      <th>sentences</th>\n",
       "      <th>tokens_sentences</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Set in the second half of the 22nd century, th...</td>\n",
       "      <td>[Set, in, the, second, half, of, the, 22nd, ce...</td>\n",
       "      <td>[Set in the second half of the 22nd century, t...</td>\n",
       "      <td>[[Set, in, the, second, half, of, the, 22nd, c...</td>\n",
       "      <td>[set, second, half, century, film, depict, mar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A series of murders of rich young women throug...</td>\n",
       "      <td>[A, series, of, murders, of, rich, young, wome...</td>\n",
       "      <td>[A series of murders of rich young women throu...</td>\n",
       "      <td>[[A, series, of, murders, of, rich, young, wom...</td>\n",
       "      <td>[series, murder, woman, throughout, arizona, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Eva, an upper class housewife, becomes frustra...</td>\n",
       "      <td>[Eva, ,, an, upper, class, housewife, ,, becom...</td>\n",
       "      <td>[Eva, an upper class housewife, becomes frustr...</td>\n",
       "      <td>[[Eva, ,, an, upper, class, housewife, ,, beco...</td>\n",
       "      <td>[upper, class, housewife, becomes, frustrated,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Plot  \\\n",
       "0  Set in the second half of the 22nd century, th...   \n",
       "1                                                NaN   \n",
       "2                                                NaN   \n",
       "3  A series of murders of rich young women throug...   \n",
       "4  Eva, an upper class housewife, becomes frustra...   \n",
       "\n",
       "                                          words_punc  \\\n",
       "0  [Set, in, the, second, half, of, the, 22nd, ce...   \n",
       "1                                                NaN   \n",
       "2                                                NaN   \n",
       "3  [A, series, of, murders, of, rich, young, wome...   \n",
       "4  [Eva, ,, an, upper, class, housewife, ,, becom...   \n",
       "\n",
       "                                           sentences  \\\n",
       "0  [Set in the second half of the 22nd century, t...   \n",
       "1                                                NaN   \n",
       "2                                                NaN   \n",
       "3  [A series of murders of rich young women throu...   \n",
       "4  [Eva, an upper class housewife, becomes frustr...   \n",
       "\n",
       "                                    tokens_sentences  \\\n",
       "0  [[Set, in, the, second, half, of, the, 22nd, c...   \n",
       "1                                                NaN   \n",
       "2                                                NaN   \n",
       "3  [[A, series, of, murders, of, rich, young, wom...   \n",
       "4  [[Eva, ,, an, upper, class, housewife, ,, beco...   \n",
       "\n",
       "                                              tokens  \n",
       "0  [set, second, half, century, film, depict, mar...  \n",
       "1                                                NaN  \n",
       "2                                                NaN  \n",
       "3  [series, murder, woman, throughout, arizona, d...  \n",
       "4  [upper, class, housewife, becomes, frustrated,...  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies[['Plot','words_punc','sentences','tokens_sentences','tokens']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "46a23b34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set in the second half of the 22nd century, the film depicts Mars as a planet that has been 84% terraformed, allowing humans to walk on the surface without wearing pressure suits. The Martian society has become largely matriarchal, with women in most positions of authority. The story concerns a police officer, Melanie Ballard , second in command of a small team alongside Sergeant Jericho  sent to pick up and transport a prisoner named Desolation Williams . Arriving at the remote mining town where Williams is being held, Ballard finds virtually all of the people missing. She learns that the miners had discovered an underground doorway created by an ancient Martian civilization. When the door was opened it released \"ghosts,\" disembodied spirits which possessed the miners. Violence ensues, as the possessed miners commit horrific acts of death and destruction, as well as self-mutilation. With their team leader Helena Bradock  murdered, Ballard must fight off the attacking miners, escape the town, and destroy the ghosts, if possible. Unfortunately, her intentions are complicated by the fact that killing a possessed human merely releases the Martian spirit to possess another human. The team eventually decides to blow up a nuclear reactor to try and vaporize all of the ghosts. At several points in the film Sergeant Jericho shows a romantic interest in Ballard, mostly unreciprocated. Ballard's crew along with survivors who manage to gather in the jail are eventually wiped out by the miners after many fierce battles and events , leaving only her and Williams after Sergeant Jericho and the other remaining officers and the two operators of the train are killed upon returning from a brief retreat to finish the fight. Not wanting the authorities to blame the massacre on him, he handcuffs Ballard to her cot and escapes from the train, leaving her to return home and deliver her report, which is received with skepticism by her superiors. While Ballard recuperates at a hospital, the released spirits, who weren't destroyed after all, attack the city. The end scene sets the movie up for a sequel as Williams returns to team up with Ballard to fight the possessed.\n"
     ]
    }
   ],
   "source": [
    "print(movies['Plot'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "860bd599",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[('Set', 'NN'), ('in', 'IN'), ('the', 'DT'), ('second', 'JJ'), ('half', 'NN'), ('of', 'IN'), ('the', 'DT'), ('22nd', 'JJ'), ('century', 'NN'), (',', ','), ('the', 'DT'), ('film', 'NN'), ('depicts', 'VBZ'), ('Mars', 'NNP'), ('as', 'IN'), ('a', 'DT'), ('planet', 'NN'), ('that', 'WDT'), ('has', 'VBZ'), ('been', 'VBN'), ('84', 'CD'), ('%', 'NN'), ('terraformed', 'VBN'), (',', ','), ('allowing', 'VBG'), ('humans', 'NNS'), ('to', 'TO'), ('walk', 'VB'), ('on', 'IN'), ('the', 'DT'), ('surface', 'NN'), ('without', 'IN'), ('wearing', 'VBG'), ('pressure', 'NN'), ('suits', 'NNS'), ('.', '.')], [('The', 'DT'), ('Martian', 'JJ'), ('society', 'NN'), ('has', 'VBZ'), ('become', 'VBN'), ('largely', 'RB'), ('matriarchal', 'JJ'), (',', ','), ('with', 'IN'), ('women', 'NNS'), ('in', 'IN'), ('most', 'JJS'), ('positions', 'NNS'), ('of', 'IN'), ('authority', 'NN'), ('.', '.')], [('The', 'DT'), ('story', 'NN'), ('concerns', 'VBZ'), ('a', 'DT'), ('police', 'NN'), ('officer', 'NN'), (',', ','), ('Melanie', 'NNP'), ('Ballard', 'NNP'), (',', ','), ('second', 'JJ'), ('in', 'IN'), ('command', 'NN'), ('of', 'IN'), ('a', 'DT'), ('small', 'JJ'), ('team', 'NN'), ('alongside', 'RB'), ('Sergeant', 'NNP'), ('Jericho', 'NNP'), ('sent', 'VBD'), ('to', 'TO'), ('pick', 'VB'), ('up', 'RP'), ('and', 'CC'), ('transport', 'VB'), ('a', 'DT'), ('prisoner', 'NN'), ('named', 'VBN'), ('Desolation', 'NNP'), ('Williams', 'NNP'), ('.', '.')], [('Arriving', 'VBG'), ('at', 'IN'), ('the', 'DT'), ('remote', 'JJ'), ('mining', 'NN'), ('town', 'NN'), ('where', 'WRB'), ('Williams', 'NNP'), ('is', 'VBZ'), ('being', 'VBG'), ('held', 'VBN'), (',', ','), ('Ballard', 'NNP'), ('finds', 'VBZ'), ('virtually', 'RB'), ('all', 'DT'), ('of', 'IN'), ('the', 'DT'), ('people', 'NNS'), ('missing', 'VBG'), ('.', '.')], [('She', 'PRP'), ('learns', 'VBZ'), ('that', 'IN'), ('the', 'DT'), ('miners', 'NNS'), ('had', 'VBD'), ('discovered', 'VBN'), ('an', 'DT'), ('underground', 'JJ'), ('doorway', 'NN'), ('created', 'VBN'), ('by', 'IN'), ('an', 'DT'), ('ancient', 'JJ'), ('Martian', 'JJ'), ('civilization', 'NN'), ('.', '.')], [('When', 'WRB'), ('the', 'DT'), ('door', 'NN'), ('was', 'VBD'), ('opened', 'VBN'), ('it', 'PRP'), ('released', 'VBD'), ('``', '``'), ('ghosts', 'NNS'), (',', ','), (\"''\", \"''\"), ('disembodied', 'VBD'), ('spirits', 'NNS'), ('which', 'WDT'), ('possessed', 'VBD'), ('the', 'DT'), ('miners', 'NNS'), ('.', '.')], [('Violence', 'NN'), ('ensues', 'NNS'), (',', ','), ('as', 'IN'), ('the', 'DT'), ('possessed', 'JJ'), ('miners', 'NNS'), ('commit', 'VBP'), ('horrific', 'JJ'), ('acts', 'NNS'), ('of', 'IN'), ('death', 'NN'), ('and', 'CC'), ('destruction', 'NN'), (',', ','), ('as', 'RB'), ('well', 'RB'), ('as', 'IN'), ('self-mutilation', 'NN'), ('.', '.')], [('With', 'IN'), ('their', 'PRP$'), ('team', 'NN'), ('leader', 'NN'), ('Helena', 'NNP'), ('Bradock', 'NNP'), ('murdered', 'VBD'), (',', ','), ('Ballard', 'NNP'), ('must', 'MD'), ('fight', 'VB'), ('off', 'RP'), ('the', 'DT'), ('attacking', 'VBG'), ('miners', 'NNS'), (',', ','), ('escape', 'VBP'), ('the', 'DT'), ('town', 'NN'), (',', ','), ('and', 'CC'), ('destroy', 'VB'), ('the', 'DT'), ('ghosts', 'NNS'), (',', ','), ('if', 'IN'), ('possible', 'JJ'), ('.', '.')], [('Unfortunately', 'RB'), (',', ','), ('her', 'PRP'), ('intentions', 'NNS'), ('are', 'VBP'), ('complicated', 'VBN'), ('by', 'IN'), ('the', 'DT'), ('fact', 'NN'), ('that', 'IN'), ('killing', 'VBG'), ('a', 'DT'), ('possessed', 'JJ'), ('human', 'NN'), ('merely', 'RB'), ('releases', 'VBZ'), ('the', 'DT'), ('Martian', 'JJ'), ('spirit', 'NN'), ('to', 'TO'), ('possess', 'VB'), ('another', 'DT'), ('human', 'NN'), ('.', '.')], [('The', 'DT'), ('team', 'NN'), ('eventually', 'RB'), ('decides', 'VBZ'), ('to', 'TO'), ('blow', 'VB'), ('up', 'RP'), ('a', 'DT'), ('nuclear', 'JJ'), ('reactor', 'NN'), ('to', 'TO'), ('try', 'VB'), ('and', 'CC'), ('vaporize', 'VB'), ('all', 'DT'), ('of', 'IN'), ('the', 'DT'), ('ghosts', 'NNS'), ('.', '.')], [('At', 'IN'), ('several', 'JJ'), ('points', 'NNS'), ('in', 'IN'), ('the', 'DT'), ('film', 'NN'), ('Sergeant', 'NNP'), ('Jericho', 'NNP'), ('shows', 'VBZ'), ('a', 'DT'), ('romantic', 'JJ'), ('interest', 'NN'), ('in', 'IN'), ('Ballard', 'NNP'), (',', ','), ('mostly', 'RB'), ('unreciprocated', 'JJ'), ('.', '.')], [('Ballard', 'NNP'), (\"'s\", 'POS'), ('crew', 'NN'), ('along', 'IN'), ('with', 'IN'), ('survivors', 'NNS'), ('who', 'WP'), ('manage', 'VBP'), ('to', 'TO'), ('gather', 'VB'), ('in', 'IN'), ('the', 'DT'), ('jail', 'NN'), ('are', 'VBP'), ('eventually', 'RB'), ('wiped', 'VBN'), ('out', 'RP'), ('by', 'IN'), ('the', 'DT'), ('miners', 'NNS'), ('after', 'IN'), ('many', 'JJ'), ('fierce', 'JJ'), ('battles', 'NNS'), ('and', 'CC'), ('events', 'NNS'), (',', ','), ('leaving', 'VBG'), ('only', 'RB'), ('her', 'PRP$'), ('and', 'CC'), ('Williams', 'NNP'), ('after', 'IN'), ('Sergeant', 'NNP'), ('Jericho', 'NNP'), ('and', 'CC'), ('the', 'DT'), ('other', 'JJ'), ('remaining', 'VBG'), ('officers', 'NNS'), ('and', 'CC'), ('the', 'DT'), ('two', 'CD'), ('operators', 'NNS'), ('of', 'IN'), ('the', 'DT'), ('train', 'NN'), ('are', 'VBP'), ('killed', 'VBN'), ('upon', 'IN'), ('returning', 'VBG'), ('from', 'IN'), ('a', 'DT'), ('brief', 'JJ'), ('retreat', 'NN'), ('to', 'TO'), ('finish', 'VB'), ('the', 'DT'), ('fight', 'NN'), ('.', '.')], [('Not', 'RB'), ('wanting', 'VBG'), ('the', 'DT'), ('authorities', 'NNS'), ('to', 'TO'), ('blame', 'VB'), ('the', 'DT'), ('massacre', 'NN'), ('on', 'IN'), ('him', 'PRP'), (',', ','), ('he', 'PRP'), ('handcuffs', 'VBZ'), ('Ballard', 'NNP'), ('to', 'TO'), ('her', 'PRP$'), ('cot', 'NN'), ('and', 'CC'), ('escapes', 'NNS'), ('from', 'IN'), ('the', 'DT'), ('train', 'NN'), (',', ','), ('leaving', 'VBG'), ('her', 'PRP$'), ('to', 'TO'), ('return', 'VB'), ('home', 'NN'), ('and', 'CC'), ('deliver', 'VB'), ('her', 'PRP$'), ('report', 'NN'), (',', ','), ('which', 'WDT'), ('is', 'VBZ'), ('received', 'VBN'), ('with', 'IN'), ('skepticism', 'NN'), ('by', 'IN'), ('her', 'PRP$'), ('superiors', 'NNS'), ('.', '.')], [('While', 'IN'), ('Ballard', 'NNP'), ('recuperates', 'VBZ'), ('at', 'IN'), ('a', 'DT'), ('hospital', 'NN'), (',', ','), ('the', 'DT'), ('released', 'JJ'), ('spirits', 'NNS'), (',', ','), ('who', 'WP'), ('were', 'VBD'), (\"n't\", 'RB'), ('destroyed', 'VBN'), ('after', 'IN'), ('all', 'DT'), (',', ','), ('attack', 'VBP'), ('the', 'DT'), ('city', 'NN'), ('.', '.')], [('The', 'DT'), ('end', 'NN'), ('scene', 'NN'), ('sets', 'VBZ'), ('the', 'DT'), ('movie', 'NN'), ('up', 'RP'), ('for', 'IN'), ('a', 'DT'), ('sequel', 'NN'), ('as', 'IN'), ('Williams', 'NNP'), ('returns', 'VBZ'), ('to', 'TO'), ('team', 'VB'), ('up', 'RP'), ('with', 'IN'), ('Ballard', 'NNP'), ('to', 'TO'), ('fight', 'VB'), ('the', 'DT'), ('possessed', 'VBN'), ('.', '.')]]\n"
     ]
    }
   ],
   "source": [
    "print(movies['POS_tokens'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "28708c37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Set', 'in', 'the', 'second', 'half', 'of', 'the', '22nd', 'century', ',', 'the', 'film', 'depict', 'Mars', 'as', 'a', 'planet', 'that', 'have', 'be', '84', '%', 'terraformed', ',', 'allow', 'human', 'to', 'walk', 'on', 'the', 'surface', 'without', 'wear', 'pressure', 'suit', '.'], ['The', 'Martian', 'society', 'have', 'become', 'largely', 'matriarchal', ',', 'with', 'woman', 'in', 'most', 'position', 'of', 'authority', '.'], ['The', 'story', 'concern', 'a', 'police', 'officer', ',', 'Melanie', 'Ballard', ',', 'second', 'in', 'command', 'of', 'a', 'small', 'team', 'alongside', 'Sergeant', 'Jericho', 'send', 'to', 'pick', 'up', 'and', 'transport', 'a', 'prisoner', 'name', 'Desolation', 'Williams', '.'], ['Arriving', 'at', 'the', 'remote', 'mining', 'town', 'where', 'Williams', 'be', 'be', 'hold', ',', 'Ballard', 'find', 'virtually', 'all', 'of', 'the', 'people', 'miss', '.'], ['She', 'learn', 'that', 'the', 'miner', 'have', 'discover', 'an', 'underground', 'doorway', 'create', 'by', 'an', 'ancient', 'Martian', 'civilization', '.'], ['When', 'the', 'door', 'be', 'open', 'it', 'release', '``', 'ghost', ',', \"''\", 'disembody', 'spirit', 'which', 'possess', 'the', 'miner', '.'], ['Violence', 'ensues', ',', 'as', 'the', 'possessed', 'miner', 'commit', 'horrific', 'act', 'of', 'death', 'and', 'destruction', ',', 'as', 'well', 'as', 'self-mutilation', '.'], ['With', 'their', 'team', 'leader', 'Helena', 'Bradock', 'murder', ',', 'Ballard', 'must', 'fight', 'off', 'the', 'attack', 'miner', ',', 'escape', 'the', 'town', ',', 'and', 'destroy', 'the', 'ghost', ',', 'if', 'possible', '.'], ['Unfortunately', ',', 'her', 'intention', 'be', 'complicate', 'by', 'the', 'fact', 'that', 'kill', 'a', 'possessed', 'human', 'merely', 'release', 'the', 'Martian', 'spirit', 'to', 'possess', 'another', 'human', '.'], ['The', 'team', 'eventually', 'decide', 'to', 'blow', 'up', 'a', 'nuclear', 'reactor', 'to', 'try', 'and', 'vaporize', 'all', 'of', 'the', 'ghost', '.'], ['At', 'several', 'point', 'in', 'the', 'film', 'Sergeant', 'Jericho', 'show', 'a', 'romantic', 'interest', 'in', 'Ballard', ',', 'mostly', 'unreciprocated', '.'], ['Ballard', \"'s\", 'crew', 'along', 'with', 'survivor', 'who', 'manage', 'to', 'gather', 'in', 'the', 'jail', 'be', 'eventually', 'wipe', 'out', 'by', 'the', 'miner', 'after', 'many', 'fierce', 'battle', 'and', 'event', ',', 'leave', 'only', 'her', 'and', 'Williams', 'after', 'Sergeant', 'Jericho', 'and', 'the', 'other', 'remain', 'officer', 'and', 'the', 'two', 'operator', 'of', 'the', 'train', 'be', 'kill', 'upon', 'return', 'from', 'a', 'brief', 'retreat', 'to', 'finish', 'the', 'fight', '.'], ['Not', 'want', 'the', 'authority', 'to', 'blame', 'the', 'massacre', 'on', 'him', ',', 'he', 'handcuff', 'Ballard', 'to', 'her', 'cot', 'and', 'escape', 'from', 'the', 'train', ',', 'leave', 'her', 'to', 'return', 'home', 'and', 'deliver', 'her', 'report', ',', 'which', 'be', 'receive', 'with', 'skepticism', 'by', 'her', 'superior', '.'], ['While', 'Ballard', 'recuperate', 'at', 'a', 'hospital', ',', 'the', 'released', 'spirit', ',', 'who', 'be', \"n't\", 'destroy', 'after', 'all', ',', 'attack', 'the', 'city', '.'], ['The', 'end', 'scene', 'set', 'the', 'movie', 'up', 'for', 'a', 'sequel', 'as', 'Williams', 'return', 'to', 'team', 'up', 'with', 'Ballard', 'to', 'fight', 'the', 'possess', '.']]\n"
     ]
    }
   ],
   "source": [
    "print(movies['tokens_sentences_lemmatized'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cad52ee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['set', 'second', 'half', 'century', 'film', 'depict', 'mars', 'planet', 'terraformed', 'allow', 'human', 'walk', 'surface', 'without', 'wear', 'pressure', 'suit', 'martian', 'society', 'largely', 'matriarchal', 'woman', 'position', 'authority', 'story', 'concern', 'police', 'officer', 'ballard', 'second', 'command', 'small', 'team', 'alongside', 'sergeant', 'jericho', 'send', 'pick', 'transport', 'prisoner', 'name', 'desolation', 'arriving', 'remote', 'mining', 'town', 'hold', 'ballard', 'virtually', 'people', 'miss', 'learn', 'miner', 'discover', 'underground', 'doorway', 'create', 'ancient', 'martian', 'civilization', 'door', 'open', 'release', 'ghost', 'disembody', 'spirit', 'possess', 'miner', 'violence', 'ensues', 'possessed', 'miner', 'commit', 'horrific', 'act', 'death', 'destruction', 'well', 'team', 'leader', 'bradock', 'murder', 'ballard', 'must', 'fight', 'attack', 'miner', 'escape', 'town', 'destroy', 'ghost', 'possible', 'unfortunately', 'intention', 'complicate', 'fact', 'kill', 'possessed', 'human', 'merely', 'release', 'martian', 'spirit', 'possess', 'another', 'human', 'team', 'eventually', 'decide', 'blow', 'nuclear', 'reactor', 'vaporize', 'ghost', 'several', 'point', 'film', 'sergeant', 'jericho', 'show', 'romantic', 'interest', 'ballard', 'mostly', 'unreciprocated', 'ballard', 'crew', 'along', 'survivor', 'manage', 'gather', 'jail', 'eventually', 'wipe', 'miner', 'many', 'fierce', 'battle', 'event', 'sergeant', 'jericho', 'remain', 'officer', 'operator', 'train', 'kill', 'upon', 'return', 'brief', 'retreat', 'finish', 'fight', 'want', 'authority', 'blame', 'massacre', 'handcuff', 'ballard', 'cot', 'escape', 'train', 'return', 'home', 'deliver', 'report', 'receive', 'skepticism', 'superior', 'ballard', 'recuperate', 'hospital', 'released', 'spirit', 'destroy', 'attack', 'city', 'end', 'scene', 'set', 'movie', 'sequel', 'return', 'team', 'ballard', 'fight', 'possess']\n"
     ]
    }
   ],
   "source": [
    "print(movies['tokens'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c416d9fa",
   "metadata": {},
   "source": [
    "#### Saving `movies`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9733e250",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('data', exist_ok=True)  \n",
    "movies.to_pickle('data/movies_aug.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84cd5486",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = pd.read_pickle('data/movies_aug.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf3ecdb6",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2.2 Importing Metascore  <a id='2.2'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a284815f",
   "metadata": {},
   "source": [
    "When considering film rating, we can think about using the IMDb database. In particular, it provides the variable `averageRating` which is the weighted average of all the individual user ratings. However, IMDb user opinions can be given whenever the user wants. So, the ratings of IMDb do not match with the release date of the movie. It only works for analyzing the current opinions, as very recent reviews and can be written for an old film. \n",
    "\n",
    "In order to have an insigth into the movie impression at a time closer to the release date, we can consider metascore. [Metascore](https://github.com/miazhx/metacritic) is a weighted average of reviews from top published critic reviews for a given movie, and thus does not include any votes or comments from our users.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "694bfb38-e7d7-44d6-906d-c0afe62a2574",
   "metadata": {},
   "source": [
    "#### Metacritic dataset loading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "400f0855",
   "metadata": {},
   "source": [
    "We use a dataset which brings together the film title, release date, metascore and other scores. We load it and add the `metascore` information into the `movie` dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bd623c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "metacritic_url = \"https://raw.githubusercontent.com/miazhx/metacritic/master/data/metacritic_movies.csv\"\n",
    "\n",
    "metacritic = pd.read_csv(metacritic_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "af68bc44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_title</th>\n",
       "      <th>release_date</th>\n",
       "      <th>genre</th>\n",
       "      <th>meta_mixed</th>\n",
       "      <th>meta_negative</th>\n",
       "      <th>meta_positive</th>\n",
       "      <th>metascore</th>\n",
       "      <th>user_mixed</th>\n",
       "      <th>user_negative</th>\n",
       "      <th>user_positive</th>\n",
       "      <th>userscore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Anatomy of a Murder</td>\n",
       "      <td>1-Jul-59</td>\n",
       "      <td>Drama,Mystery,Thriller,Crime</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>95</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>tbd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bringing Up Baby</td>\n",
       "      <td>18-Feb-38</td>\n",
       "      <td>Comedy,Romance,Family</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>91</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>tbd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>After Life</td>\n",
       "      <td>12-May-99</td>\n",
       "      <td>Drama,Fantasy</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>91</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>tbd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gavagai</td>\n",
       "      <td>3-Aug-18</td>\n",
       "      <td>Drama</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>91</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>tbd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Hustler</td>\n",
       "      <td>25-Sep-61</td>\n",
       "      <td>Drama,Sport</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>tbd</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           movie_title release_date                         genre  meta_mixed  \\\n",
       "0  Anatomy of a Murder     1-Jul-59  Drama,Mystery,Thriller,Crime           0   \n",
       "1     Bringing Up Baby    18-Feb-38         Comedy,Romance,Family           0   \n",
       "2           After Life    12-May-99                 Drama,Fantasy           0   \n",
       "3              Gavagai     3-Aug-18                         Drama           1   \n",
       "4          The Hustler    25-Sep-61                   Drama,Sport           1   \n",
       "\n",
       "   meta_negative  meta_positive  metascore user_mixed user_negative  \\\n",
       "0              0             15         95          0             0   \n",
       "1              1             16         91          1             0   \n",
       "2              0             19         91          0             2   \n",
       "3              0              6         91          0             1   \n",
       "4              0             17         90          0             0   \n",
       "\n",
       "  user_positive userscore  \n",
       "0             3       tbd  \n",
       "1             2       tbd  \n",
       "2             1       tbd  \n",
       "3             2       tbd  \n",
       "4             3       tbd  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metacritic.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f785b867-462f-434b-8f9c-0550a7295133",
   "metadata": {},
   "source": [
    "#### Missing value check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4106617f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing metascore in metacritic dataset: 0\n"
     ]
    }
   ],
   "source": [
    "print('Number of missing metascore in metacritic dataset: {}'.format(metacritic['metascore'].isna().sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "014281ff-59db-414f-8ea6-a0a0e99a00b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 9121 metascores for 81741 movies (including 42176 with plot summary available).\n"
     ]
    }
   ],
   "source": [
    "print('There are {} metascores for {} movies (including {} with plot summary available).'.format(len(metacritic),len(movies), (len(movies)-movies.Plot.isna().sum())))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14ba8920-9cef-4da5-b030-c207ae08ce59",
   "metadata": {},
   "source": [
    "#### Sub-dataset with the features we are interested in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9b352ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "metacritic_score = metacritic[['movie_title','metascore','release_date']].rename(columns = {'movie_title':'Title'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "daf60d1c-289d-49b3-8018-167447b572ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>metascore</th>\n",
       "      <th>release_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Anatomy of a Murder</td>\n",
       "      <td>95</td>\n",
       "      <td>1-Jul-59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bringing Up Baby</td>\n",
       "      <td>91</td>\n",
       "      <td>18-Feb-38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>After Life</td>\n",
       "      <td>91</td>\n",
       "      <td>12-May-99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Title  metascore release_date\n",
       "0  Anatomy of a Murder         95     1-Jul-59\n",
       "1     Bringing Up Baby         91    18-Feb-38\n",
       "2           After Life         91    12-May-99"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metacritic_score.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "14cb61b7-4504-43d1-ab6d-f504f710425a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1-Jul-59\n",
       "Name: release_date, dtype: object"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metacritic_score.release_date[[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "6930b58f-3275-45d6-89df-a0b0dac6a983",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0   2059-07-01\n",
       "Name: release_date, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date=pd.to_datetime(metacritic_score.release_date[[0]], format='%d-%b-%y')\n",
    "date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "65cef74a-59de-406b-b0e0-3dbee2e4c2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "metacritic['release_date_'] = pd.to_datetime(metacritic['release_date'], format='%d-%b-%y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "9822a7ea-ac86-42a3-8070-1f72f8d99891",
   "metadata": {},
   "outputs": [],
   "source": [
    "metacritic['year_last_digits']=metacritic['release_date_'].apply( lambda x: x.year-2000 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b2ea2856-bae2-4cc9-abd7-218a3eb9f653",
   "metadata": {},
   "outputs": [
    {
     "ename": "OutOfBoundsDatetime",
     "evalue": "Out of bounds nanosecond timestamp: 1010-12-02 00:00:00",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m/opt/anaconda3/envs/ada/lib/python3.9/site-packages/pandas/core/arrays/datetimes.py:2236\u001b[0m, in \u001b[0;36mobjects_to_datetime64ns\u001b[0;34m(data, dayfirst, yearfirst, utc, errors, require_iso8601, allow_object, allow_mixed)\u001b[0m\n\u001b[1;32m   2235\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 2236\u001b[0m     values, tz_parsed \u001b[38;5;241m=\u001b[39m \u001b[43mconversion\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdatetime_to_datetime64\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mravel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mK\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2237\u001b[0m     \u001b[38;5;66;03m# If tzaware, these values represent unix timestamps, so we\u001b[39;00m\n\u001b[1;32m   2238\u001b[0m     \u001b[38;5;66;03m#  return them as i8 to distinguish from wall times\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ada/lib/python3.9/site-packages/pandas/_libs/tslibs/conversion.pyx:360\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.conversion.datetime_to_datetime64\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Unrecognized value type: <class 'str'>",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mOutOfBoundsDatetime\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [59]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_datetime\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmovies\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mReleaseDate\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mhead()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ada/lib/python3.9/site-packages/pandas/core/tools/datetimes.py:1051\u001b[0m, in \u001b[0;36mto_datetime\u001b[0;34m(arg, errors, dayfirst, yearfirst, utc, format, exact, unit, infer_datetime_format, origin, cache)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         result \u001b[38;5;241m=\u001b[39m arg\u001b[38;5;241m.\u001b[39mmap(cache_array)\n\u001b[1;32m   1050\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1051\u001b[0m         values \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_listlike\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1052\u001b[0m         result \u001b[38;5;241m=\u001b[39m arg\u001b[38;5;241m.\u001b[39m_constructor(values, index\u001b[38;5;241m=\u001b[39marg\u001b[38;5;241m.\u001b[39mindex, name\u001b[38;5;241m=\u001b[39marg\u001b[38;5;241m.\u001b[39mname)\n\u001b[1;32m   1053\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arg, (ABCDataFrame, abc\u001b[38;5;241m.\u001b[39mMutableMapping)):\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ada/lib/python3.9/site-packages/pandas/core/tools/datetimes.py:402\u001b[0m, in \u001b[0;36m_convert_listlike_datetimes\u001b[0;34m(arg, format, name, tz, unit, errors, infer_datetime_format, dayfirst, yearfirst, exact)\u001b[0m\n\u001b[1;32m    400\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m infer_datetime_format\n\u001b[1;32m    401\u001b[0m utc \u001b[38;5;241m=\u001b[39m tz \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutc\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 402\u001b[0m result, tz_parsed \u001b[38;5;241m=\u001b[39m \u001b[43mobjects_to_datetime64ns\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    403\u001b[0m \u001b[43m    \u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    404\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdayfirst\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdayfirst\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    405\u001b[0m \u001b[43m    \u001b[49m\u001b[43myearfirst\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43myearfirst\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    406\u001b[0m \u001b[43m    \u001b[49m\u001b[43mutc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mutc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    407\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    408\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequire_iso8601\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequire_iso8601\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    409\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_object\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    410\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    412\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tz_parsed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    413\u001b[0m     \u001b[38;5;66;03m# We can take a shortcut since the datetime64 numpy array\u001b[39;00m\n\u001b[1;32m    414\u001b[0m     \u001b[38;5;66;03m# is in UTC\u001b[39;00m\n\u001b[1;32m    415\u001b[0m     dta \u001b[38;5;241m=\u001b[39m DatetimeArray(result, dtype\u001b[38;5;241m=\u001b[39mtz_to_dtype(tz_parsed))\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ada/lib/python3.9/site-packages/pandas/core/arrays/datetimes.py:2242\u001b[0m, in \u001b[0;36mobjects_to_datetime64ns\u001b[0;34m(data, dayfirst, yearfirst, utc, errors, require_iso8601, allow_object, allow_mixed)\u001b[0m\n\u001b[1;32m   2240\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m values\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mi8\u001b[39m\u001b[38;5;124m\"\u001b[39m), tz_parsed\n\u001b[1;32m   2241\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m):\n\u001b[0;32m-> 2242\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[1;32m   2244\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tz_parsed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2245\u001b[0m     \u001b[38;5;66;03m# We can take a shortcut since the datetime64 numpy array\u001b[39;00m\n\u001b[1;32m   2246\u001b[0m     \u001b[38;5;66;03m#  is in UTC\u001b[39;00m\n\u001b[1;32m   2247\u001b[0m     \u001b[38;5;66;03m# Return i8 values to denote unix timestamps\u001b[39;00m\n\u001b[1;32m   2248\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mi8\u001b[39m\u001b[38;5;124m\"\u001b[39m), tz_parsed\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ada/lib/python3.9/site-packages/pandas/core/arrays/datetimes.py:2224\u001b[0m, in \u001b[0;36mobjects_to_datetime64ns\u001b[0;34m(data, dayfirst, yearfirst, utc, errors, require_iso8601, allow_object, allow_mixed)\u001b[0m\n\u001b[1;32m   2222\u001b[0m order: Literal[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mF\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mF\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m flags\u001b[38;5;241m.\u001b[39mf_contiguous \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2223\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 2224\u001b[0m     result, tz_parsed \u001b[38;5;241m=\u001b[39m \u001b[43mtslib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray_to_datetime\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2225\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mravel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mK\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2226\u001b[0m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2227\u001b[0m \u001b[43m        \u001b[49m\u001b[43mutc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mutc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2228\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdayfirst\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdayfirst\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2229\u001b[0m \u001b[43m        \u001b[49m\u001b[43myearfirst\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43myearfirst\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2230\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequire_iso8601\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequire_iso8601\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2231\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_mixed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_mixed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2232\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2233\u001b[0m     result \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39mreshape(data\u001b[38;5;241m.\u001b[39mshape, order\u001b[38;5;241m=\u001b[39morder)\n\u001b[1;32m   2234\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ada/lib/python3.9/site-packages/pandas/_libs/tslib.pyx:381\u001b[0m, in \u001b[0;36mpandas._libs.tslib.array_to_datetime\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ada/lib/python3.9/site-packages/pandas/_libs/tslib.pyx:608\u001b[0m, in \u001b[0;36mpandas._libs.tslib.array_to_datetime\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ada/lib/python3.9/site-packages/pandas/_libs/tslib.pyx:604\u001b[0m, in \u001b[0;36mpandas._libs.tslib.array_to_datetime\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ada/lib/python3.9/site-packages/pandas/_libs/tslib.pyx:580\u001b[0m, in \u001b[0;36mpandas._libs.tslib.array_to_datetime\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ada/lib/python3.9/site-packages/pandas/_libs/tslibs/np_datetime.pyx:120\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.np_datetime.check_dts_bounds\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mOutOfBoundsDatetime\u001b[0m: Out of bounds nanosecond timestamp: 1010-12-02 00:00:00"
     ]
    }
   ],
   "source": [
    "pd.to_datetime(movies['ReleaseDate']).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4b1b7388-b0d6-45a3-bf95-dd43c510de55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>metascore</th>\n",
       "      <th>release_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Anatomy of a Murder</td>\n",
       "      <td>95</td>\n",
       "      <td>1-Jul-59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bringing Up Baby</td>\n",
       "      <td>91</td>\n",
       "      <td>18-Feb-38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>After Life</td>\n",
       "      <td>91</td>\n",
       "      <td>12-May-99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Title  metascore release_date\n",
       "0  Anatomy of a Murder         95     1-Jul-59\n",
       "1     Bringing Up Baby         91    18-Feb-38\n",
       "2           After Life         91    12-May-99"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metacritic_score.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a40ef0b7-5143-4ebd-8ace-f2e9aa9bbb47",
   "metadata": {},
   "outputs": [],
   "source": [
    "metacritic['release_date'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "b6537a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trying to convert release_date to date time, in order to compare the movies release date and the metacritic release date\n",
    "# => handle metascore for the movie series (same title but different release date)\n",
    "#metacritic_score[\"release_date\"] = metacritic_score[\"release_date\"].apply( lambda x:'{:%Y-%m-%d}'.format(x.replace(\" \", \"\").strptime(no_space, '%d''%B''%Y')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2660491f",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'strptime'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [56]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmetacritic_score\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrelease_date\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m{\u001b[39;49m\u001b[38;5;124;43m:\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mY-\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mm-\u001b[39;49m\u001b[38;5;132;43;01m%d\u001b[39;49;00m\u001b[38;5;124;43m}\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreplace\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstrptime\u001b[49m\u001b[43m(\u001b[49m\u001b[43mno_space\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m%d\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mB\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mY\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mhead()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ada/lib/python3.9/site-packages/pandas/core/series.py:4433\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[1;32m   4323\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[1;32m   4324\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   4325\u001b[0m     func: AggFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4328\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   4329\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[1;32m   4330\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4331\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   4332\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4431\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[1;32m   4432\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4433\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ada/lib/python3.9/site-packages/pandas/core/apply.py:1088\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1084\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m   1085\u001b[0m     \u001b[38;5;66;03m# if we are a string, try to dispatch\u001b[39;00m\n\u001b[1;32m   1086\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_str()\n\u001b[0;32m-> 1088\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ada/lib/python3.9/site-packages/pandas/core/apply.py:1143\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1137\u001b[0m         values \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m)\u001b[38;5;241m.\u001b[39m_values\n\u001b[1;32m   1138\u001b[0m         \u001b[38;5;66;03m# error: Argument 2 to \"map_infer\" has incompatible type\u001b[39;00m\n\u001b[1;32m   1139\u001b[0m         \u001b[38;5;66;03m# \"Union[Callable[..., Any], str, List[Union[Callable[..., Any], str]],\u001b[39;00m\n\u001b[1;32m   1140\u001b[0m         \u001b[38;5;66;03m# Dict[Hashable, Union[Union[Callable[..., Any], str],\u001b[39;00m\n\u001b[1;32m   1141\u001b[0m         \u001b[38;5;66;03m# List[Union[Callable[..., Any], str]]]]]\"; expected\u001b[39;00m\n\u001b[1;32m   1142\u001b[0m         \u001b[38;5;66;03m# \"Callable[[Any], Any]\"\u001b[39;00m\n\u001b[0;32m-> 1143\u001b[0m         mapped \u001b[38;5;241m=\u001b[39m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1144\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1145\u001b[0m \u001b[43m            \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m   1146\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1147\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1149\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[1;32m   1150\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[1;32m   1151\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[1;32m   1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ada/lib/python3.9/site-packages/pandas/_libs/lib.pyx:2870\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "Input \u001b[0;32mIn [56]\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[0;32m----> 1\u001b[0m metacritic_score[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrelease_date\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mapply( \u001b[38;5;28;01mlambda\u001b[39;00m x:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm-\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m}\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreplace\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstrptime\u001b[49m(no_space, \u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mB\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY\u001b[39m\u001b[38;5;124m'\u001b[39m)))\u001b[38;5;241m.\u001b[39mhead()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'strptime'"
     ]
    }
   ],
   "source": [
    "metacritic_score[\"release_date\"].apply( lambda x:'{:%Y-%m-%d}'.format(x.replace(\" \", \"\").strptime(no_space, '%d''%B''%Y'))).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cadb5a32-fcad-4c6b-ac2a-dbe4a32bbf2e",
   "metadata": {},
   "source": [
    "#### Adding metascores to the `movies` dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "704c39a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = movies.merge(metacritic_score, how=\"left\", on=\"Title\") # Not really sure how this works but there's no duplicates or sth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "8e34c676",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WikiMovieID</th>\n",
       "      <th>FreeMovieID</th>\n",
       "      <th>Title</th>\n",
       "      <th>ReleaseDate</th>\n",
       "      <th>Revenue</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Languages</th>\n",
       "      <th>Countries</th>\n",
       "      <th>Genres</th>\n",
       "      <th>Plot</th>\n",
       "      <th>lang</th>\n",
       "      <th>words_punc</th>\n",
       "      <th>sentences</th>\n",
       "      <th>tokens_sentences</th>\n",
       "      <th>POS_tokens</th>\n",
       "      <th>tokens_sentences_lemmatized</th>\n",
       "      <th>tokens</th>\n",
       "      <th>metascore</th>\n",
       "      <th>release_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>975900</td>\n",
       "      <td>/m/03vyhn</td>\n",
       "      <td>Ghosts of Mars</td>\n",
       "      <td>2001-08-24</td>\n",
       "      <td>14010832.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>[English Language]</td>\n",
       "      <td>[United States of America]</td>\n",
       "      <td>[Thriller, Science Fiction, Horror, Adventure,...</td>\n",
       "      <td>Set in the second half of the 22nd century, th...</td>\n",
       "      <td>en</td>\n",
       "      <td>[Set, in, the, second, half, of, the, 22nd, ce...</td>\n",
       "      <td>[Set in the second half of the 22nd century, t...</td>\n",
       "      <td>[[Set, in, the, second, half, of, the, 22nd, c...</td>\n",
       "      <td>[[(Set, NN), (in, IN), (the, DT), (second, JJ)...</td>\n",
       "      <td>[[Set, in, the, second, half, of, the, 22nd, c...</td>\n",
       "      <td>[set, second, half, century, film, depict, mar...</td>\n",
       "      <td>35.0</td>\n",
       "      <td>24-Aug-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3196793</td>\n",
       "      <td>/m/08yl5d</td>\n",
       "      <td>Getting Away with Murder: The JonBenét Ramsey ...</td>\n",
       "      <td>2000-02-16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>95.0</td>\n",
       "      <td>[English Language]</td>\n",
       "      <td>[United States of America]</td>\n",
       "      <td>[Mystery, Biographical film, Drama, Crime Drama]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28463795</td>\n",
       "      <td>/m/0crgdbh</td>\n",
       "      <td>Brun bitter</td>\n",
       "      <td>1988</td>\n",
       "      <td>NaN</td>\n",
       "      <td>83.0</td>\n",
       "      <td>[Norwegian Language]</td>\n",
       "      <td>[Norway]</td>\n",
       "      <td>[Crime Fiction, Drama]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9363483</td>\n",
       "      <td>/m/0285_cd</td>\n",
       "      <td>White Of The Eye</td>\n",
       "      <td>1987</td>\n",
       "      <td>NaN</td>\n",
       "      <td>110.0</td>\n",
       "      <td>[English Language]</td>\n",
       "      <td>[United Kingdom]</td>\n",
       "      <td>[Thriller, Erotic thriller, Psychological thri...</td>\n",
       "      <td>A series of murders of rich young women throug...</td>\n",
       "      <td>en</td>\n",
       "      <td>[A, series, of, murders, of, rich, young, wome...</td>\n",
       "      <td>[A series of murders of rich young women throu...</td>\n",
       "      <td>[[A, series, of, murders, of, rich, young, wom...</td>\n",
       "      <td>[[(A, DT), (series, NN), (of, IN), (murders, N...</td>\n",
       "      <td>[[A, series, of, murder, of, rich, young, woma...</td>\n",
       "      <td>[series, murder, woman, throughout, arizona, d...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>261236</td>\n",
       "      <td>/m/01mrr1</td>\n",
       "      <td>A Woman in Flames</td>\n",
       "      <td>1983</td>\n",
       "      <td>NaN</td>\n",
       "      <td>106.0</td>\n",
       "      <td>[German Language]</td>\n",
       "      <td>[Germany]</td>\n",
       "      <td>[Drama]</td>\n",
       "      <td>Eva, an upper class housewife, becomes frustra...</td>\n",
       "      <td>en</td>\n",
       "      <td>[Eva, ,, an, upper, class, housewife, ,, becom...</td>\n",
       "      <td>[Eva, an upper class housewife, becomes frustr...</td>\n",
       "      <td>[[Eva, ,, an, upper, class, housewife, ,, beco...</td>\n",
       "      <td>[[(Eva, NNP), (,, ,), (an, DT), (upper, JJ), (...</td>\n",
       "      <td>[[Eva, ,, an, upper, class, housewife, ,, beco...</td>\n",
       "      <td>[upper, class, housewife, becomes, frustrated,...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   WikiMovieID FreeMovieID                                              Title  \\\n",
       "0       975900   /m/03vyhn                                     Ghosts of Mars   \n",
       "1      3196793   /m/08yl5d  Getting Away with Murder: The JonBenét Ramsey ...   \n",
       "2     28463795  /m/0crgdbh                                        Brun bitter   \n",
       "3      9363483  /m/0285_cd                                   White Of The Eye   \n",
       "4       261236   /m/01mrr1                                  A Woman in Flames   \n",
       "\n",
       "  ReleaseDate     Revenue  Runtime             Languages  \\\n",
       "0  2001-08-24  14010832.0     98.0    [English Language]   \n",
       "1  2000-02-16         NaN     95.0    [English Language]   \n",
       "2        1988         NaN     83.0  [Norwegian Language]   \n",
       "3        1987         NaN    110.0    [English Language]   \n",
       "4        1983         NaN    106.0     [German Language]   \n",
       "\n",
       "                    Countries  \\\n",
       "0  [United States of America]   \n",
       "1  [United States of America]   \n",
       "2                    [Norway]   \n",
       "3            [United Kingdom]   \n",
       "4                   [Germany]   \n",
       "\n",
       "                                              Genres  \\\n",
       "0  [Thriller, Science Fiction, Horror, Adventure,...   \n",
       "1   [Mystery, Biographical film, Drama, Crime Drama]   \n",
       "2                             [Crime Fiction, Drama]   \n",
       "3  [Thriller, Erotic thriller, Psychological thri...   \n",
       "4                                            [Drama]   \n",
       "\n",
       "                                                Plot lang  \\\n",
       "0  Set in the second half of the 22nd century, th...   en   \n",
       "1                                                NaN  NaN   \n",
       "2                                                NaN  NaN   \n",
       "3  A series of murders of rich young women throug...   en   \n",
       "4  Eva, an upper class housewife, becomes frustra...   en   \n",
       "\n",
       "                                          words_punc  \\\n",
       "0  [Set, in, the, second, half, of, the, 22nd, ce...   \n",
       "1                                                NaN   \n",
       "2                                                NaN   \n",
       "3  [A, series, of, murders, of, rich, young, wome...   \n",
       "4  [Eva, ,, an, upper, class, housewife, ,, becom...   \n",
       "\n",
       "                                           sentences  \\\n",
       "0  [Set in the second half of the 22nd century, t...   \n",
       "1                                                NaN   \n",
       "2                                                NaN   \n",
       "3  [A series of murders of rich young women throu...   \n",
       "4  [Eva, an upper class housewife, becomes frustr...   \n",
       "\n",
       "                                    tokens_sentences  \\\n",
       "0  [[Set, in, the, second, half, of, the, 22nd, c...   \n",
       "1                                                NaN   \n",
       "2                                                NaN   \n",
       "3  [[A, series, of, murders, of, rich, young, wom...   \n",
       "4  [[Eva, ,, an, upper, class, housewife, ,, beco...   \n",
       "\n",
       "                                          POS_tokens  \\\n",
       "0  [[(Set, NN), (in, IN), (the, DT), (second, JJ)...   \n",
       "1                                                NaN   \n",
       "2                                                NaN   \n",
       "3  [[(A, DT), (series, NN), (of, IN), (murders, N...   \n",
       "4  [[(Eva, NNP), (,, ,), (an, DT), (upper, JJ), (...   \n",
       "\n",
       "                         tokens_sentences_lemmatized  \\\n",
       "0  [[Set, in, the, second, half, of, the, 22nd, c...   \n",
       "1                                                NaN   \n",
       "2                                                NaN   \n",
       "3  [[A, series, of, murder, of, rich, young, woma...   \n",
       "4  [[Eva, ,, an, upper, class, housewife, ,, beco...   \n",
       "\n",
       "                                              tokens  metascore release_date  \n",
       "0  [set, second, half, century, film, depict, mar...       35.0    24-Aug-01  \n",
       "1                                                NaN        NaN          NaN  \n",
       "2                                                NaN        NaN          NaN  \n",
       "3  [series, murder, woman, throughout, arizona, d...        NaN          NaN  \n",
       "4  [upper, class, housewife, becomes, frustrated,...        NaN          NaN  "
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "ab6273b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing metascores in movies dataset: 90.50%\n"
     ]
    }
   ],
   "source": [
    "print(\"Missing metascores in movies dataset: {:.2f}%\".format(movies['metascore'].isna().sum()/len(movies)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f0f440d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2.3 Initial analysis  <a id='2.3'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "43c9fcba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WikiMovieID</th>\n",
       "      <th>FreeMovieID</th>\n",
       "      <th>Title</th>\n",
       "      <th>ReleaseDate</th>\n",
       "      <th>Revenue</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Languages</th>\n",
       "      <th>Countries</th>\n",
       "      <th>Genres</th>\n",
       "      <th>Plot</th>\n",
       "      <th>lang</th>\n",
       "      <th>words_punc</th>\n",
       "      <th>sentences</th>\n",
       "      <th>tokens_sentences</th>\n",
       "      <th>POS_tokens</th>\n",
       "      <th>tokens_sentences_lemmatized</th>\n",
       "      <th>tokens</th>\n",
       "      <th>metascore</th>\n",
       "      <th>release_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>975900</td>\n",
       "      <td>/m/03vyhn</td>\n",
       "      <td>Ghosts of Mars</td>\n",
       "      <td>2001-08-24</td>\n",
       "      <td>14010832.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>[English Language]</td>\n",
       "      <td>[United States of America]</td>\n",
       "      <td>[Thriller, Science Fiction, Horror, Adventure,...</td>\n",
       "      <td>Set in the second half of the 22nd century, th...</td>\n",
       "      <td>en</td>\n",
       "      <td>[Set, in, the, second, half, of, the, 22nd, ce...</td>\n",
       "      <td>[Set in the second half of the 22nd century, t...</td>\n",
       "      <td>[[Set, in, the, second, half, of, the, 22nd, c...</td>\n",
       "      <td>[[(Set, NN), (in, IN), (the, DT), (second, JJ)...</td>\n",
       "      <td>[[Set, in, the, second, half, of, the, 22nd, c...</td>\n",
       "      <td>[set, second, half, century, film, depict, mar...</td>\n",
       "      <td>35.0</td>\n",
       "      <td>24-Aug-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3196793</td>\n",
       "      <td>/m/08yl5d</td>\n",
       "      <td>Getting Away with Murder: The JonBenét Ramsey ...</td>\n",
       "      <td>2000-02-16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>95.0</td>\n",
       "      <td>[English Language]</td>\n",
       "      <td>[United States of America]</td>\n",
       "      <td>[Mystery, Biographical film, Drama, Crime Drama]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28463795</td>\n",
       "      <td>/m/0crgdbh</td>\n",
       "      <td>Brun bitter</td>\n",
       "      <td>1988</td>\n",
       "      <td>NaN</td>\n",
       "      <td>83.0</td>\n",
       "      <td>[Norwegian Language]</td>\n",
       "      <td>[Norway]</td>\n",
       "      <td>[Crime Fiction, Drama]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9363483</td>\n",
       "      <td>/m/0285_cd</td>\n",
       "      <td>White Of The Eye</td>\n",
       "      <td>1987</td>\n",
       "      <td>NaN</td>\n",
       "      <td>110.0</td>\n",
       "      <td>[English Language]</td>\n",
       "      <td>[United Kingdom]</td>\n",
       "      <td>[Thriller, Erotic thriller, Psychological thri...</td>\n",
       "      <td>A series of murders of rich young women throug...</td>\n",
       "      <td>en</td>\n",
       "      <td>[A, series, of, murders, of, rich, young, wome...</td>\n",
       "      <td>[A series of murders of rich young women throu...</td>\n",
       "      <td>[[A, series, of, murders, of, rich, young, wom...</td>\n",
       "      <td>[[(A, DT), (series, NN), (of, IN), (murders, N...</td>\n",
       "      <td>[[A, series, of, murder, of, rich, young, woma...</td>\n",
       "      <td>[series, murder, woman, throughout, arizona, d...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>261236</td>\n",
       "      <td>/m/01mrr1</td>\n",
       "      <td>A Woman in Flames</td>\n",
       "      <td>1983</td>\n",
       "      <td>NaN</td>\n",
       "      <td>106.0</td>\n",
       "      <td>[German Language]</td>\n",
       "      <td>[Germany]</td>\n",
       "      <td>[Drama]</td>\n",
       "      <td>Eva, an upper class housewife, becomes frustra...</td>\n",
       "      <td>en</td>\n",
       "      <td>[Eva, ,, an, upper, class, housewife, ,, becom...</td>\n",
       "      <td>[Eva, an upper class housewife, becomes frustr...</td>\n",
       "      <td>[[Eva, ,, an, upper, class, housewife, ,, beco...</td>\n",
       "      <td>[[(Eva, NNP), (,, ,), (an, DT), (upper, JJ), (...</td>\n",
       "      <td>[[Eva, ,, an, upper, class, housewife, ,, beco...</td>\n",
       "      <td>[upper, class, housewife, becomes, frustrated,...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   WikiMovieID FreeMovieID                                              Title  \\\n",
       "0       975900   /m/03vyhn                                     Ghosts of Mars   \n",
       "1      3196793   /m/08yl5d  Getting Away with Murder: The JonBenét Ramsey ...   \n",
       "2     28463795  /m/0crgdbh                                        Brun bitter   \n",
       "3      9363483  /m/0285_cd                                   White Of The Eye   \n",
       "4       261236   /m/01mrr1                                  A Woman in Flames   \n",
       "\n",
       "  ReleaseDate     Revenue  Runtime             Languages  \\\n",
       "0  2001-08-24  14010832.0     98.0    [English Language]   \n",
       "1  2000-02-16         NaN     95.0    [English Language]   \n",
       "2        1988         NaN     83.0  [Norwegian Language]   \n",
       "3        1987         NaN    110.0    [English Language]   \n",
       "4        1983         NaN    106.0     [German Language]   \n",
       "\n",
       "                    Countries  \\\n",
       "0  [United States of America]   \n",
       "1  [United States of America]   \n",
       "2                    [Norway]   \n",
       "3            [United Kingdom]   \n",
       "4                   [Germany]   \n",
       "\n",
       "                                              Genres  \\\n",
       "0  [Thriller, Science Fiction, Horror, Adventure,...   \n",
       "1   [Mystery, Biographical film, Drama, Crime Drama]   \n",
       "2                             [Crime Fiction, Drama]   \n",
       "3  [Thriller, Erotic thriller, Psychological thri...   \n",
       "4                                            [Drama]   \n",
       "\n",
       "                                                Plot lang  \\\n",
       "0  Set in the second half of the 22nd century, th...   en   \n",
       "1                                                NaN  NaN   \n",
       "2                                                NaN  NaN   \n",
       "3  A series of murders of rich young women throug...   en   \n",
       "4  Eva, an upper class housewife, becomes frustra...   en   \n",
       "\n",
       "                                          words_punc  \\\n",
       "0  [Set, in, the, second, half, of, the, 22nd, ce...   \n",
       "1                                                NaN   \n",
       "2                                                NaN   \n",
       "3  [A, series, of, murders, of, rich, young, wome...   \n",
       "4  [Eva, ,, an, upper, class, housewife, ,, becom...   \n",
       "\n",
       "                                           sentences  \\\n",
       "0  [Set in the second half of the 22nd century, t...   \n",
       "1                                                NaN   \n",
       "2                                                NaN   \n",
       "3  [A series of murders of rich young women throu...   \n",
       "4  [Eva, an upper class housewife, becomes frustr...   \n",
       "\n",
       "                                    tokens_sentences  \\\n",
       "0  [[Set, in, the, second, half, of, the, 22nd, c...   \n",
       "1                                                NaN   \n",
       "2                                                NaN   \n",
       "3  [[A, series, of, murders, of, rich, young, wom...   \n",
       "4  [[Eva, ,, an, upper, class, housewife, ,, beco...   \n",
       "\n",
       "                                          POS_tokens  \\\n",
       "0  [[(Set, NN), (in, IN), (the, DT), (second, JJ)...   \n",
       "1                                                NaN   \n",
       "2                                                NaN   \n",
       "3  [[(A, DT), (series, NN), (of, IN), (murders, N...   \n",
       "4  [[(Eva, NNP), (,, ,), (an, DT), (upper, JJ), (...   \n",
       "\n",
       "                         tokens_sentences_lemmatized  \\\n",
       "0  [[Set, in, the, second, half, of, the, 22nd, c...   \n",
       "1                                                NaN   \n",
       "2                                                NaN   \n",
       "3  [[A, series, of, murder, of, rich, young, woma...   \n",
       "4  [[Eva, ,, an, upper, class, housewife, ,, beco...   \n",
       "\n",
       "                                              tokens  metascore release_date  \n",
       "0  [set, second, half, century, film, depict, mar...       35.0    24-Aug-01  \n",
       "1                                                NaN        NaN          NaN  \n",
       "2                                                NaN        NaN          NaN  \n",
       "3  [series, murder, woman, throughout, arizona, d...        NaN          NaN  \n",
       "4  [upper, class, housewife, becomes, frustrated,...        NaN          NaN  "
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check the state of our dataset\n",
    "movies.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f78ad43",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 2.3.1 Plot structure <a id='2.3.1'></a>\n",
    "\n",
    "Here, for each plot summary, we investigate the number of sentences, number of words, numbers of the different punctuation marks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf84136c-0550-4734-9a34-f029cf94ae4c",
   "metadata": {},
   "source": [
    "We work on the `plot_summarie` dataset, adding new columns (`plot_num_sentences`,`plot_num_words`,`plot_num_dot`,`plot_num_coma`,`plot_num_interrogation`,``````"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "20767281",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>plot_num_sentences</th>\n",
       "      <th>plot_num_words</th>\n",
       "      <th>plot_num_dot</th>\n",
       "      <th>plot_num_coma</th>\n",
       "      <th>plot_num_interrogation</th>\n",
       "      <th>plot_num_exclamation</th>\n",
       "      <th>plot_num_percentage</th>\n",
       "      <th>plot_num_semicolon</th>\n",
       "      <th>plot_num_colon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>52</td>\n",
       "      <td>789</td>\n",
       "      <td>52</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26</td>\n",
       "      <td>493</td>\n",
       "      <td>26</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>49</td>\n",
       "      <td>866</td>\n",
       "      <td>49</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15</td>\n",
       "      <td>408</td>\n",
       "      <td>15</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   plot_num_sentences  plot_num_words  plot_num_dot  plot_num_coma  \\\n",
       "0                   1              28             1              5   \n",
       "1                  52             789            52             48   \n",
       "2                  26             493            26             23   \n",
       "3                  49             866            49             51   \n",
       "4                  15             408            15             26   \n",
       "\n",
       "   plot_num_interrogation  plot_num_exclamation  plot_num_percentage  \\\n",
       "0                       0                     0                    0   \n",
       "1                       0                     0                    0   \n",
       "2                       0                     0                    0   \n",
       "3                       0                     0                    0   \n",
       "4                       0                     0                    0   \n",
       "\n",
       "   plot_num_semicolon  plot_num_colon  \n",
       "0                   0               0  \n",
       "1                   3               0  \n",
       "2                   0               0  \n",
       "3                   0               0  \n",
       "4                   0               0  "
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Moving back to plot_summaries to avoid nan values\n",
    "plot_summaries['plot_num_sentences'] = plot_summaries.sentences.apply( lambda x: len(x))\n",
    "plot_summaries['plot_num_words'] =  plot_summaries.Plot.apply( lambda x: len(RegexpTokenizer(r'\\w+').tokenize(x)))\n",
    "plot_summaries['plot_num_dot'] = plot_summaries.words_punc.apply( lambda x: list(x).count('.'))\n",
    "plot_summaries['plot_num_coma'] = plot_summaries.words_punc.apply( lambda x: x.count(','))\n",
    "plot_summaries['plot_num_interrogation'] = plot_summaries.words_punc.apply( lambda x: x.count('?'))\n",
    "plot_summaries['plot_num_exclamation'] = plot_summaries.words_punc.apply( lambda x: x.count('!'))\n",
    "plot_summaries['plot_num_percentage'] = plot_summaries.words_punc.apply( lambda x: x.count('%'))\n",
    "plot_summaries['plot_num_semicolon'] = plot_summaries.words_punc.apply( lambda x: x.count(';'))\n",
    "plot_summaries['plot_num_colon'] = plot_summaries.words_punc.apply( lambda x: x.count(':'))\n",
    "\n",
    "plot_summaries[['plot_num_sentences','plot_num_words','plot_num_dot','plot_num_coma','plot_num_interrogation',\\\n",
    "        'plot_num_exclamation','plot_num_percentage','plot_num_semicolon','plot_num_colon']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a1ac363",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 2.3.1.1 Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "430deec4-9ea8-40ab-b58e-d7062e127cfc",
   "metadata": {},
   "source": [
    "#### 2.3.1.2 Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "5638b53e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>plot_num_sentences</th>\n",
       "      <th>plot_num_words</th>\n",
       "      <th>plot_num_dot</th>\n",
       "      <th>plot_num_coma</th>\n",
       "      <th>plot_num_interrogation</th>\n",
       "      <th>plot_num_exclamation</th>\n",
       "      <th>plot_num_percentage</th>\n",
       "      <th>plot_num_semicolon</th>\n",
       "      <th>plot_num_colon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>42276.000000</td>\n",
       "      <td>42276.000000</td>\n",
       "      <td>42276.000000</td>\n",
       "      <td>42276.000000</td>\n",
       "      <td>42276.000000</td>\n",
       "      <td>42276.000000</td>\n",
       "      <td>42276.000000</td>\n",
       "      <td>42276.000000</td>\n",
       "      <td>42276.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>15.693585</td>\n",
       "      <td>316.079052</td>\n",
       "      <td>15.458180</td>\n",
       "      <td>18.626975</td>\n",
       "      <td>0.079194</td>\n",
       "      <td>0.088703</td>\n",
       "      <td>0.009012</td>\n",
       "      <td>0.415129</td>\n",
       "      <td>0.303908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>16.598726</td>\n",
       "      <td>323.456430</td>\n",
       "      <td>16.507334</td>\n",
       "      <td>20.718703</td>\n",
       "      <td>0.449321</td>\n",
       "      <td>0.560378</td>\n",
       "      <td>0.283409</td>\n",
       "      <td>1.202210</td>\n",
       "      <td>0.929971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>89.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>190.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>23.000000</td>\n",
       "      <td>460.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>344.000000</td>\n",
       "      <td>5016.000000</td>\n",
       "      <td>333.000000</td>\n",
       "      <td>307.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>48.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       plot_num_sentences  plot_num_words  plot_num_dot  plot_num_coma  \\\n",
       "count        42276.000000    42276.000000  42276.000000   42276.000000   \n",
       "mean            15.693585      316.079052     15.458180      18.626975   \n",
       "std             16.598726      323.456430     16.507334      20.718703   \n",
       "min              1.000000       14.000000      0.000000       0.000000   \n",
       "25%              4.000000       89.000000      4.000000       4.000000   \n",
       "50%              9.000000      190.000000      9.000000      11.000000   \n",
       "75%             23.000000      460.000000     23.000000      27.000000   \n",
       "max            344.000000     5016.000000    333.000000     307.000000   \n",
       "\n",
       "       plot_num_interrogation  plot_num_exclamation  plot_num_percentage  \\\n",
       "count            42276.000000          42276.000000         42276.000000   \n",
       "mean                 0.079194              0.088703             0.009012   \n",
       "std                  0.449321              0.560378             0.283409   \n",
       "min                  0.000000              0.000000             0.000000   \n",
       "25%                  0.000000              0.000000             0.000000   \n",
       "50%                  0.000000              0.000000             0.000000   \n",
       "75%                  0.000000              0.000000             0.000000   \n",
       "max                 30.000000             27.000000            52.000000   \n",
       "\n",
       "       plot_num_semicolon  plot_num_colon  \n",
       "count        42276.000000    42276.000000  \n",
       "mean             0.415129        0.303908  \n",
       "std              1.202210        0.929971  \n",
       "min              0.000000        0.000000  \n",
       "25%              0.000000        0.000000  \n",
       "50%              0.000000        0.000000  \n",
       "75%              0.000000        0.000000  \n",
       "max             65.000000       48.000000  "
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot_summaries[['plot_num_sentences','plot_num_words','plot_num_dot','plot_num_coma','plot_num_interrogation',\\\n",
    "                'plot_num_exclamation','plot_num_percentage','plot_num_semicolon','plot_num_colon']].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c4458f",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 2.3.2 Most common tokens in plot summaries <a id='2.3.2'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "97f7116b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_frequent(List,n):\n",
    "    occurence_count = Counter(List)\n",
    "    return occurence_count.most_common(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "19ab78fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [(shlykov, 1), (taxi, 1), (driver, 1), (lyosha...\n",
       "1    [(katniss, 24), (peeta, 16), (rue, 11), (distr...\n",
       "2    [(induchoodan, 18), (menon, 12), (manapally, 8...\n",
       "3    [(kid, 34), (home, 10), (moran, 8), (money, 7)...\n",
       "4    [(azaria, 4), (guilty, 3), (wife, 2), (baby, 2...\n",
       "Name: plot_top_ten_tokens, dtype: object"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot_summaries['plot_top_ten_tokens'] = plot_summaries.tokens.apply( lambda x: most_frequent(x,10))\n",
    "\n",
    "plot_summaries['plot_top_ten_tokens'].head() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71bc26a0",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 2.3.3 Words polarity <a id='2.3.3'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "1fff9a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "#count of the different negative and positive words\n",
    "positive_txt = requests.get('https://ptrckprry.com/course/ssd/data/positive-words.txt').text\n",
    "negative_txt = requests.get('https://ptrckprry.com/course/ssd/data/negative-words.txt').text\n",
    "\n",
    "def parse_str(s):\n",
    "    return list(filter(lambda x:x[0]!=';', list(filter(None, s.split(\"\\n\")))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "562b4732",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>plot_num_positive</th>\n",
       "      <th>plot_num_negative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   plot_num_positive  plot_num_negative\n",
       "0                  1                  4\n",
       "1                 17                 33\n",
       "2                 10                 23\n",
       "3                 19                 23\n",
       "4                  4                 14"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot_summaries['plot_num_positive']= plot_summaries.Plot.apply(lambda x : len(set(parse_str(positive_txt)) & set(RegexpTokenizer(r'\\w+').tokenize(x.lower()))))\n",
    "plot_summaries['plot_num_negative']= plot_summaries.Plot.apply(lambda x : len(set(parse_str(negative_txt)) & set(RegexpTokenizer(r'\\w+').tokenize(x.lower()))))\n",
    "\n",
    "plot_summaries[['plot_num_positive','plot_num_negative']].head()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "da0867d6",
   "metadata": {},
   "source": [
    "len((set(['a','a','b']) & set(['a','c','b']) )) # output: 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d06561",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Saving `movies`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "fa3b7f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "merging_cols = list(plot_summaries.columns.difference(movies.columns)) + [\"WikiMovieID\"]\n",
    "movies = movies.merge(plot_summaries[merging_cols], how=\"left\", on=\"WikiMovieID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "d82eb98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('data', exist_ok=True)  \n",
    "movies.to_pickle('data/movies_aug2.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "956a46ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = pd.read_pickle('data/movies_aug2.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83e4931d-c9c5-4216-a08d-5e021fc366ed",
   "metadata": {},
   "source": [
    "### 2.3.4 Ratings <a id='2.3.4'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63876bcb-2860-451c-b735-46c0d9eea01a",
   "metadata": {},
   "source": [
    "### 2.3.5 Combined information <a id='2.3.5'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a9d7665",
   "metadata": {},
   "source": [
    "# 3. Topic Extraction "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c9d8e9",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 3.1 LDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f9943c3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### 3.1.1 Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3bef03c",
   "metadata": {},
   "source": [
    "#### Prepare bi-grams and tri-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "08db24f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = plot_summaries['tokens'].tolist()\n",
    "bigram_model = Phrases(tokens)\n",
    "trigram_model = Phrases(bigram_model[tokens], min_count=1)\n",
    "tokens = list(trigram_model[bigram_model[tokens]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f46c80",
   "metadata": {},
   "source": [
    "#### Prepare objects for LDA gensim implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "90db40c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary_LDA = corpora.Dictionary(tokens)\n",
    "dictionary_LDA.filter_extremes(no_below=3)\n",
    "corpus = [dictionary_LDA.doc2bow(tok) for tok in tokens]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da4dfb74",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### 3.1.2 Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "0abf63e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 41s, sys: 572 ms, total: 1min 41s\n",
      "Wall time: 1min 42s\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(123456)\n",
    "num_topics = 20\n",
    "%time lda_model = models.LdaModel(corpus, num_topics=num_topics, \\\n",
    "                                  id2word=dictionary_LDA, \\\n",
    "                                  passes=4, alpha=[0.01]*num_topics, \\\n",
    "                                  eta=[0.01]*len(dictionary_LDA.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba22ba2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### 3.1.3 Model evaluation \n",
    "\n",
    "(by checking how many topics a word exists in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "381afe7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_ = dict()\n",
    "for i,topic in lda_model.show_topics(formatted=False, num_topics=num_topics, num_words=20):\n",
    "    topics_[i]=topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "3be6e552",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Counts for each word the number of topics that include it\n",
    "\"\"\"\n",
    "def count_words(topics_):\n",
    "    counts = dict()\n",
    "    for i in topics_:\n",
    "        for word in topics_[i]:\n",
    "            if word[0] in counts:\n",
    "                counts[word[0]]+=1\n",
    "            else:\n",
    "                counts[word[0]]=1\n",
    "    return counts\n",
    "\n",
    "def takeSecond(elem):\n",
    "    return elem[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "a8759e8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('woman', 5),\n",
       " ('fall', 5),\n",
       " ('life', 4),\n",
       " ('play', 4),\n",
       " ('give', 4),\n",
       " ('meet', 4),\n",
       " ('time', 4),\n",
       " ('escape', 4),\n",
       " ('men', 4),\n",
       " ('attack', 4),\n",
       " ('begin', 4),\n",
       " ('group', 4)]"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts = count_words(topics_)\n",
    "repeated_words = [(k,v) for k,v in counts.items() if v>=4]\n",
    "repeated_words.sort(reverse=True, key = takeSecond)\n",
    "repeated_words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c657085",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### 3.1.4 Resulting topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "ddc77619",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0 : ['story', 'raja', 'uncle', 'life', 'hollis', 'kang', 'expand_section', 'lambert', 'cite_web', 'play', 'follow', 'idol', 'guru', 'poet', 'bergman', 'millionaire', 'film_tell_story', 'child', 'woman', 'set']\n",
      "\n",
      "Topic 1 : ['money', 'boy', 'kid', 'steal', 'work', 'gang', 'sell', 'bank', 'pay', 'plan', 'give', 'car', 'decide', 'big', 'new', 'company', 'business', 'buy', 'owner', 'town']\n",
      "\n",
      "Topic 2 : ['family', 'mother', 'life', 'father', 'friend', 'child', 'meet', 'wife', 'marry', 'husband', 'live', 'work', 'home', 'woman', 'daughter', 'decide', 'relationship', 'time', 'return', 'fall']\n",
      "\n",
      "Topic 3 : ['kill', 'police', 'escape', 'men', 'shoot', 'murder', 'tell', 'help', 'meet', 'plan', 'fight', 'reveal', 'brother', 'death', 'arrive', 'arrest', 'later', 'gun', 'gang', 'attack']\n",
      "\n",
      "Topic 4 : ['japanese', 'camp', 'spike', 'bowen', 'japan', 'lion', 'korea', 'tokyo', 'circus', 'mace', 'sullivan', 'whitey', 'toshio', 'tarzan', 'preacher', 'korean', 'finch', 'mississippi', 'pa', 'winter']\n",
      "\n",
      "Topic 5 : ['play', 'show', 'dance', 'perform', 'sex', 'act', 'club', 'woman', 'music', 'sing', 'stage', 'performance', 'song', 'begin', 'audience', 'turn', 'dress', 'guest', 'room', 'appear']\n",
      "\n",
      "Topic 6 : ['tell', 'say', 'ask', 'house', 'call', 'give', 'home', 'show', 'want', 'next', 'later', 'night', 'room', 'friend', 'look', 'talk', 'time', 'arrive', 'start', 'think']\n",
      "\n",
      "Topic 7 : ['dog', 'house', 'kill', 'body', 'ghost', 'attack', 'dead', 'baby', 'begin', 'zombie', 'discover', 'head', 'girl', 'child', 'woman', 'old', 'death', 'group', 'wood', 'mother']\n",
      "\n",
      "Topic 8 : ['return', 'ship', 'captain', 'men', 'sir', 'british', 'send', 'order', 'war', 'french', 'england', 'english', 'island', 'give', 'baron', 'count', 'rescue', 'land', 'france', 'crew']\n",
      "\n",
      "Topic 9 : ['dragon', 'castle', 'queen', 'daffy', 'palace', 'kingdom', 'wu', 'sharpe', 'lord', 'turner', 'knight', 'crown', 'puppet', 'boone', 'give', 'fall', 'harper', 'fairy', 'judah', 'gopal']\n",
      "\n",
      "Topic 10 : ['band', 'race', 'win', 'horse', 'fight', 'mayor', 'competition', 'blue', 'samurai', 'local', 'town', 'roberts', 'match', 'train', 'fighter', 'compete', 'team', 'champion', 'challenge', 'crowd']\n",
      "\n",
      "Topic 11 : ['team', 'soldier', 'game', 'agent', 'mission', 'order', 'president', 'men', 'war', 'player', 'lead', 'base', 'group', 'army', 'vampire', 'use', 'attack', 'force', 'tank', 'general']\n",
      "\n",
      "Topic 12 : ['raju', 'murphy', 'kong', 'miller', 'bond', 'scholar', 'chinese', 'pirate', 'treasure', 'wong', 'smuggler', 'fei', 'gayatri', 'jeb', 'hill', 'baker', 'shanghai', 'crawford', 'meet', 'pizza']\n",
      "\n",
      "Topic 13 : ['island', 'water', 'boat', 'fly', 'attempt', 'fall', 'escape', 'head', 'rescue', 'group', 'plane', 'begin', 'land', 'snake', 'trap', 'egg', 'ship', 'another', 'animal', 'pilot']\n",
      "\n",
      "Topic 14 : ['train', 'group', 'camp', 'truck', 'town', 'gold', 'men', 'station', 'soldier', 'escape', 'travel', 'stop', 'survivor', 'hayes', 'mountain', 'prisoner', 'bus', 'mine', 'area', 'driver']\n",
      "\n",
      "Topic 15 : ['film', 'movie', 'show', 'story', 'character', 'play', 'life', 'scene', 'include', 'first', 'people', 'world', 'end', 'director', 'actor', 'part', 'set', 'interview', 'many', 'event']\n",
      "\n",
      "Topic 16 : ['wife', 'life', 'work', 'people', 'case', 'lead', 'death', 'murder', 'involve', 'woman', 'doctor', 'time', 'story', 'state', 'begin', 'know', 'family', 'even', 'believe', 'place']\n",
      "\n",
      "Topic 17 : ['father', 'school', 'girl', 'brother', 'village', 'daughter', 'family', 'student', 'fall', 'mother', 'boy', 'friend', 'marry', 'help', 'sister', 'know', 'meet', 'want', 'decide', 'start']\n",
      "\n",
      "Topic 18 : ['bugs', 'end', 'mouse', 'godzilla', 'wile', 'start', 'fall', 'porky', 'coyote', 'duck', 'rabbit', 'kamini', 'turn', 'cause', 'hit', 'use', 'head', 'play', 'ball', 'attempt']\n",
      "\n",
      "Topic 19 : ['kill', 'use', 'destroy', 'attack', 'world', 'fight', 'escape', 'earth', 'human', 'force', 'return', 'save', 'discover', 'power', 'capture', 'battle', 'monster', 'time', 'reveal', 'attempt']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in topics_:\n",
    "    message = \"Topic {} : \".format(i) \n",
    "    words = str([k for (k,v) in topics_[i]])\n",
    "    print(message+words)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ebccbc",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 3.1.5 Topic Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2afa5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models as gensimvis\n",
    "vis = gensimvis.prepare(topic_model=lda_model, corpus=corpus, dictionary=dictionary_LDA)\n",
    "pyLDAvis.enable_notebook()\n",
    "pyLDAvis.display(vis)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "359ec31c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 3.1.6 Assigning topics to movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "dfb28a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_probable_topic(possible_topics):\n",
    "    possible_topics.sort(reverse=True, key = takeSecond)\n",
    "    return possible_topics[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "131b101b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████| 42276/42276 [00:18<00:00, 2309.42it/s]\n"
     ]
    }
   ],
   "source": [
    "chosen_topics = list()\n",
    "for plot in tqdm(corpus):\n",
    "    possible_topics = lda_model[plot]\n",
    "    chosen_topic = most_probable_topic(possible_topics)\n",
    "    chosen_topics.append(chosen_topic)\n",
    "\n",
    "chosen_topics = np.array(chosen_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "d4d5de8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Topic  Index\n",
       "0      2      0\n",
       "1     19      1\n",
       "2     16      2\n",
       "3      1      3\n",
       "4     16      4"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "topics_df = pd.DataFrame(chosen_topics, columns = [\"Topic\"]) #Rename this to Topic_LDA\n",
    "\n",
    "topics_df[\"Index\"] = topics_df.index\n",
    "\n",
    "display(topics_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "6dfd6755",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_summaries[\"Index\"] = plot_summaries.index\n",
    "\n",
    "plot_summaries = plot_summaries.merge(topics_df, left_on=\"Index\", right_on=\"Index\").drop(columns=[\"Index\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "276bd929",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WikiMovieID</th>\n",
       "      <th>Plot</th>\n",
       "      <th>Topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23890098</td>\n",
       "      <td>Shlykov, a hard-working taxi driver and Lyosha...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31186339</td>\n",
       "      <td>The nation of Panem consists of a wealthy Capi...</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20663735</td>\n",
       "      <td>Poovalli Induchoodan  is sentenced for six yea...</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2231378</td>\n",
       "      <td>The Lemon Drop Kid , a New York City swindler,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>595909</td>\n",
       "      <td>Seventh-day Adventist Church pastor Michael Ch...</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   WikiMovieID                                               Plot  Topic\n",
       "0     23890098  Shlykov, a hard-working taxi driver and Lyosha...      2\n",
       "1     31186339  The nation of Panem consists of a wealthy Capi...     19\n",
       "2     20663735  Poovalli Induchoodan  is sentenced for six yea...     16\n",
       "3      2231378  The Lemon Drop Kid , a New York City swindler,...      1\n",
       "4       595909  Seventh-day Adventist Church pastor Michael Ch...     16"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot_summaries[[\"WikiMovieID\", \"Plot\", \"Topic\"]].head() # Can merge again with movies "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5edd742b",
   "metadata": {},
   "source": [
    "#### Saving `movies`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "971ea89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "merging_cols = list(plot_summaries.columns.difference(movies.columns)) + [\"WikiMovieID\"]\n",
    "movies = movies.merge(plot_summaries[merging_cols], how=\"left\", on=\"WikiMovieID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "ae95a9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('data', exist_ok=True)  \n",
    "movies.to_pickle('data/movies_aug3.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "84175ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = pd.read_pickle('data/movies_aug3.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a0eb59",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 3.2 BERTopic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "246235aa",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### 3.2.1 Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be9026fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of docs\n",
    "docs = data.Plot.tolist()\n",
    "\n",
    "# List of punctuation marks\n",
    "punctuations = list()\n",
    "for punctuation in string.punctuation:\n",
    "    punctuations.append(punctuation)\n",
    "\n",
    "# Stopwords to use\n",
    "stop_words = list(set(stopwords.words('english'))) + punctuations + names\n",
    "\n",
    "# Tokenization : List of Lists of Tokens\n",
    "docs_tokenized = [word_tokenize(doc) for doc in docs]\n",
    "\n",
    "# Removing the stopwords\n",
    "filtered_docs = list()\n",
    "for doc in tqdm(docs_tokenized):\n",
    "    filtered_doc = \" \".join([w.lower() for w in doc if not w.lower() in stop_words])\n",
    "    filtered_docs.append(filtered_doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d67fd5c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### 3.2.2 Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ae32ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BERTopic(language=\"english\")\n",
    "topics, probs = model.fit_transform(filtered_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa4dabf3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### 3.2.3 Resulting topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db39c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(model.get_topic_freq().head(20))\n",
    "model.get_topic(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57ee736b",
   "metadata": {},
   "source": [
    "### 3.2.4 Topic Visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a890834",
   "metadata": {},
   "source": [
    "### 3.2.5 Assigning topics to movies"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ada] *",
   "language": "python",
   "name": "conda-env-ada-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
